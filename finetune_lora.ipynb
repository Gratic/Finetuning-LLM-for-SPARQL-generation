{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da6d7fed7314b289d61c91ae49f62b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/711 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6944cfea634d63ae5a67938837dcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6c8d935c9740f7a10dd3e0c73ccec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2044968c1e640559ba3c4bb8e19dfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef68d3811066451fa5e24b6d281acd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Setup the model\n",
    "# checkpoint = \"bigscience/bloomz-560m\"\n",
    "checkpoint = \"bigscience/bigscience-small-testing\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map='auto') # load_in_8bit=True,\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Freeze the original weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False # freeze the model - train adapters later\n",
    "    if param.ndim == 1:\n",
    "        # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "        param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable() # reduce the number of stored activations\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "    def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8192 || all params: 16164736 || trainable%: 0.05067821707697546\n"
     ]
    }
   ],
   "source": [
    "# 3) Setting up the LoRA Adapters\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    \n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100*trainable_params/all_param}\")\n",
    "    \n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16, # attention heads\n",
    "    lora_alpha=32, # alpha scaling TODO: Research what this is\n",
    "    # target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Alexis Strappazzon/.cache/huggingface/datasets/Abirate___json/Abirate--english_quotes-6e72855d06356857/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9d44d5fc6645e78902e99e690de283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4) Data\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "data = load_dataset(\"Abirate/english_quotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Be yourself; everyone else is already taken.”',\n",
       " \"“I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.”\",\n",
       " \"“Two things are infinite: the universe and human stupidity; and I'm not sure about the universe.”\",\n",
       " '“So many books, so little time.”',\n",
       " '“A room without books is like a body without a soul.”']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"quote\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['be-yourself',\n",
       "  'gilbert-perreira',\n",
       "  'honesty',\n",
       "  'inspirational',\n",
       "  'misattributed-oscar-wilde',\n",
       "  'quote-investigator'],\n",
       " ['best', 'life', 'love', 'mistakes', 'out-of-control', 'truth', 'worst'],\n",
       " ['human-nature',\n",
       "  'humor',\n",
       "  'infinity',\n",
       "  'philosophy',\n",
       "  'science',\n",
       "  'stupidity',\n",
       "  'universe'],\n",
       " ['books', 'humor'],\n",
       " ['books', 'simile', 'soul']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"tags\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Alexis Strappazzon\\.cache\\huggingface\\datasets\\Abirate___json\\Abirate--english_quotes-6e72855d06356857\\0.0.0\\e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\\cache-8a7463b65fe0bb13.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"“Be yourself; everyone else is already taken.” ->: ['be-yourself', 'gilbert-perreira', 'honesty', 'inspirational', 'misattributed-oscar-wilde', 'quote-investigator']\",\n",
       " \"“I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.” ->: ['best', 'life', 'love', 'mistakes', 'out-of-control', 'truth', 'worst']\",\n",
       " \"“Two things are infinite: the universe and human stupidity; and I'm not sure about the universe.” ->: ['human-nature', 'humor', 'infinity', 'philosophy', 'science', 'stupidity', 'universe']\",\n",
       " \"“So many books, so little time.” ->: ['books', 'humor']\",\n",
       " \"“A room without books is like a body without a soul.” ->: ['books', 'simile', 'soul']\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_columns(example):\n",
    "    example[\"prediction\"] = example[\"quote\"] + \" ->: \" + str(example[\"tags\"])\n",
    "    return example\n",
    "\n",
    "data[\"train\"] = data[\"train\"].map(merge_columns)\n",
    "data[\"train\"][\"prediction\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': '“Be yourself; everyone else is already taken.”',\n",
       " 'author': 'Oscar Wilde',\n",
       " 'tags': ['be-yourself',\n",
       "  'gilbert-perreira',\n",
       "  'honesty',\n",
       "  'inspirational',\n",
       "  'misattributed-oscar-wilde',\n",
       "  'quote-investigator'],\n",
       " 'prediction': \"“Be yourself; everyone else is already taken.” ->: ['be-yourself', 'gilbert-perreira', 'honesty', 'inspirational', 'misattributed-oscar-wilde', 'quote-investigator']\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dcfeb02c6f41e8bff14851d2ebb366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(lambda samples: tokenizer(samples['prediction']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['quote', 'author', 'tags', 'prediction', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2508\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexis Strappazzon\\Documents\\code\\python\\HF_bloomz_test\\.venv\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1249290006e642f89c6e0bf263fb1eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.4345, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 12.4354, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 12.4311, 'learning_rate': 6e-06, 'epoch': 0.02}\n",
      "{'loss': 12.4335, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 12.4321, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 12.4321, 'learning_rate': 1.2e-05, 'epoch': 0.04}\n",
      "{'loss': 12.435, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 12.4335, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 12.4359, 'learning_rate': 1.8e-05, 'epoch': 0.06}\n",
      "{'loss': 12.4319, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
      "{'loss': 12.4338, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 12.4331, 'learning_rate': 2.4e-05, 'epoch': 0.08}\n",
      "{'loss': 12.4345, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 12.4338, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 12.4348, 'learning_rate': 3e-05, 'epoch': 0.1}\n",
      "{'loss': 12.433, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.1}\n",
      "{'loss': 12.4357, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.11}\n",
      "{'loss': 12.4341, 'learning_rate': 3.6e-05, 'epoch': 0.11}\n",
      "{'loss': 12.4328, 'learning_rate': 3.8e-05, 'epoch': 0.12}\n",
      "{'loss': 12.4361, 'learning_rate': 4e-05, 'epoch': 0.13}\n",
      "{'loss': 12.434, 'learning_rate': 4.2e-05, 'epoch': 0.13}\n",
      "{'loss': 12.4335, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.14}\n",
      "{'loss': 12.43, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.15}\n",
      "{'loss': 12.4351, 'learning_rate': 4.8e-05, 'epoch': 0.15}\n",
      "{'loss': 12.4332, 'learning_rate': 5e-05, 'epoch': 0.16}\n",
      "{'loss': 12.4357, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.17}\n",
      "{'loss': 12.4359, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.17}\n",
      "{'loss': 12.4365, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.18}\n",
      "{'loss': 12.4348, 'learning_rate': 5.8e-05, 'epoch': 0.19}\n",
      "{'loss': 12.4346, 'learning_rate': 6e-05, 'epoch': 0.19}\n",
      "{'loss': 12.4334, 'learning_rate': 6.2e-05, 'epoch': 0.2}\n",
      "{'loss': 12.4342, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.2}\n",
      "{'loss': 12.432, 'learning_rate': 6.6e-05, 'epoch': 0.21}\n",
      "{'loss': 12.4325, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.22}\n",
      "{'loss': 12.4349, 'learning_rate': 7e-05, 'epoch': 0.22}\n",
      "{'loss': 12.4321, 'learning_rate': 7.2e-05, 'epoch': 0.23}\n",
      "{'loss': 12.4341, 'learning_rate': 7.4e-05, 'epoch': 0.24}\n",
      "{'loss': 12.4316, 'learning_rate': 7.6e-05, 'epoch': 0.24}\n",
      "{'loss': 12.4321, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.25}\n",
      "{'loss': 12.4363, 'learning_rate': 8e-05, 'epoch': 0.26}\n",
      "{'loss': 12.4354, 'learning_rate': 8.2e-05, 'epoch': 0.26}\n",
      "{'loss': 12.4327, 'learning_rate': 8.4e-05, 'epoch': 0.27}\n",
      "{'loss': 12.4327, 'learning_rate': 8.6e-05, 'epoch': 0.27}\n",
      "{'loss': 12.4333, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.28}\n",
      "{'loss': 12.4343, 'learning_rate': 9e-05, 'epoch': 0.29}\n",
      "{'loss': 12.4333, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.29}\n",
      "{'loss': 12.4335, 'learning_rate': 9.4e-05, 'epoch': 0.3}\n",
      "{'loss': 12.432, 'learning_rate': 9.6e-05, 'epoch': 0.31}\n",
      "{'loss': 12.4356, 'learning_rate': 9.8e-05, 'epoch': 0.31}\n",
      "{'loss': 12.433, 'learning_rate': 0.0001, 'epoch': 0.32}\n",
      "{'loss': 12.4345, 'learning_rate': 0.00010200000000000001, 'epoch': 0.33}\n",
      "{'loss': 12.4343, 'learning_rate': 0.00010400000000000001, 'epoch': 0.33}\n",
      "{'loss': 12.4359, 'learning_rate': 0.00010600000000000002, 'epoch': 0.34}\n",
      "{'loss': 12.4313, 'learning_rate': 0.00010800000000000001, 'epoch': 0.34}\n",
      "{'loss': 12.4326, 'learning_rate': 0.00011000000000000002, 'epoch': 0.35}\n",
      "{'loss': 12.4328, 'learning_rate': 0.00011200000000000001, 'epoch': 0.36}\n",
      "{'loss': 12.4322, 'learning_rate': 0.00011399999999999999, 'epoch': 0.36}\n",
      "{'loss': 12.433, 'learning_rate': 0.000116, 'epoch': 0.37}\n",
      "{'loss': 12.4341, 'learning_rate': 0.000118, 'epoch': 0.38}\n",
      "{'loss': 12.4324, 'learning_rate': 0.00012, 'epoch': 0.38}\n",
      "{'loss': 12.4322, 'learning_rate': 0.000122, 'epoch': 0.39}\n",
      "{'loss': 12.4319, 'learning_rate': 0.000124, 'epoch': 0.4}\n",
      "{'loss': 12.4333, 'learning_rate': 0.000126, 'epoch': 0.4}\n",
      "{'loss': 12.4351, 'learning_rate': 0.00012800000000000002, 'epoch': 0.41}\n",
      "{'loss': 12.433, 'learning_rate': 0.00013000000000000002, 'epoch': 0.41}\n",
      "{'loss': 12.4302, 'learning_rate': 0.000132, 'epoch': 0.42}\n",
      "{'loss': 12.434, 'learning_rate': 0.000134, 'epoch': 0.43}\n",
      "{'loss': 12.4334, 'learning_rate': 0.00013600000000000003, 'epoch': 0.43}\n",
      "{'loss': 12.4356, 'learning_rate': 0.000138, 'epoch': 0.44}\n",
      "{'loss': 12.4327, 'learning_rate': 0.00014, 'epoch': 0.45}\n",
      "{'loss': 12.4326, 'learning_rate': 0.000142, 'epoch': 0.45}\n",
      "{'loss': 12.4328, 'learning_rate': 0.000144, 'epoch': 0.46}\n",
      "{'loss': 12.4334, 'learning_rate': 0.000146, 'epoch': 0.47}\n",
      "{'loss': 12.4314, 'learning_rate': 0.000148, 'epoch': 0.47}\n",
      "{'loss': 12.4348, 'learning_rate': 0.00015000000000000001, 'epoch': 0.48}\n",
      "{'loss': 12.431, 'learning_rate': 0.000152, 'epoch': 0.48}\n",
      "{'loss': 12.4347, 'learning_rate': 0.000154, 'epoch': 0.49}\n",
      "{'loss': 12.4338, 'learning_rate': 0.00015600000000000002, 'epoch': 0.5}\n",
      "{'loss': 12.4345, 'learning_rate': 0.00015800000000000002, 'epoch': 0.5}\n",
      "{'loss': 12.4347, 'learning_rate': 0.00016, 'epoch': 0.51}\n",
      "{'loss': 12.4308, 'learning_rate': 0.000162, 'epoch': 0.52}\n",
      "{'loss': 12.4356, 'learning_rate': 0.000164, 'epoch': 0.52}\n",
      "{'loss': 12.4353, 'learning_rate': 0.000166, 'epoch': 0.53}\n",
      "{'loss': 12.4318, 'learning_rate': 0.000168, 'epoch': 0.54}\n",
      "{'loss': 12.4321, 'learning_rate': 0.00017, 'epoch': 0.54}\n",
      "{'loss': 12.434, 'learning_rate': 0.000172, 'epoch': 0.55}\n",
      "{'loss': 12.433, 'learning_rate': 0.000174, 'epoch': 0.56}\n",
      "{'loss': 12.4358, 'learning_rate': 0.00017600000000000002, 'epoch': 0.56}\n",
      "{'loss': 12.4312, 'learning_rate': 0.00017800000000000002, 'epoch': 0.57}\n",
      "{'loss': 12.4346, 'learning_rate': 0.00018, 'epoch': 0.57}\n",
      "{'loss': 12.434, 'learning_rate': 0.000182, 'epoch': 0.58}\n",
      "{'loss': 12.4344, 'learning_rate': 0.00018400000000000003, 'epoch': 0.59}\n",
      "{'loss': 12.431, 'learning_rate': 0.00018600000000000002, 'epoch': 0.59}\n",
      "{'loss': 12.431, 'learning_rate': 0.000188, 'epoch': 0.6}\n",
      "{'loss': 12.4334, 'learning_rate': 0.00019, 'epoch': 0.61}\n",
      "{'loss': 12.4341, 'learning_rate': 0.000192, 'epoch': 0.61}\n",
      "{'loss': 12.434, 'learning_rate': 0.000194, 'epoch': 0.62}\n",
      "{'loss': 12.434, 'learning_rate': 0.000196, 'epoch': 0.63}\n",
      "{'loss': 12.4343, 'learning_rate': 0.00019800000000000002, 'epoch': 0.63}\n",
      "{'loss': 12.4313, 'learning_rate': 0.0002, 'epoch': 0.64}\n",
      "{'loss': 12.4335, 'learning_rate': 0.0001997777777777778, 'epoch': 0.64}\n",
      "{'loss': 12.4325, 'learning_rate': 0.00019955555555555558, 'epoch': 0.65}\n",
      "{'loss': 12.4327, 'learning_rate': 0.00019933333333333334, 'epoch': 0.66}\n",
      "{'loss': 12.4324, 'learning_rate': 0.00019911111111111111, 'epoch': 0.66}\n",
      "{'loss': 12.4311, 'learning_rate': 0.0001988888888888889, 'epoch': 0.67}\n",
      "{'loss': 12.4344, 'learning_rate': 0.00019866666666666668, 'epoch': 0.68}\n",
      "{'loss': 12.4334, 'learning_rate': 0.00019844444444444445, 'epoch': 0.68}\n",
      "{'loss': 12.4349, 'learning_rate': 0.00019822222222222225, 'epoch': 0.69}\n",
      "{'loss': 12.4308, 'learning_rate': 0.00019800000000000002, 'epoch': 0.7}\n",
      "{'loss': 12.4336, 'learning_rate': 0.00019777777777777778, 'epoch': 0.7}\n",
      "{'loss': 12.435, 'learning_rate': 0.00019755555555555555, 'epoch': 0.71}\n",
      "{'loss': 12.4295, 'learning_rate': 0.00019733333333333335, 'epoch': 0.71}\n",
      "{'loss': 12.435, 'learning_rate': 0.00019711111111111112, 'epoch': 0.72}\n",
      "{'loss': 12.4334, 'learning_rate': 0.0001968888888888889, 'epoch': 0.73}\n",
      "{'loss': 12.4322, 'learning_rate': 0.00019666666666666666, 'epoch': 0.73}\n",
      "{'loss': 12.434, 'learning_rate': 0.00019644444444444445, 'epoch': 0.74}\n",
      "{'loss': 12.4339, 'learning_rate': 0.00019622222222222225, 'epoch': 0.75}\n",
      "{'loss': 12.4322, 'learning_rate': 0.000196, 'epoch': 0.75}\n",
      "{'loss': 12.4333, 'learning_rate': 0.0001957777777777778, 'epoch': 0.76}\n",
      "{'loss': 12.4327, 'learning_rate': 0.00019555555555555556, 'epoch': 0.77}\n",
      "{'loss': 12.4336, 'learning_rate': 0.00019533333333333336, 'epoch': 0.77}\n",
      "{'loss': 12.4324, 'learning_rate': 0.0001951111111111111, 'epoch': 0.78}\n",
      "{'loss': 12.4329, 'learning_rate': 0.0001948888888888889, 'epoch': 0.78}\n",
      "{'loss': 12.4342, 'learning_rate': 0.0001946666666666667, 'epoch': 0.79}\n",
      "{'loss': 12.4327, 'learning_rate': 0.00019444444444444446, 'epoch': 0.8}\n",
      "{'loss': 12.4317, 'learning_rate': 0.00019422222222222223, 'epoch': 0.8}\n",
      "{'loss': 12.4315, 'learning_rate': 0.000194, 'epoch': 0.81}\n",
      "{'loss': 12.4344, 'learning_rate': 0.0001937777777777778, 'epoch': 0.82}\n",
      "{'loss': 12.4332, 'learning_rate': 0.00019355555555555557, 'epoch': 0.82}\n",
      "{'loss': 12.4326, 'learning_rate': 0.00019333333333333333, 'epoch': 0.83}\n",
      "{'loss': 12.4332, 'learning_rate': 0.0001931111111111111, 'epoch': 0.84}\n",
      "{'loss': 12.4332, 'learning_rate': 0.0001928888888888889, 'epoch': 0.84}\n",
      "{'loss': 12.4321, 'learning_rate': 0.0001926666666666667, 'epoch': 0.85}\n",
      "{'loss': 12.4363, 'learning_rate': 0.00019244444444444444, 'epoch': 0.85}\n",
      "{'loss': 12.4346, 'learning_rate': 0.00019222222222222224, 'epoch': 0.86}\n",
      "{'loss': 12.4327, 'learning_rate': 0.000192, 'epoch': 0.87}\n",
      "{'loss': 12.4344, 'learning_rate': 0.0001917777777777778, 'epoch': 0.87}\n",
      "{'loss': 12.4333, 'learning_rate': 0.00019155555555555554, 'epoch': 0.88}\n",
      "{'loss': 12.4322, 'learning_rate': 0.00019133333333333334, 'epoch': 0.89}\n",
      "{'loss': 12.4352, 'learning_rate': 0.00019111111111111114, 'epoch': 0.89}\n",
      "{'loss': 12.4333, 'learning_rate': 0.0001908888888888889, 'epoch': 0.9}\n",
      "{'loss': 12.432, 'learning_rate': 0.00019066666666666668, 'epoch': 0.91}\n",
      "{'loss': 12.4326, 'learning_rate': 0.00019044444444444444, 'epoch': 0.91}\n",
      "{'loss': 12.4306, 'learning_rate': 0.00019022222222222224, 'epoch': 0.92}\n",
      "{'loss': 12.437, 'learning_rate': 0.00019, 'epoch': 0.93}\n",
      "{'loss': 12.4344, 'learning_rate': 0.00018977777777777778, 'epoch': 0.93}\n",
      "{'loss': 12.4324, 'learning_rate': 0.00018955555555555558, 'epoch': 0.94}\n",
      "{'loss': 12.431, 'learning_rate': 0.00018933333333333335, 'epoch': 0.94}\n",
      "{'loss': 12.435, 'learning_rate': 0.00018911111111111112, 'epoch': 0.95}\n",
      "{'loss': 12.4365, 'learning_rate': 0.00018888888888888888, 'epoch': 0.96}\n",
      "{'loss': 12.4339, 'learning_rate': 0.00018866666666666668, 'epoch': 0.96}\n",
      "{'loss': 12.4319, 'learning_rate': 0.00018844444444444445, 'epoch': 0.97}\n",
      "{'loss': 12.432, 'learning_rate': 0.00018822222222222222, 'epoch': 0.98}\n",
      "{'loss': 12.4324, 'learning_rate': 0.000188, 'epoch': 0.98}\n",
      "{'loss': 12.433, 'learning_rate': 0.00018777777777777779, 'epoch': 0.99}\n",
      "{'loss': 12.4347, 'learning_rate': 0.00018755555555555558, 'epoch': 1.0}\n",
      "{'loss': 12.4337, 'learning_rate': 0.00018733333333333335, 'epoch': 1.0}\n",
      "{'loss': 12.4343, 'learning_rate': 0.00018711111111111112, 'epoch': 1.01}\n",
      "{'loss': 12.4324, 'learning_rate': 0.0001868888888888889, 'epoch': 1.01}\n",
      "{'loss': 12.4337, 'learning_rate': 0.0001866666666666667, 'epoch': 1.02}\n",
      "{'loss': 12.4337, 'learning_rate': 0.00018644444444444446, 'epoch': 1.03}\n",
      "{'loss': 12.4321, 'learning_rate': 0.00018622222222222223, 'epoch': 1.03}\n",
      "{'loss': 12.4343, 'learning_rate': 0.00018600000000000002, 'epoch': 1.04}\n",
      "{'loss': 12.4312, 'learning_rate': 0.0001857777777777778, 'epoch': 1.05}\n",
      "{'loss': 12.433, 'learning_rate': 0.00018555555555555556, 'epoch': 1.05}\n",
      "{'loss': 12.4363, 'learning_rate': 0.00018533333333333333, 'epoch': 1.06}\n",
      "{'loss': 12.4342, 'learning_rate': 0.00018511111111111113, 'epoch': 1.07}\n",
      "{'loss': 12.4345, 'learning_rate': 0.0001848888888888889, 'epoch': 1.07}\n",
      "{'loss': 12.4311, 'learning_rate': 0.00018466666666666666, 'epoch': 1.08}\n",
      "{'loss': 12.4352, 'learning_rate': 0.00018444444444444446, 'epoch': 1.08}\n",
      "{'loss': 12.4328, 'learning_rate': 0.00018422222222222223, 'epoch': 1.09}\n",
      "{'loss': 12.4359, 'learning_rate': 0.00018400000000000003, 'epoch': 1.1}\n",
      "{'loss': 12.4356, 'learning_rate': 0.00018377777777777777, 'epoch': 1.1}\n",
      "{'loss': 12.4341, 'learning_rate': 0.00018355555555555557, 'epoch': 1.11}\n",
      "{'loss': 12.4318, 'learning_rate': 0.00018333333333333334, 'epoch': 1.12}\n",
      "{'loss': 12.4337, 'learning_rate': 0.00018311111111111113, 'epoch': 1.12}\n",
      "{'loss': 12.4337, 'learning_rate': 0.00018288888888888887, 'epoch': 1.13}\n",
      "{'loss': 12.4332, 'learning_rate': 0.00018266666666666667, 'epoch': 1.14}\n",
      "{'loss': 12.431, 'learning_rate': 0.00018244444444444447, 'epoch': 1.14}\n",
      "{'loss': 12.4343, 'learning_rate': 0.00018222222222222224, 'epoch': 1.15}\n",
      "{'loss': 12.4349, 'learning_rate': 0.000182, 'epoch': 1.15}\n",
      "{'loss': 12.4323, 'learning_rate': 0.00018177777777777778, 'epoch': 1.16}\n",
      "{'loss': 12.4327, 'learning_rate': 0.00018155555555555557, 'epoch': 1.17}\n",
      "{'loss': 12.4313, 'learning_rate': 0.00018133333333333334, 'epoch': 1.17}\n",
      "{'loss': 12.4319, 'learning_rate': 0.0001811111111111111, 'epoch': 1.18}\n",
      "{'loss': 12.4367, 'learning_rate': 0.0001808888888888889, 'epoch': 1.19}\n",
      "{'loss': 12.4329, 'learning_rate': 0.00018066666666666668, 'epoch': 1.19}\n",
      "{'loss': 12.4339, 'learning_rate': 0.00018044444444444447, 'epoch': 1.2}\n",
      "{'loss': 12.4305, 'learning_rate': 0.00018022222222222221, 'epoch': 1.21}\n",
      "{'loss': 12.4335, 'learning_rate': 0.00018, 'epoch': 1.21}\n",
      "{'loss': 12.4308, 'learning_rate': 0.00017977777777777778, 'epoch': 1.22}\n",
      "{'loss': 12.4332, 'learning_rate': 0.00017955555555555558, 'epoch': 1.22}\n",
      "{'loss': 12.4319, 'learning_rate': 0.00017933333333333332, 'epoch': 1.23}\n",
      "{'loss': 12.4315, 'learning_rate': 0.00017911111111111112, 'epoch': 1.24}\n",
      "{'loss': 12.4347, 'learning_rate': 0.0001788888888888889, 'epoch': 1.24}\n",
      "{'loss': 12.4309, 'learning_rate': 0.00017866666666666668, 'epoch': 1.25}\n",
      "{'loss': 12.432, 'learning_rate': 0.00017844444444444445, 'epoch': 1.26}\n",
      "{'loss': 12.4307, 'learning_rate': 0.00017822222222222222, 'epoch': 1.26}\n",
      "{'loss': 12.4321, 'learning_rate': 0.00017800000000000002, 'epoch': 1.27}\n",
      "{'loss': 12.4321, 'learning_rate': 0.00017777777777777779, 'epoch': 1.28}\n",
      "{'loss': 12.4334, 'learning_rate': 0.00017755555555555556, 'epoch': 1.28}\n",
      "{'loss': 12.432, 'learning_rate': 0.00017733333333333335, 'epoch': 1.29}\n",
      "{'loss': 12.434, 'learning_rate': 0.00017711111111111112, 'epoch': 1.3}\n",
      "{'loss': 12.432, 'learning_rate': 0.0001768888888888889, 'epoch': 1.3}\n",
      "{'loss': 12.4333, 'learning_rate': 0.00017666666666666666, 'epoch': 1.31}\n",
      "{'loss': 12.431, 'learning_rate': 0.00017644444444444446, 'epoch': 1.31}\n",
      "{'loss': 12.4317, 'learning_rate': 0.00017622222222222223, 'epoch': 1.32}\n",
      "{'loss': 12.432, 'learning_rate': 0.00017600000000000002, 'epoch': 1.33}\n",
      "{'loss': 12.4321, 'learning_rate': 0.0001757777777777778, 'epoch': 1.33}\n",
      "{'loss': 12.4338, 'learning_rate': 0.00017555555555555556, 'epoch': 1.34}\n",
      "{'loss': 12.4345, 'learning_rate': 0.00017533333333333336, 'epoch': 1.35}\n",
      "{'loss': 12.4325, 'learning_rate': 0.00017511111111111113, 'epoch': 1.35}\n",
      "{'loss': 12.4339, 'learning_rate': 0.0001748888888888889, 'epoch': 1.36}\n",
      "{'loss': 12.4331, 'learning_rate': 0.00017466666666666667, 'epoch': 1.37}\n",
      "{'loss': 12.4312, 'learning_rate': 0.00017444444444444446, 'epoch': 1.37}\n",
      "{'loss': 12.4354, 'learning_rate': 0.00017422222222222223, 'epoch': 1.38}\n",
      "{'loss': 12.432, 'learning_rate': 0.000174, 'epoch': 1.38}\n",
      "{'loss': 12.4337, 'learning_rate': 0.0001737777777777778, 'epoch': 1.39}\n",
      "{'loss': 12.4312, 'learning_rate': 0.00017355555555555557, 'epoch': 1.4}\n",
      "{'loss': 12.4303, 'learning_rate': 0.00017333333333333334, 'epoch': 1.4}\n",
      "{'loss': 12.4315, 'learning_rate': 0.0001731111111111111, 'epoch': 1.41}\n",
      "{'loss': 12.4309, 'learning_rate': 0.0001728888888888889, 'epoch': 1.42}\n",
      "{'loss': 12.4336, 'learning_rate': 0.00017266666666666667, 'epoch': 1.42}\n",
      "{'loss': 12.4302, 'learning_rate': 0.00017244444444444444, 'epoch': 1.43}\n",
      "{'loss': 12.4321, 'learning_rate': 0.00017222222222222224, 'epoch': 1.44}\n",
      "{'loss': 12.4319, 'learning_rate': 0.000172, 'epoch': 1.44}\n",
      "{'loss': 12.4299, 'learning_rate': 0.0001717777777777778, 'epoch': 1.45}\n",
      "{'loss': 12.4317, 'learning_rate': 0.00017155555555555555, 'epoch': 1.45}\n",
      "{'loss': 12.429, 'learning_rate': 0.00017133333333333334, 'epoch': 1.46}\n",
      "{'loss': 12.4293, 'learning_rate': 0.0001711111111111111, 'epoch': 1.47}\n",
      "{'loss': 12.43, 'learning_rate': 0.0001708888888888889, 'epoch': 1.47}\n",
      "{'loss': 12.4321, 'learning_rate': 0.00017066666666666668, 'epoch': 1.48}\n",
      "{'loss': 12.4327, 'learning_rate': 0.00017044444444444445, 'epoch': 1.49}\n",
      "{'loss': 12.4342, 'learning_rate': 0.00017022222222222224, 'epoch': 1.49}\n",
      "{'loss': 12.4299, 'learning_rate': 0.00017, 'epoch': 1.5}\n",
      "{'loss': 12.4279, 'learning_rate': 0.00016977777777777778, 'epoch': 1.51}\n",
      "{'loss': 12.4323, 'learning_rate': 0.00016955555555555555, 'epoch': 1.51}\n",
      "{'loss': 12.4311, 'learning_rate': 0.00016933333333333335, 'epoch': 1.52}\n",
      "{'loss': 12.4323, 'learning_rate': 0.00016911111111111112, 'epoch': 1.52}\n",
      "{'loss': 12.4292, 'learning_rate': 0.00016888888888888889, 'epoch': 1.53}\n",
      "{'loss': 12.4326, 'learning_rate': 0.00016866666666666668, 'epoch': 1.54}\n",
      "{'loss': 12.4314, 'learning_rate': 0.00016844444444444445, 'epoch': 1.54}\n",
      "{'loss': 12.4327, 'learning_rate': 0.00016822222222222225, 'epoch': 1.55}\n",
      "{'loss': 12.4343, 'learning_rate': 0.000168, 'epoch': 1.56}\n",
      "{'loss': 12.4341, 'learning_rate': 0.0001677777777777778, 'epoch': 1.56}\n",
      "{'loss': 12.4334, 'learning_rate': 0.00016755555555555556, 'epoch': 1.57}\n",
      "{'loss': 12.4324, 'learning_rate': 0.00016733333333333335, 'epoch': 1.58}\n",
      "{'loss': 12.431, 'learning_rate': 0.00016711111111111112, 'epoch': 1.58}\n",
      "{'loss': 12.4299, 'learning_rate': 0.0001668888888888889, 'epoch': 1.59}\n",
      "{'loss': 12.43, 'learning_rate': 0.0001666666666666667, 'epoch': 1.59}\n",
      "{'loss': 12.4314, 'learning_rate': 0.00016644444444444446, 'epoch': 1.6}\n",
      "{'loss': 12.431, 'learning_rate': 0.00016622222222222223, 'epoch': 1.61}\n",
      "{'loss': 12.4311, 'learning_rate': 0.000166, 'epoch': 1.61}\n",
      "{'loss': 12.4289, 'learning_rate': 0.0001657777777777778, 'epoch': 1.62}\n",
      "{'loss': 12.4305, 'learning_rate': 0.00016555555555555556, 'epoch': 1.63}\n",
      "{'loss': 12.4314, 'learning_rate': 0.00016533333333333333, 'epoch': 1.63}\n",
      "{'loss': 12.4324, 'learning_rate': 0.00016511111111111113, 'epoch': 1.64}\n",
      "{'loss': 12.4309, 'learning_rate': 0.0001648888888888889, 'epoch': 1.65}\n",
      "{'loss': 12.4308, 'learning_rate': 0.00016466666666666667, 'epoch': 1.65}\n",
      "{'loss': 12.4335, 'learning_rate': 0.00016444444444444444, 'epoch': 1.66}\n",
      "{'loss': 12.4294, 'learning_rate': 0.00016422222222222223, 'epoch': 1.67}\n",
      "{'loss': 12.4304, 'learning_rate': 0.000164, 'epoch': 1.67}\n",
      "{'loss': 12.4307, 'learning_rate': 0.0001637777777777778, 'epoch': 1.68}\n",
      "{'loss': 12.4279, 'learning_rate': 0.00016355555555555557, 'epoch': 1.68}\n",
      "{'loss': 12.4298, 'learning_rate': 0.00016333333333333334, 'epoch': 1.69}\n",
      "{'loss': 12.4323, 'learning_rate': 0.00016311111111111113, 'epoch': 1.7}\n",
      "{'loss': 12.4267, 'learning_rate': 0.0001628888888888889, 'epoch': 1.7}\n",
      "{'loss': 12.4283, 'learning_rate': 0.00016266666666666667, 'epoch': 1.71}\n",
      "{'loss': 12.4321, 'learning_rate': 0.00016244444444444444, 'epoch': 1.72}\n",
      "{'loss': 12.4299, 'learning_rate': 0.00016222222222222224, 'epoch': 1.72}\n",
      "{'loss': 12.4299, 'learning_rate': 0.000162, 'epoch': 1.73}\n",
      "{'loss': 12.431, 'learning_rate': 0.00016177777777777778, 'epoch': 1.74}\n",
      "{'loss': 12.4293, 'learning_rate': 0.00016155555555555557, 'epoch': 1.74}\n",
      "{'loss': 12.4293, 'learning_rate': 0.00016133333333333334, 'epoch': 1.75}\n",
      "{'loss': 12.4314, 'learning_rate': 0.0001611111111111111, 'epoch': 1.75}\n",
      "{'loss': 12.4311, 'learning_rate': 0.00016088888888888888, 'epoch': 1.76}\n",
      "{'loss': 12.431, 'learning_rate': 0.00016066666666666668, 'epoch': 1.77}\n",
      "{'loss': 12.4301, 'learning_rate': 0.00016044444444444445, 'epoch': 1.77}\n",
      "{'loss': 12.4303, 'learning_rate': 0.00016022222222222222, 'epoch': 1.78}\n",
      "{'loss': 12.4322, 'learning_rate': 0.00016, 'epoch': 1.79}\n",
      "{'loss': 12.4294, 'learning_rate': 0.00015977777777777778, 'epoch': 1.79}\n",
      "{'loss': 12.4298, 'learning_rate': 0.00015955555555555558, 'epoch': 1.8}\n",
      "{'loss': 12.4292, 'learning_rate': 0.00015933333333333332, 'epoch': 1.81}\n",
      "{'loss': 12.4296, 'learning_rate': 0.00015911111111111112, 'epoch': 1.81}\n",
      "{'loss': 12.4314, 'learning_rate': 0.0001588888888888889, 'epoch': 1.82}\n",
      "{'loss': 12.4322, 'learning_rate': 0.00015866666666666668, 'epoch': 1.82}\n",
      "{'loss': 12.4303, 'learning_rate': 0.00015844444444444445, 'epoch': 1.83}\n",
      "{'loss': 12.43, 'learning_rate': 0.00015822222222222222, 'epoch': 1.84}\n",
      "{'loss': 12.4304, 'learning_rate': 0.00015800000000000002, 'epoch': 1.84}\n",
      "{'loss': 12.4307, 'learning_rate': 0.0001577777777777778, 'epoch': 1.85}\n",
      "{'loss': 12.4334, 'learning_rate': 0.00015755555555555556, 'epoch': 1.86}\n",
      "{'loss': 12.4305, 'learning_rate': 0.00015733333333333333, 'epoch': 1.86}\n",
      "{'loss': 12.4295, 'learning_rate': 0.00015711111111111112, 'epoch': 1.87}\n",
      "{'loss': 12.4286, 'learning_rate': 0.00015688888888888892, 'epoch': 1.88}\n",
      "{'loss': 12.4297, 'learning_rate': 0.00015666666666666666, 'epoch': 1.88}\n",
      "{'loss': 12.429, 'learning_rate': 0.00015644444444444446, 'epoch': 1.89}\n",
      "{'loss': 12.4313, 'learning_rate': 0.00015622222222222223, 'epoch': 1.89}\n",
      "{'loss': 12.4296, 'learning_rate': 0.00015600000000000002, 'epoch': 1.9}\n",
      "{'loss': 12.4295, 'learning_rate': 0.00015577777777777777, 'epoch': 1.91}\n",
      "{'loss': 12.4288, 'learning_rate': 0.00015555555555555556, 'epoch': 1.91}\n",
      "{'loss': 12.4277, 'learning_rate': 0.00015533333333333333, 'epoch': 1.92}\n",
      "{'loss': 12.4297, 'learning_rate': 0.00015511111111111113, 'epoch': 1.93}\n",
      "{'loss': 12.4296, 'learning_rate': 0.0001548888888888889, 'epoch': 1.93}\n",
      "{'loss': 12.4304, 'learning_rate': 0.00015466666666666667, 'epoch': 1.94}\n",
      "{'loss': 12.4273, 'learning_rate': 0.00015444444444444446, 'epoch': 1.95}\n",
      "{'loss': 12.43, 'learning_rate': 0.00015422222222222223, 'epoch': 1.95}\n",
      "{'loss': 12.4293, 'learning_rate': 0.000154, 'epoch': 1.96}\n",
      "{'loss': 12.4301, 'learning_rate': 0.00015377777777777777, 'epoch': 1.96}\n",
      "{'loss': 12.428, 'learning_rate': 0.00015355555555555557, 'epoch': 1.97}\n",
      "{'loss': 12.4285, 'learning_rate': 0.00015333333333333334, 'epoch': 1.98}\n",
      "{'loss': 12.4293, 'learning_rate': 0.0001531111111111111, 'epoch': 1.98}\n",
      "{'loss': 12.432, 'learning_rate': 0.0001528888888888889, 'epoch': 1.99}\n",
      "{'loss': 12.4283, 'learning_rate': 0.00015266666666666667, 'epoch': 2.0}\n",
      "{'loss': 12.43, 'learning_rate': 0.00015244444444444447, 'epoch': 2.0}\n",
      "{'loss': 12.4277, 'learning_rate': 0.0001522222222222222, 'epoch': 2.01}\n",
      "{'loss': 12.4296, 'learning_rate': 0.000152, 'epoch': 2.02}\n",
      "{'loss': 12.4303, 'learning_rate': 0.00015177777777777778, 'epoch': 2.02}\n",
      "{'loss': 12.4291, 'learning_rate': 0.00015155555555555557, 'epoch': 2.03}\n",
      "{'loss': 12.4285, 'learning_rate': 0.00015133333333333334, 'epoch': 2.04}\n",
      "{'loss': 12.4268, 'learning_rate': 0.0001511111111111111, 'epoch': 2.04}\n",
      "{'loss': 12.4281, 'learning_rate': 0.0001508888888888889, 'epoch': 2.05}\n",
      "{'loss': 12.43, 'learning_rate': 0.00015066666666666668, 'epoch': 2.05}\n",
      "{'loss': 12.4285, 'learning_rate': 0.00015044444444444445, 'epoch': 2.06}\n",
      "{'loss': 12.4295, 'learning_rate': 0.00015022222222222222, 'epoch': 2.07}\n",
      "{'loss': 12.4278, 'learning_rate': 0.00015000000000000001, 'epoch': 2.07}\n",
      "{'loss': 12.4305, 'learning_rate': 0.00014977777777777778, 'epoch': 2.08}\n",
      "{'loss': 12.4283, 'learning_rate': 0.00014955555555555555, 'epoch': 2.09}\n",
      "{'loss': 12.4262, 'learning_rate': 0.00014933333333333335, 'epoch': 2.09}\n",
      "{'loss': 12.433, 'learning_rate': 0.00014911111111111112, 'epoch': 2.1}\n",
      "{'loss': 12.425, 'learning_rate': 0.0001488888888888889, 'epoch': 2.11}\n",
      "{'loss': 12.4292, 'learning_rate': 0.00014866666666666666, 'epoch': 2.11}\n",
      "{'loss': 12.4301, 'learning_rate': 0.00014844444444444445, 'epoch': 2.12}\n",
      "{'loss': 12.429, 'learning_rate': 0.00014822222222222225, 'epoch': 2.12}\n",
      "{'loss': 12.4294, 'learning_rate': 0.000148, 'epoch': 2.13}\n",
      "{'loss': 12.4284, 'learning_rate': 0.0001477777777777778, 'epoch': 2.14}\n",
      "{'loss': 12.4285, 'learning_rate': 0.00014755555555555556, 'epoch': 2.14}\n",
      "{'loss': 12.4277, 'learning_rate': 0.00014733333333333335, 'epoch': 2.15}\n",
      "{'loss': 12.429, 'learning_rate': 0.00014711111111111112, 'epoch': 2.16}\n",
      "{'loss': 12.4286, 'learning_rate': 0.0001468888888888889, 'epoch': 2.16}\n",
      "{'loss': 12.4298, 'learning_rate': 0.00014666666666666666, 'epoch': 2.17}\n",
      "{'loss': 12.4282, 'learning_rate': 0.00014644444444444446, 'epoch': 2.18}\n",
      "{'loss': 12.427, 'learning_rate': 0.00014622222222222223, 'epoch': 2.18}\n",
      "{'loss': 12.429, 'learning_rate': 0.000146, 'epoch': 2.19}\n",
      "{'loss': 12.4272, 'learning_rate': 0.0001457777777777778, 'epoch': 2.19}\n",
      "{'loss': 12.4296, 'learning_rate': 0.00014555555555555556, 'epoch': 2.2}\n",
      "{'loss': 12.4258, 'learning_rate': 0.00014533333333333333, 'epoch': 2.21}\n",
      "{'loss': 12.4296, 'learning_rate': 0.0001451111111111111, 'epoch': 2.21}\n",
      "{'loss': 12.4281, 'learning_rate': 0.0001448888888888889, 'epoch': 2.22}\n",
      "{'loss': 12.4262, 'learning_rate': 0.0001446666666666667, 'epoch': 2.23}\n",
      "{'loss': 12.4249, 'learning_rate': 0.00014444444444444444, 'epoch': 2.23}\n",
      "{'loss': 12.4295, 'learning_rate': 0.00014422222222222223, 'epoch': 2.24}\n",
      "{'loss': 12.4278, 'learning_rate': 0.000144, 'epoch': 2.25}\n",
      "{'loss': 12.4302, 'learning_rate': 0.0001437777777777778, 'epoch': 2.25}\n",
      "{'loss': 12.4267, 'learning_rate': 0.00014355555555555554, 'epoch': 2.26}\n",
      "{'loss': 12.4302, 'learning_rate': 0.00014333333333333334, 'epoch': 2.26}\n",
      "{'loss': 12.4266, 'learning_rate': 0.0001431111111111111, 'epoch': 2.27}\n",
      "{'loss': 12.4286, 'learning_rate': 0.0001428888888888889, 'epoch': 2.28}\n",
      "{'loss': 12.4273, 'learning_rate': 0.00014266666666666667, 'epoch': 2.28}\n",
      "{'loss': 12.4286, 'learning_rate': 0.00014244444444444444, 'epoch': 2.29}\n",
      "{'loss': 12.429, 'learning_rate': 0.00014222222222222224, 'epoch': 2.3}\n",
      "{'loss': 12.4279, 'learning_rate': 0.000142, 'epoch': 2.3}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00014177777777777778, 'epoch': 2.31}\n",
      "{'loss': 12.4291, 'learning_rate': 0.00014155555555555555, 'epoch': 2.32}\n",
      "{'loss': 12.4287, 'learning_rate': 0.00014133333333333334, 'epoch': 2.32}\n",
      "{'loss': 12.4265, 'learning_rate': 0.00014111111111111111, 'epoch': 2.33}\n",
      "{'loss': 12.4283, 'learning_rate': 0.00014088888888888888, 'epoch': 2.33}\n",
      "{'loss': 12.4291, 'learning_rate': 0.00014066666666666668, 'epoch': 2.34}\n",
      "{'loss': 12.4268, 'learning_rate': 0.00014044444444444445, 'epoch': 2.35}\n",
      "{'loss': 12.4284, 'learning_rate': 0.00014022222222222225, 'epoch': 2.35}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00014, 'epoch': 2.36}\n",
      "{'loss': 12.4297, 'learning_rate': 0.00013977777777777778, 'epoch': 2.37}\n",
      "{'loss': 12.4248, 'learning_rate': 0.00013955555555555558, 'epoch': 2.37}\n",
      "{'loss': 12.4248, 'learning_rate': 0.00013933333333333335, 'epoch': 2.38}\n",
      "{'loss': 12.4218, 'learning_rate': 0.00013911111111111112, 'epoch': 2.39}\n",
      "{'loss': 12.4268, 'learning_rate': 0.0001388888888888889, 'epoch': 2.39}\n",
      "{'loss': 12.4255, 'learning_rate': 0.00013866666666666669, 'epoch': 2.4}\n",
      "{'loss': 12.4269, 'learning_rate': 0.00013844444444444445, 'epoch': 2.41}\n",
      "{'loss': 12.4272, 'learning_rate': 0.00013822222222222222, 'epoch': 2.41}\n",
      "{'loss': 12.4265, 'learning_rate': 0.000138, 'epoch': 2.42}\n",
      "{'loss': 12.4265, 'learning_rate': 0.0001377777777777778, 'epoch': 2.42}\n",
      "{'loss': 12.4258, 'learning_rate': 0.00013755555555555556, 'epoch': 2.43}\n",
      "{'loss': 12.4249, 'learning_rate': 0.00013733333333333333, 'epoch': 2.44}\n",
      "{'loss': 12.4287, 'learning_rate': 0.00013711111111111113, 'epoch': 2.44}\n",
      "{'loss': 12.427, 'learning_rate': 0.0001368888888888889, 'epoch': 2.45}\n",
      "{'loss': 12.4224, 'learning_rate': 0.00013666666666666666, 'epoch': 2.46}\n",
      "{'loss': 12.4284, 'learning_rate': 0.00013644444444444443, 'epoch': 2.46}\n",
      "{'loss': 12.4283, 'learning_rate': 0.00013622222222222223, 'epoch': 2.47}\n",
      "{'loss': 12.4264, 'learning_rate': 0.00013600000000000003, 'epoch': 2.48}\n",
      "{'loss': 12.4297, 'learning_rate': 0.00013577777777777777, 'epoch': 2.48}\n",
      "{'loss': 12.4308, 'learning_rate': 0.00013555555555555556, 'epoch': 2.49}\n",
      "{'loss': 12.4283, 'learning_rate': 0.00013533333333333333, 'epoch': 2.49}\n",
      "{'loss': 12.4278, 'learning_rate': 0.00013511111111111113, 'epoch': 2.5}\n",
      "{'loss': 12.426, 'learning_rate': 0.0001348888888888889, 'epoch': 2.51}\n",
      "{'loss': 12.4246, 'learning_rate': 0.00013466666666666667, 'epoch': 2.51}\n",
      "{'loss': 12.4261, 'learning_rate': 0.00013444444444444447, 'epoch': 2.52}\n",
      "{'loss': 12.4254, 'learning_rate': 0.00013422222222222224, 'epoch': 2.53}\n",
      "{'loss': 12.4297, 'learning_rate': 0.000134, 'epoch': 2.53}\n",
      "{'loss': 12.4254, 'learning_rate': 0.00013377777777777777, 'epoch': 2.54}\n",
      "{'loss': 12.4274, 'learning_rate': 0.00013355555555555557, 'epoch': 2.55}\n",
      "{'loss': 12.4219, 'learning_rate': 0.00013333333333333334, 'epoch': 2.55}\n",
      "{'loss': 12.428, 'learning_rate': 0.0001331111111111111, 'epoch': 2.56}\n",
      "{'loss': 12.4291, 'learning_rate': 0.00013288888888888888, 'epoch': 2.56}\n",
      "{'loss': 12.425, 'learning_rate': 0.00013266666666666667, 'epoch': 2.57}\n",
      "{'loss': 12.4239, 'learning_rate': 0.00013244444444444447, 'epoch': 2.58}\n",
      "{'loss': 12.4262, 'learning_rate': 0.00013222222222222221, 'epoch': 2.58}\n",
      "{'loss': 12.4283, 'learning_rate': 0.000132, 'epoch': 2.59}\n",
      "{'loss': 12.4282, 'learning_rate': 0.00013177777777777778, 'epoch': 2.6}\n",
      "{'loss': 12.4274, 'learning_rate': 0.00013155555555555558, 'epoch': 2.6}\n",
      "{'loss': 12.4284, 'learning_rate': 0.00013133333333333332, 'epoch': 2.61}\n",
      "{'loss': 12.4271, 'learning_rate': 0.00013111111111111111, 'epoch': 2.62}\n",
      "{'loss': 12.4255, 'learning_rate': 0.0001308888888888889, 'epoch': 2.62}\n",
      "{'loss': 12.4249, 'learning_rate': 0.00013066666666666668, 'epoch': 2.63}\n",
      "{'loss': 12.4285, 'learning_rate': 0.00013044444444444445, 'epoch': 2.63}\n",
      "{'loss': 12.4243, 'learning_rate': 0.00013022222222222222, 'epoch': 2.64}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00013000000000000002, 'epoch': 2.65}\n",
      "{'loss': 12.4244, 'learning_rate': 0.00012977777777777779, 'epoch': 2.65}\n",
      "{'loss': 12.4267, 'learning_rate': 0.00012955555555555555, 'epoch': 2.66}\n",
      "{'loss': 12.4241, 'learning_rate': 0.00012933333333333332, 'epoch': 2.67}\n",
      "{'loss': 12.4256, 'learning_rate': 0.00012911111111111112, 'epoch': 2.67}\n",
      "{'loss': 12.426, 'learning_rate': 0.00012888888888888892, 'epoch': 2.68}\n",
      "{'loss': 12.4251, 'learning_rate': 0.00012866666666666666, 'epoch': 2.69}\n",
      "{'loss': 12.4259, 'learning_rate': 0.00012844444444444446, 'epoch': 2.69}\n",
      "{'loss': 12.4262, 'learning_rate': 0.00012822222222222222, 'epoch': 2.7}\n",
      "{'loss': 12.4248, 'learning_rate': 0.00012800000000000002, 'epoch': 2.7}\n",
      "{'loss': 12.4257, 'learning_rate': 0.00012777777777777776, 'epoch': 2.71}\n",
      "{'loss': 12.4276, 'learning_rate': 0.00012755555555555556, 'epoch': 2.72}\n",
      "{'loss': 12.4244, 'learning_rate': 0.00012733333333333336, 'epoch': 2.72}\n",
      "{'loss': 12.4258, 'learning_rate': 0.00012711111111111113, 'epoch': 2.73}\n",
      "{'loss': 12.4259, 'learning_rate': 0.0001268888888888889, 'epoch': 2.74}\n",
      "{'loss': 12.4282, 'learning_rate': 0.00012666666666666666, 'epoch': 2.74}\n",
      "{'loss': 12.4262, 'learning_rate': 0.00012644444444444446, 'epoch': 2.75}\n",
      "{'loss': 12.429, 'learning_rate': 0.00012622222222222223, 'epoch': 2.76}\n",
      "{'loss': 12.4254, 'learning_rate': 0.000126, 'epoch': 2.76}\n",
      "{'loss': 12.4255, 'learning_rate': 0.0001257777777777778, 'epoch': 2.77}\n",
      "{'loss': 12.4287, 'learning_rate': 0.00012555555555555557, 'epoch': 2.78}\n",
      "{'loss': 12.425, 'learning_rate': 0.00012533333333333334, 'epoch': 2.78}\n",
      "{'loss': 12.426, 'learning_rate': 0.0001251111111111111, 'epoch': 2.79}\n",
      "{'loss': 12.4242, 'learning_rate': 0.0001248888888888889, 'epoch': 2.79}\n",
      "{'loss': 12.4259, 'learning_rate': 0.00012466666666666667, 'epoch': 2.8}\n",
      "{'loss': 12.4244, 'learning_rate': 0.00012444444444444444, 'epoch': 2.81}\n",
      "{'loss': 12.4253, 'learning_rate': 0.0001242222222222222, 'epoch': 2.81}\n",
      "{'loss': 12.4267, 'learning_rate': 0.000124, 'epoch': 2.82}\n",
      "{'loss': 12.4236, 'learning_rate': 0.0001237777777777778, 'epoch': 2.83}\n",
      "{'loss': 12.4245, 'learning_rate': 0.00012355555555555557, 'epoch': 2.83}\n",
      "{'loss': 12.4228, 'learning_rate': 0.00012333333333333334, 'epoch': 2.84}\n",
      "{'loss': 12.4256, 'learning_rate': 0.0001231111111111111, 'epoch': 2.85}\n",
      "{'loss': 12.4235, 'learning_rate': 0.0001228888888888889, 'epoch': 2.85}\n",
      "{'loss': 12.4254, 'learning_rate': 0.00012266666666666668, 'epoch': 2.86}\n",
      "{'loss': 12.4264, 'learning_rate': 0.00012244444444444445, 'epoch': 2.86}\n",
      "{'loss': 12.4239, 'learning_rate': 0.00012222222222222224, 'epoch': 2.87}\n",
      "{'loss': 12.4216, 'learning_rate': 0.000122, 'epoch': 2.88}\n",
      "{'loss': 12.4242, 'learning_rate': 0.0001217777777777778, 'epoch': 2.88}\n",
      "{'loss': 12.428, 'learning_rate': 0.00012155555555555555, 'epoch': 2.89}\n",
      "{'loss': 12.4265, 'learning_rate': 0.00012133333333333335, 'epoch': 2.9}\n",
      "{'loss': 12.4242, 'learning_rate': 0.0001211111111111111, 'epoch': 2.9}\n",
      "{'loss': 12.4269, 'learning_rate': 0.0001208888888888889, 'epoch': 2.91}\n",
      "{'loss': 12.4243, 'learning_rate': 0.00012066666666666668, 'epoch': 2.92}\n",
      "{'loss': 12.4222, 'learning_rate': 0.00012044444444444445, 'epoch': 2.92}\n",
      "{'loss': 12.4243, 'learning_rate': 0.00012022222222222223, 'epoch': 2.93}\n",
      "{'loss': 12.4255, 'learning_rate': 0.00012, 'epoch': 2.93}\n",
      "{'loss': 12.4242, 'learning_rate': 0.00011977777777777779, 'epoch': 2.94}\n",
      "{'loss': 12.4262, 'learning_rate': 0.00011955555555555556, 'epoch': 2.95}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00011933333333333334, 'epoch': 2.95}\n",
      "{'loss': 12.4238, 'learning_rate': 0.00011911111111111111, 'epoch': 2.96}\n",
      "{'loss': 12.4229, 'learning_rate': 0.00011888888888888889, 'epoch': 2.97}\n",
      "{'loss': 12.4255, 'learning_rate': 0.00011866666666666669, 'epoch': 2.97}\n",
      "{'loss': 12.4242, 'learning_rate': 0.00011844444444444444, 'epoch': 2.98}\n",
      "{'loss': 12.4257, 'learning_rate': 0.00011822222222222224, 'epoch': 2.99}\n",
      "{'loss': 12.4247, 'learning_rate': 0.000118, 'epoch': 2.99}\n",
      "{'loss': 12.4261, 'learning_rate': 0.00011777777777777779, 'epoch': 3.0}\n",
      "{'loss': 12.4244, 'learning_rate': 0.00011755555555555555, 'epoch': 3.0}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00011733333333333334, 'epoch': 3.01}\n",
      "{'loss': 12.4228, 'learning_rate': 0.00011711111111111113, 'epoch': 3.02}\n",
      "{'loss': 12.4246, 'learning_rate': 0.0001168888888888889, 'epoch': 3.02}\n",
      "{'loss': 12.4287, 'learning_rate': 0.00011666666666666668, 'epoch': 3.03}\n",
      "{'loss': 12.425, 'learning_rate': 0.00011644444444444445, 'epoch': 3.04}\n",
      "{'loss': 12.4252, 'learning_rate': 0.00011622222222222223, 'epoch': 3.04}\n",
      "{'loss': 12.4237, 'learning_rate': 0.000116, 'epoch': 3.05}\n",
      "{'loss': 12.4225, 'learning_rate': 0.00011577777777777778, 'epoch': 3.06}\n",
      "{'loss': 12.4264, 'learning_rate': 0.00011555555555555555, 'epoch': 3.06}\n",
      "{'loss': 12.4248, 'learning_rate': 0.00011533333333333334, 'epoch': 3.07}\n",
      "{'loss': 12.4282, 'learning_rate': 0.00011511111111111112, 'epoch': 3.07}\n",
      "{'loss': 12.4259, 'learning_rate': 0.00011488888888888889, 'epoch': 3.08}\n",
      "{'loss': 12.4256, 'learning_rate': 0.00011466666666666667, 'epoch': 3.09}\n",
      "{'loss': 12.4227, 'learning_rate': 0.00011444444444444444, 'epoch': 3.09}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00011422222222222224, 'epoch': 3.1}\n",
      "{'loss': 12.4213, 'learning_rate': 0.00011399999999999999, 'epoch': 3.11}\n",
      "{'loss': 12.4256, 'learning_rate': 0.00011377777777777779, 'epoch': 3.11}\n",
      "{'loss': 12.4245, 'learning_rate': 0.00011355555555555557, 'epoch': 3.12}\n",
      "{'loss': 12.4255, 'learning_rate': 0.00011333333333333334, 'epoch': 3.13}\n",
      "{'loss': 12.4263, 'learning_rate': 0.00011311111111111112, 'epoch': 3.13}\n",
      "{'loss': 12.4234, 'learning_rate': 0.0001128888888888889, 'epoch': 3.14}\n",
      "{'loss': 12.4255, 'learning_rate': 0.00011266666666666668, 'epoch': 3.15}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00011244444444444445, 'epoch': 3.15}\n",
      "{'loss': 12.427, 'learning_rate': 0.00011222222222222223, 'epoch': 3.16}\n",
      "{'loss': 12.4215, 'learning_rate': 0.00011200000000000001, 'epoch': 3.16}\n",
      "{'loss': 12.4244, 'learning_rate': 0.00011177777777777778, 'epoch': 3.17}\n",
      "{'loss': 12.4213, 'learning_rate': 0.00011155555555555556, 'epoch': 3.18}\n",
      "{'loss': 12.4253, 'learning_rate': 0.00011133333333333333, 'epoch': 3.18}\n",
      "{'loss': 12.4267, 'learning_rate': 0.00011111111111111112, 'epoch': 3.19}\n",
      "{'loss': 12.422, 'learning_rate': 0.00011088888888888889, 'epoch': 3.2}\n",
      "{'loss': 12.4213, 'learning_rate': 0.00011066666666666667, 'epoch': 3.2}\n",
      "{'loss': 12.4226, 'learning_rate': 0.00011044444444444444, 'epoch': 3.21}\n",
      "{'loss': 12.4261, 'learning_rate': 0.00011022222222222222, 'epoch': 3.22}\n",
      "{'loss': 12.4266, 'learning_rate': 0.00011000000000000002, 'epoch': 3.22}\n",
      "{'loss': 12.4261, 'learning_rate': 0.00010977777777777777, 'epoch': 3.23}\n",
      "{'loss': 12.4236, 'learning_rate': 0.00010955555555555557, 'epoch': 3.23}\n",
      "{'loss': 12.4231, 'learning_rate': 0.00010933333333333333, 'epoch': 3.24}\n",
      "{'loss': 12.4249, 'learning_rate': 0.00010911111111111112, 'epoch': 3.25}\n",
      "{'loss': 12.421, 'learning_rate': 0.00010888888888888889, 'epoch': 3.25}\n",
      "{'loss': 12.4243, 'learning_rate': 0.00010866666666666667, 'epoch': 3.26}\n",
      "{'loss': 12.422, 'learning_rate': 0.00010844444444444446, 'epoch': 3.27}\n",
      "{'loss': 12.4213, 'learning_rate': 0.00010822222222222223, 'epoch': 3.27}\n",
      "{'loss': 12.423, 'learning_rate': 0.00010800000000000001, 'epoch': 3.28}\n",
      "{'loss': 12.4212, 'learning_rate': 0.00010777777777777778, 'epoch': 3.29}\n",
      "{'loss': 12.4234, 'learning_rate': 0.00010755555555555556, 'epoch': 3.29}\n",
      "{'loss': 12.4262, 'learning_rate': 0.00010733333333333333, 'epoch': 3.3}\n",
      "{'loss': 12.4231, 'learning_rate': 0.00010711111111111111, 'epoch': 3.3}\n",
      "{'loss': 12.4235, 'learning_rate': 0.00010688888888888891, 'epoch': 3.31}\n",
      "{'loss': 12.4245, 'learning_rate': 0.00010666666666666667, 'epoch': 3.32}\n",
      "{'loss': 12.4229, 'learning_rate': 0.00010644444444444446, 'epoch': 3.32}\n",
      "{'loss': 12.4219, 'learning_rate': 0.00010622222222222222, 'epoch': 3.33}\n",
      "{'loss': 12.4252, 'learning_rate': 0.00010600000000000002, 'epoch': 3.34}\n",
      "{'loss': 12.4225, 'learning_rate': 0.00010577777777777777, 'epoch': 3.34}\n",
      "{'loss': 12.4232, 'learning_rate': 0.00010555555555555557, 'epoch': 3.35}\n",
      "{'loss': 12.4242, 'learning_rate': 0.00010533333333333332, 'epoch': 3.36}\n",
      "{'loss': 12.4233, 'learning_rate': 0.00010511111111111112, 'epoch': 3.36}\n",
      "{'loss': 12.4204, 'learning_rate': 0.0001048888888888889, 'epoch': 3.37}\n",
      "{'loss': 12.4215, 'learning_rate': 0.00010466666666666667, 'epoch': 3.37}\n",
      "{'loss': 12.4247, 'learning_rate': 0.00010444444444444445, 'epoch': 3.38}\n",
      "{'loss': 12.4201, 'learning_rate': 0.00010422222222222222, 'epoch': 3.39}\n",
      "{'loss': 12.4242, 'learning_rate': 0.00010400000000000001, 'epoch': 3.39}\n",
      "{'loss': 12.4232, 'learning_rate': 0.00010377777777777778, 'epoch': 3.4}\n",
      "{'loss': 12.4253, 'learning_rate': 0.00010355555555555556, 'epoch': 3.41}\n",
      "{'loss': 12.4229, 'learning_rate': 0.00010333333333333334, 'epoch': 3.41}\n",
      "{'loss': 12.4234, 'learning_rate': 0.00010311111111111111, 'epoch': 3.42}\n",
      "{'loss': 12.4235, 'learning_rate': 0.0001028888888888889, 'epoch': 3.43}\n",
      "{'loss': 12.4242, 'learning_rate': 0.00010266666666666666, 'epoch': 3.43}\n",
      "{'loss': 12.4216, 'learning_rate': 0.00010244444444444446, 'epoch': 3.44}\n",
      "{'loss': 12.4242, 'learning_rate': 0.00010222222222222222, 'epoch': 3.44}\n",
      "{'loss': 12.4254, 'learning_rate': 0.00010200000000000001, 'epoch': 3.45}\n",
      "{'loss': 12.4231, 'learning_rate': 0.00010177777777777777, 'epoch': 3.46}\n",
      "{'loss': 12.424, 'learning_rate': 0.00010155555555555557, 'epoch': 3.46}\n",
      "{'loss': 12.4229, 'learning_rate': 0.00010133333333333335, 'epoch': 3.47}\n",
      "{'loss': 12.4234, 'learning_rate': 0.00010111111111111112, 'epoch': 3.48}\n",
      "{'loss': 12.4248, 'learning_rate': 0.0001008888888888889, 'epoch': 3.48}\n",
      "{'loss': 12.4185, 'learning_rate': 0.00010066666666666667, 'epoch': 3.49}\n",
      "{'loss': 12.4254, 'learning_rate': 0.00010044444444444445, 'epoch': 3.5}\n",
      "{'loss': 12.424, 'learning_rate': 0.00010022222222222222, 'epoch': 3.5}\n",
      "{'loss': 12.425, 'learning_rate': 0.0001, 'epoch': 3.51}\n",
      "{'loss': 12.4244, 'learning_rate': 9.977777777777779e-05, 'epoch': 3.52}\n",
      "{'loss': 12.4245, 'learning_rate': 9.955555555555556e-05, 'epoch': 3.52}\n",
      "{'loss': 12.426, 'learning_rate': 9.933333333333334e-05, 'epoch': 3.53}\n",
      "{'loss': 12.4217, 'learning_rate': 9.911111111111112e-05, 'epoch': 3.53}\n",
      "{'loss': 12.4218, 'learning_rate': 9.888888888888889e-05, 'epoch': 3.54}\n",
      "{'loss': 12.4222, 'learning_rate': 9.866666666666668e-05, 'epoch': 3.55}\n",
      "{'loss': 12.4232, 'learning_rate': 9.844444444444444e-05, 'epoch': 3.55}\n",
      "{'loss': 12.4239, 'learning_rate': 9.822222222222223e-05, 'epoch': 3.56}\n",
      "{'loss': 12.4193, 'learning_rate': 9.8e-05, 'epoch': 3.57}\n",
      "{'loss': 12.4215, 'learning_rate': 9.777777777777778e-05, 'epoch': 3.57}\n",
      "{'loss': 12.4227, 'learning_rate': 9.755555555555555e-05, 'epoch': 3.58}\n",
      "{'loss': 12.4218, 'learning_rate': 9.733333333333335e-05, 'epoch': 3.59}\n",
      "{'loss': 12.4257, 'learning_rate': 9.711111111111111e-05, 'epoch': 3.59}\n",
      "{'loss': 12.422, 'learning_rate': 9.68888888888889e-05, 'epoch': 3.6}\n",
      "{'loss': 12.4256, 'learning_rate': 9.666666666666667e-05, 'epoch': 3.6}\n",
      "{'loss': 12.4206, 'learning_rate': 9.644444444444445e-05, 'epoch': 3.61}\n",
      "{'loss': 12.4256, 'learning_rate': 9.622222222222222e-05, 'epoch': 3.62}\n",
      "{'loss': 12.4259, 'learning_rate': 9.6e-05, 'epoch': 3.62}\n",
      "{'loss': 12.4242, 'learning_rate': 9.577777777777777e-05, 'epoch': 3.63}\n",
      "{'loss': 12.427, 'learning_rate': 9.555555555555557e-05, 'epoch': 3.64}\n",
      "{'loss': 12.4229, 'learning_rate': 9.533333333333334e-05, 'epoch': 3.64}\n",
      "{'loss': 12.4231, 'learning_rate': 9.511111111111112e-05, 'epoch': 3.65}\n",
      "{'loss': 12.4224, 'learning_rate': 9.488888888888889e-05, 'epoch': 3.66}\n",
      "{'loss': 12.4224, 'learning_rate': 9.466666666666667e-05, 'epoch': 3.66}\n",
      "{'loss': 12.4235, 'learning_rate': 9.444444444444444e-05, 'epoch': 3.67}\n",
      "{'loss': 12.4222, 'learning_rate': 9.422222222222223e-05, 'epoch': 3.67}\n",
      "{'loss': 12.4233, 'learning_rate': 9.4e-05, 'epoch': 3.68}\n",
      "{'loss': 12.4235, 'learning_rate': 9.377777777777779e-05, 'epoch': 3.69}\n",
      "{'loss': 12.4234, 'learning_rate': 9.355555555555556e-05, 'epoch': 3.69}\n",
      "{'loss': 12.4234, 'learning_rate': 9.333333333333334e-05, 'epoch': 3.7}\n",
      "{'loss': 12.424, 'learning_rate': 9.311111111111111e-05, 'epoch': 3.71}\n",
      "{'loss': 12.4251, 'learning_rate': 9.28888888888889e-05, 'epoch': 3.71}\n",
      "{'loss': 12.4248, 'learning_rate': 9.266666666666666e-05, 'epoch': 3.72}\n",
      "{'loss': 12.4269, 'learning_rate': 9.244444444444445e-05, 'epoch': 3.73}\n",
      "{'loss': 12.4201, 'learning_rate': 9.222222222222223e-05, 'epoch': 3.73}\n",
      "{'loss': 12.423, 'learning_rate': 9.200000000000001e-05, 'epoch': 3.74}\n",
      "{'loss': 12.4233, 'learning_rate': 9.177777777777778e-05, 'epoch': 3.74}\n",
      "{'loss': 12.4204, 'learning_rate': 9.155555555555557e-05, 'epoch': 3.75}\n",
      "{'loss': 12.4234, 'learning_rate': 9.133333333333334e-05, 'epoch': 3.76}\n",
      "{'loss': 12.4217, 'learning_rate': 9.111111111111112e-05, 'epoch': 3.76}\n",
      "{'loss': 12.4259, 'learning_rate': 9.088888888888889e-05, 'epoch': 3.77}\n",
      "{'loss': 12.4233, 'learning_rate': 9.066666666666667e-05, 'epoch': 3.78}\n",
      "{'loss': 12.4231, 'learning_rate': 9.044444444444445e-05, 'epoch': 3.78}\n",
      "{'loss': 12.4239, 'learning_rate': 9.022222222222224e-05, 'epoch': 3.79}\n",
      "{'loss': 12.4204, 'learning_rate': 9e-05, 'epoch': 3.8}\n",
      "{'loss': 12.4241, 'learning_rate': 8.977777777777779e-05, 'epoch': 3.8}\n",
      "{'loss': 12.4217, 'learning_rate': 8.955555555555556e-05, 'epoch': 3.81}\n",
      "{'loss': 12.4213, 'learning_rate': 8.933333333333334e-05, 'epoch': 3.81}\n",
      "{'loss': 12.4242, 'learning_rate': 8.911111111111111e-05, 'epoch': 3.82}\n",
      "{'loss': 12.4236, 'learning_rate': 8.888888888888889e-05, 'epoch': 3.83}\n",
      "{'loss': 12.426, 'learning_rate': 8.866666666666668e-05, 'epoch': 3.83}\n",
      "{'loss': 12.4187, 'learning_rate': 8.844444444444445e-05, 'epoch': 3.84}\n",
      "{'loss': 12.4212, 'learning_rate': 8.822222222222223e-05, 'epoch': 3.85}\n",
      "{'loss': 12.4214, 'learning_rate': 8.800000000000001e-05, 'epoch': 3.85}\n",
      "{'loss': 12.4242, 'learning_rate': 8.777777777777778e-05, 'epoch': 3.86}\n",
      "{'loss': 12.422, 'learning_rate': 8.755555555555556e-05, 'epoch': 3.87}\n",
      "{'loss': 12.4203, 'learning_rate': 8.733333333333333e-05, 'epoch': 3.87}\n",
      "{'loss': 12.4237, 'learning_rate': 8.711111111111112e-05, 'epoch': 3.88}\n",
      "{'loss': 12.4205, 'learning_rate': 8.68888888888889e-05, 'epoch': 3.89}\n",
      "{'loss': 12.4198, 'learning_rate': 8.666666666666667e-05, 'epoch': 3.89}\n",
      "{'loss': 12.4227, 'learning_rate': 8.644444444444445e-05, 'epoch': 3.9}\n",
      "{'loss': 12.4207, 'learning_rate': 8.622222222222222e-05, 'epoch': 3.9}\n",
      "{'loss': 12.4227, 'learning_rate': 8.6e-05, 'epoch': 3.91}\n",
      "{'loss': 12.423, 'learning_rate': 8.577777777777777e-05, 'epoch': 3.92}\n",
      "{'loss': 12.425, 'learning_rate': 8.555555555555556e-05, 'epoch': 3.92}\n",
      "{'loss': 12.4212, 'learning_rate': 8.533333333333334e-05, 'epoch': 3.93}\n",
      "{'loss': 12.4233, 'learning_rate': 8.511111111111112e-05, 'epoch': 3.94}\n",
      "{'loss': 12.4182, 'learning_rate': 8.488888888888889e-05, 'epoch': 3.94}\n",
      "{'loss': 12.4203, 'learning_rate': 8.466666666666667e-05, 'epoch': 3.95}\n",
      "{'loss': 12.422, 'learning_rate': 8.444444444444444e-05, 'epoch': 3.96}\n",
      "{'loss': 12.4229, 'learning_rate': 8.422222222222223e-05, 'epoch': 3.96}\n",
      "{'loss': 12.4221, 'learning_rate': 8.4e-05, 'epoch': 3.97}\n",
      "{'loss': 12.4194, 'learning_rate': 8.377777777777778e-05, 'epoch': 3.97}\n",
      "{'loss': 12.4178, 'learning_rate': 8.355555555555556e-05, 'epoch': 3.98}\n",
      "{'loss': 12.4234, 'learning_rate': 8.333333333333334e-05, 'epoch': 3.99}\n",
      "{'loss': 12.4214, 'learning_rate': 8.311111111111111e-05, 'epoch': 3.99}\n",
      "{'loss': 12.4197, 'learning_rate': 8.28888888888889e-05, 'epoch': 4.0}\n",
      "{'loss': 12.4208, 'learning_rate': 8.266666666666667e-05, 'epoch': 4.01}\n",
      "{'loss': 12.4222, 'learning_rate': 8.244444444444445e-05, 'epoch': 4.01}\n",
      "{'loss': 12.4225, 'learning_rate': 8.222222222222222e-05, 'epoch': 4.02}\n",
      "{'loss': 12.4246, 'learning_rate': 8.2e-05, 'epoch': 4.03}\n",
      "{'loss': 12.4192, 'learning_rate': 8.177777777777778e-05, 'epoch': 4.03}\n",
      "{'loss': 12.4214, 'learning_rate': 8.155555555555557e-05, 'epoch': 4.04}\n",
      "{'loss': 12.4194, 'learning_rate': 8.133333333333334e-05, 'epoch': 4.04}\n",
      "{'loss': 12.4227, 'learning_rate': 8.111111111111112e-05, 'epoch': 4.05}\n",
      "{'loss': 12.4259, 'learning_rate': 8.088888888888889e-05, 'epoch': 4.06}\n",
      "{'loss': 12.4213, 'learning_rate': 8.066666666666667e-05, 'epoch': 4.06}\n",
      "{'loss': 12.4261, 'learning_rate': 8.044444444444444e-05, 'epoch': 4.07}\n",
      "{'loss': 12.4257, 'learning_rate': 8.022222222222222e-05, 'epoch': 4.08}\n",
      "{'loss': 12.421, 'learning_rate': 8e-05, 'epoch': 4.08}\n",
      "{'loss': 12.418, 'learning_rate': 7.977777777777779e-05, 'epoch': 4.09}\n",
      "{'loss': 12.4244, 'learning_rate': 7.955555555555556e-05, 'epoch': 4.1}\n",
      "{'loss': 12.419, 'learning_rate': 7.933333333333334e-05, 'epoch': 4.1}\n",
      "{'loss': 12.4212, 'learning_rate': 7.911111111111111e-05, 'epoch': 4.11}\n",
      "{'loss': 12.4219, 'learning_rate': 7.88888888888889e-05, 'epoch': 4.11}\n",
      "{'loss': 12.4207, 'learning_rate': 7.866666666666666e-05, 'epoch': 4.12}\n",
      "{'loss': 12.4251, 'learning_rate': 7.844444444444446e-05, 'epoch': 4.13}\n",
      "{'loss': 12.4213, 'learning_rate': 7.822222222222223e-05, 'epoch': 4.13}\n",
      "{'loss': 12.4235, 'learning_rate': 7.800000000000001e-05, 'epoch': 4.14}\n",
      "{'loss': 12.4247, 'learning_rate': 7.777777777777778e-05, 'epoch': 4.15}\n",
      "{'loss': 12.4199, 'learning_rate': 7.755555555555556e-05, 'epoch': 4.15}\n",
      "{'loss': 12.4178, 'learning_rate': 7.733333333333333e-05, 'epoch': 4.16}\n",
      "{'loss': 12.4234, 'learning_rate': 7.711111111111112e-05, 'epoch': 4.17}\n",
      "{'loss': 12.421, 'learning_rate': 7.688888888888889e-05, 'epoch': 4.17}\n",
      "{'loss': 12.4225, 'learning_rate': 7.666666666666667e-05, 'epoch': 4.18}\n",
      "{'loss': 12.4202, 'learning_rate': 7.644444444444445e-05, 'epoch': 4.19}\n",
      "{'loss': 12.4177, 'learning_rate': 7.622222222222223e-05, 'epoch': 4.19}\n",
      "{'loss': 12.4236, 'learning_rate': 7.6e-05, 'epoch': 4.2}\n",
      "{'loss': 12.4189, 'learning_rate': 7.577777777777779e-05, 'epoch': 4.2}\n",
      "{'loss': 12.4214, 'learning_rate': 7.555555555555556e-05, 'epoch': 4.21}\n",
      "{'loss': 12.4239, 'learning_rate': 7.533333333333334e-05, 'epoch': 4.22}\n",
      "{'loss': 12.4249, 'learning_rate': 7.511111111111111e-05, 'epoch': 4.22}\n",
      "{'loss': 12.4161, 'learning_rate': 7.488888888888889e-05, 'epoch': 4.23}\n",
      "{'loss': 12.4222, 'learning_rate': 7.466666666666667e-05, 'epoch': 4.24}\n",
      "{'loss': 12.4221, 'learning_rate': 7.444444444444444e-05, 'epoch': 4.24}\n",
      "{'loss': 12.4227, 'learning_rate': 7.422222222222223e-05, 'epoch': 4.25}\n",
      "{'loss': 12.4209, 'learning_rate': 7.4e-05, 'epoch': 4.26}\n",
      "{'loss': 12.4207, 'learning_rate': 7.377777777777778e-05, 'epoch': 4.26}\n",
      "{'loss': 12.4217, 'learning_rate': 7.355555555555556e-05, 'epoch': 4.27}\n",
      "{'loss': 12.4191, 'learning_rate': 7.333333333333333e-05, 'epoch': 4.27}\n",
      "{'loss': 12.4192, 'learning_rate': 7.311111111111111e-05, 'epoch': 4.28}\n",
      "{'loss': 12.4231, 'learning_rate': 7.28888888888889e-05, 'epoch': 4.29}\n",
      "{'loss': 12.4198, 'learning_rate': 7.266666666666667e-05, 'epoch': 4.29}\n",
      "{'loss': 12.4228, 'learning_rate': 7.244444444444445e-05, 'epoch': 4.3}\n",
      "{'loss': 12.4215, 'learning_rate': 7.222222222222222e-05, 'epoch': 4.31}\n",
      "{'loss': 12.4218, 'learning_rate': 7.2e-05, 'epoch': 4.31}\n",
      "{'loss': 12.4244, 'learning_rate': 7.177777777777777e-05, 'epoch': 4.32}\n",
      "{'loss': 12.4178, 'learning_rate': 7.155555555555555e-05, 'epoch': 4.33}\n",
      "{'loss': 12.4221, 'learning_rate': 7.133333333333334e-05, 'epoch': 4.33}\n",
      "{'loss': 12.4213, 'learning_rate': 7.111111111111112e-05, 'epoch': 4.34}\n",
      "{'loss': 12.4214, 'learning_rate': 7.088888888888889e-05, 'epoch': 4.34}\n",
      "{'loss': 12.4225, 'learning_rate': 7.066666666666667e-05, 'epoch': 4.35}\n",
      "{'loss': 12.4212, 'learning_rate': 7.044444444444444e-05, 'epoch': 4.36}\n",
      "{'loss': 12.4206, 'learning_rate': 7.022222222222222e-05, 'epoch': 4.36}\n",
      "{'loss': 12.4217, 'learning_rate': 7e-05, 'epoch': 4.37}\n",
      "{'loss': 12.4178, 'learning_rate': 6.977777777777779e-05, 'epoch': 4.38}\n",
      "{'loss': 12.423, 'learning_rate': 6.955555555555556e-05, 'epoch': 4.38}\n",
      "{'loss': 12.4219, 'learning_rate': 6.933333333333334e-05, 'epoch': 4.39}\n",
      "{'loss': 12.4215, 'learning_rate': 6.911111111111111e-05, 'epoch': 4.4}\n",
      "{'loss': 12.4192, 'learning_rate': 6.88888888888889e-05, 'epoch': 4.4}\n",
      "{'loss': 12.4209, 'learning_rate': 6.866666666666666e-05, 'epoch': 4.41}\n",
      "{'loss': 12.4186, 'learning_rate': 6.844444444444445e-05, 'epoch': 4.41}\n",
      "{'loss': 12.42, 'learning_rate': 6.822222222222222e-05, 'epoch': 4.42}\n",
      "{'loss': 12.4209, 'learning_rate': 6.800000000000001e-05, 'epoch': 4.43}\n",
      "{'loss': 12.421, 'learning_rate': 6.777777777777778e-05, 'epoch': 4.43}\n",
      "{'loss': 12.4176, 'learning_rate': 6.755555555555557e-05, 'epoch': 4.44}\n",
      "{'loss': 12.4196, 'learning_rate': 6.733333333333333e-05, 'epoch': 4.45}\n",
      "{'loss': 12.42, 'learning_rate': 6.711111111111112e-05, 'epoch': 4.45}\n",
      "{'loss': 12.4212, 'learning_rate': 6.688888888888889e-05, 'epoch': 4.46}\n",
      "{'loss': 12.4233, 'learning_rate': 6.666666666666667e-05, 'epoch': 4.47}\n",
      "{'loss': 12.4197, 'learning_rate': 6.644444444444444e-05, 'epoch': 4.47}\n",
      "{'loss': 12.4221, 'learning_rate': 6.622222222222224e-05, 'epoch': 4.48}\n",
      "{'loss': 12.4209, 'learning_rate': 6.6e-05, 'epoch': 4.48}\n",
      "{'loss': 12.4202, 'learning_rate': 6.577777777777779e-05, 'epoch': 4.49}\n",
      "{'loss': 12.4227, 'learning_rate': 6.555555555555556e-05, 'epoch': 4.5}\n",
      "{'loss': 12.4187, 'learning_rate': 6.533333333333334e-05, 'epoch': 4.5}\n",
      "{'loss': 12.4221, 'learning_rate': 6.511111111111111e-05, 'epoch': 4.51}\n",
      "{'loss': 12.4241, 'learning_rate': 6.488888888888889e-05, 'epoch': 4.52}\n",
      "{'loss': 12.4213, 'learning_rate': 6.466666666666666e-05, 'epoch': 4.52}\n",
      "{'loss': 12.4241, 'learning_rate': 6.444444444444446e-05, 'epoch': 4.53}\n",
      "{'loss': 12.4235, 'learning_rate': 6.422222222222223e-05, 'epoch': 4.54}\n",
      "{'loss': 12.4191, 'learning_rate': 6.400000000000001e-05, 'epoch': 4.54}\n",
      "{'loss': 12.4206, 'learning_rate': 6.377777777777778e-05, 'epoch': 4.55}\n",
      "{'loss': 12.4208, 'learning_rate': 6.355555555555556e-05, 'epoch': 4.56}\n",
      "{'loss': 12.4201, 'learning_rate': 6.333333333333333e-05, 'epoch': 4.56}\n",
      "{'loss': 12.4231, 'learning_rate': 6.311111111111112e-05, 'epoch': 4.57}\n",
      "{'loss': 12.4222, 'learning_rate': 6.28888888888889e-05, 'epoch': 4.57}\n",
      "{'loss': 12.4204, 'learning_rate': 6.266666666666667e-05, 'epoch': 4.58}\n",
      "{'loss': 12.4208, 'learning_rate': 6.244444444444445e-05, 'epoch': 4.59}\n",
      "{'loss': 12.4237, 'learning_rate': 6.222222222222222e-05, 'epoch': 4.59}\n",
      "{'loss': 12.4232, 'learning_rate': 6.2e-05, 'epoch': 4.6}\n",
      "{'loss': 12.4233, 'learning_rate': 6.177777777777779e-05, 'epoch': 4.61}\n",
      "{'loss': 12.4196, 'learning_rate': 6.155555555555555e-05, 'epoch': 4.61}\n",
      "{'loss': 12.4241, 'learning_rate': 6.133333333333334e-05, 'epoch': 4.62}\n",
      "{'loss': 12.4171, 'learning_rate': 6.111111111111112e-05, 'epoch': 4.63}\n",
      "{'loss': 12.4214, 'learning_rate': 6.08888888888889e-05, 'epoch': 4.63}\n",
      "{'loss': 12.421, 'learning_rate': 6.066666666666667e-05, 'epoch': 4.64}\n",
      "{'loss': 12.422, 'learning_rate': 6.044444444444445e-05, 'epoch': 4.64}\n",
      "{'loss': 12.42, 'learning_rate': 6.0222222222222225e-05, 'epoch': 4.65}\n",
      "{'loss': 12.421, 'learning_rate': 6e-05, 'epoch': 4.66}\n",
      "{'loss': 12.4225, 'learning_rate': 5.977777777777778e-05, 'epoch': 4.66}\n",
      "{'loss': 12.4217, 'learning_rate': 5.9555555555555554e-05, 'epoch': 4.67}\n",
      "{'loss': 12.4181, 'learning_rate': 5.9333333333333343e-05, 'epoch': 4.68}\n",
      "{'loss': 12.4229, 'learning_rate': 5.911111111111112e-05, 'epoch': 4.68}\n",
      "{'loss': 12.4222, 'learning_rate': 5.8888888888888896e-05, 'epoch': 4.69}\n",
      "{'loss': 12.4188, 'learning_rate': 5.866666666666667e-05, 'epoch': 4.7}\n",
      "{'loss': 12.4215, 'learning_rate': 5.844444444444445e-05, 'epoch': 4.7}\n",
      "{'loss': 12.4212, 'learning_rate': 5.8222222222222224e-05, 'epoch': 4.71}\n",
      "{'loss': 12.4229, 'learning_rate': 5.8e-05, 'epoch': 4.71}\n",
      "{'loss': 12.4231, 'learning_rate': 5.7777777777777776e-05, 'epoch': 4.72}\n",
      "{'loss': 12.4213, 'learning_rate': 5.755555555555556e-05, 'epoch': 4.73}\n",
      "{'loss': 12.4218, 'learning_rate': 5.7333333333333336e-05, 'epoch': 4.73}\n",
      "{'loss': 12.4211, 'learning_rate': 5.711111111111112e-05, 'epoch': 4.74}\n",
      "{'loss': 12.4243, 'learning_rate': 5.6888888888888895e-05, 'epoch': 4.75}\n",
      "{'loss': 12.4224, 'learning_rate': 5.666666666666667e-05, 'epoch': 4.75}\n",
      "{'loss': 12.4171, 'learning_rate': 5.644444444444445e-05, 'epoch': 4.76}\n",
      "{'loss': 12.421, 'learning_rate': 5.622222222222222e-05, 'epoch': 4.77}\n",
      "{'loss': 12.4229, 'learning_rate': 5.6000000000000006e-05, 'epoch': 4.77}\n",
      "{'loss': 12.4224, 'learning_rate': 5.577777777777778e-05, 'epoch': 4.78}\n",
      "{'loss': 12.4209, 'learning_rate': 5.555555555555556e-05, 'epoch': 4.78}\n",
      "{'loss': 12.4189, 'learning_rate': 5.5333333333333334e-05, 'epoch': 4.79}\n",
      "{'loss': 12.4199, 'learning_rate': 5.511111111111111e-05, 'epoch': 4.8}\n",
      "{'loss': 12.42, 'learning_rate': 5.488888888888889e-05, 'epoch': 4.8}\n",
      "{'loss': 12.4222, 'learning_rate': 5.466666666666666e-05, 'epoch': 4.81}\n",
      "{'loss': 12.42, 'learning_rate': 5.4444444444444446e-05, 'epoch': 4.82}\n",
      "{'loss': 12.4208, 'learning_rate': 5.422222222222223e-05, 'epoch': 4.82}\n",
      "{'loss': 12.4177, 'learning_rate': 5.4000000000000005e-05, 'epoch': 4.83}\n",
      "{'loss': 12.4233, 'learning_rate': 5.377777777777778e-05, 'epoch': 4.84}\n",
      "{'loss': 12.4204, 'learning_rate': 5.355555555555556e-05, 'epoch': 4.84}\n",
      "{'loss': 12.4223, 'learning_rate': 5.333333333333333e-05, 'epoch': 4.85}\n",
      "{'loss': 12.4206, 'learning_rate': 5.311111111111111e-05, 'epoch': 4.85}\n",
      "{'loss': 12.4226, 'learning_rate': 5.2888888888888885e-05, 'epoch': 4.86}\n",
      "{'loss': 12.4212, 'learning_rate': 5.266666666666666e-05, 'epoch': 4.87}\n",
      "{'loss': 12.4183, 'learning_rate': 5.244444444444445e-05, 'epoch': 4.87}\n",
      "{'loss': 12.421, 'learning_rate': 5.222222222222223e-05, 'epoch': 4.88}\n",
      "{'loss': 12.4213, 'learning_rate': 5.2000000000000004e-05, 'epoch': 4.89}\n",
      "{'loss': 12.4211, 'learning_rate': 5.177777777777778e-05, 'epoch': 4.89}\n",
      "{'loss': 12.419, 'learning_rate': 5.1555555555555556e-05, 'epoch': 4.9}\n",
      "{'loss': 12.4227, 'learning_rate': 5.133333333333333e-05, 'epoch': 4.91}\n",
      "{'loss': 12.4209, 'learning_rate': 5.111111111111111e-05, 'epoch': 4.91}\n",
      "{'loss': 12.4209, 'learning_rate': 5.0888888888888884e-05, 'epoch': 4.92}\n",
      "{'loss': 12.4237, 'learning_rate': 5.0666666666666674e-05, 'epoch': 4.93}\n",
      "{'loss': 12.4221, 'learning_rate': 5.044444444444445e-05, 'epoch': 4.93}\n",
      "{'loss': 12.4147, 'learning_rate': 5.0222222222222226e-05, 'epoch': 4.94}\n",
      "{'loss': 12.4215, 'learning_rate': 5e-05, 'epoch': 4.94}\n",
      "{'loss': 12.4185, 'learning_rate': 4.977777777777778e-05, 'epoch': 4.95}\n",
      "{'loss': 12.4184, 'learning_rate': 4.955555555555556e-05, 'epoch': 4.96}\n",
      "{'loss': 12.4197, 'learning_rate': 4.933333333333334e-05, 'epoch': 4.96}\n",
      "{'loss': 12.4239, 'learning_rate': 4.9111111111111114e-05, 'epoch': 4.97}\n",
      "{'loss': 12.4218, 'learning_rate': 4.888888888888889e-05, 'epoch': 4.98}\n",
      "{'loss': 12.4247, 'learning_rate': 4.866666666666667e-05, 'epoch': 4.98}\n",
      "{'loss': 12.4166, 'learning_rate': 4.844444444444445e-05, 'epoch': 4.99}\n",
      "{'loss': 12.4209, 'learning_rate': 4.8222222222222225e-05, 'epoch': 5.0}\n",
      "{'loss': 12.4224, 'learning_rate': 4.8e-05, 'epoch': 5.0}\n",
      "{'loss': 12.4178, 'learning_rate': 4.7777777777777784e-05, 'epoch': 5.01}\n",
      "{'loss': 12.4172, 'learning_rate': 4.755555555555556e-05, 'epoch': 5.01}\n",
      "{'loss': 12.422, 'learning_rate': 4.7333333333333336e-05, 'epoch': 5.02}\n",
      "{'loss': 12.4133, 'learning_rate': 4.711111111111111e-05, 'epoch': 5.03}\n",
      "{'loss': 12.4176, 'learning_rate': 4.6888888888888895e-05, 'epoch': 5.03}\n",
      "{'loss': 12.4224, 'learning_rate': 4.666666666666667e-05, 'epoch': 5.04}\n",
      "{'loss': 12.4206, 'learning_rate': 4.644444444444445e-05, 'epoch': 5.05}\n",
      "{'loss': 12.4204, 'learning_rate': 4.6222222222222224e-05, 'epoch': 5.05}\n",
      "{'loss': 12.4215, 'learning_rate': 4.600000000000001e-05, 'epoch': 5.06}\n",
      "{'loss': 12.4199, 'learning_rate': 4.577777777777778e-05, 'epoch': 5.07}\n",
      "{'loss': 12.4237, 'learning_rate': 4.555555555555556e-05, 'epoch': 5.07}\n",
      "{'loss': 12.4221, 'learning_rate': 4.5333333333333335e-05, 'epoch': 5.08}\n",
      "{'loss': 12.419, 'learning_rate': 4.511111111111112e-05, 'epoch': 5.08}\n",
      "{'loss': 12.4202, 'learning_rate': 4.4888888888888894e-05, 'epoch': 5.09}\n",
      "{'loss': 12.4227, 'learning_rate': 4.466666666666667e-05, 'epoch': 5.1}\n",
      "{'loss': 12.4192, 'learning_rate': 4.4444444444444447e-05, 'epoch': 5.1}\n",
      "{'loss': 12.4216, 'learning_rate': 4.422222222222222e-05, 'epoch': 5.11}\n",
      "{'loss': 12.4217, 'learning_rate': 4.4000000000000006e-05, 'epoch': 5.12}\n",
      "{'loss': 12.4216, 'learning_rate': 4.377777777777778e-05, 'epoch': 5.12}\n",
      "{'loss': 12.4206, 'learning_rate': 4.355555555555556e-05, 'epoch': 5.13}\n",
      "{'loss': 12.4168, 'learning_rate': 4.3333333333333334e-05, 'epoch': 5.14}\n",
      "{'loss': 12.4239, 'learning_rate': 4.311111111111111e-05, 'epoch': 5.14}\n",
      "{'loss': 12.423, 'learning_rate': 4.2888888888888886e-05, 'epoch': 5.15}\n",
      "{'loss': 12.4209, 'learning_rate': 4.266666666666667e-05, 'epoch': 5.15}\n",
      "{'loss': 12.422, 'learning_rate': 4.2444444444444445e-05, 'epoch': 5.16}\n",
      "{'loss': 12.4198, 'learning_rate': 4.222222222222222e-05, 'epoch': 5.17}\n",
      "{'loss': 12.4233, 'learning_rate': 4.2e-05, 'epoch': 5.17}\n",
      "{'loss': 12.4237, 'learning_rate': 4.177777777777778e-05, 'epoch': 5.18}\n",
      "{'loss': 12.4223, 'learning_rate': 4.155555555555556e-05, 'epoch': 5.19}\n",
      "{'loss': 12.4195, 'learning_rate': 4.133333333333333e-05, 'epoch': 5.19}\n",
      "{'loss': 12.4195, 'learning_rate': 4.111111111111111e-05, 'epoch': 5.2}\n",
      "{'loss': 12.4168, 'learning_rate': 4.088888888888889e-05, 'epoch': 5.21}\n",
      "{'loss': 12.4228, 'learning_rate': 4.066666666666667e-05, 'epoch': 5.21}\n",
      "{'loss': 12.4218, 'learning_rate': 4.0444444444444444e-05, 'epoch': 5.22}\n",
      "{'loss': 12.4203, 'learning_rate': 4.022222222222222e-05, 'epoch': 5.22}\n",
      "{'loss': 12.4222, 'learning_rate': 4e-05, 'epoch': 5.23}\n",
      "{'loss': 12.417, 'learning_rate': 3.977777777777778e-05, 'epoch': 5.24}\n",
      "{'loss': 12.4215, 'learning_rate': 3.9555555555555556e-05, 'epoch': 5.24}\n",
      "{'loss': 12.4174, 'learning_rate': 3.933333333333333e-05, 'epoch': 5.25}\n",
      "{'loss': 12.4211, 'learning_rate': 3.9111111111111115e-05, 'epoch': 5.26}\n",
      "{'loss': 12.4189, 'learning_rate': 3.888888888888889e-05, 'epoch': 5.26}\n",
      "{'loss': 12.425, 'learning_rate': 3.866666666666667e-05, 'epoch': 5.27}\n",
      "{'loss': 12.4191, 'learning_rate': 3.844444444444444e-05, 'epoch': 5.28}\n",
      "{'loss': 12.4168, 'learning_rate': 3.8222222222222226e-05, 'epoch': 5.28}\n",
      "{'loss': 12.4189, 'learning_rate': 3.8e-05, 'epoch': 5.29}\n",
      "{'loss': 12.4185, 'learning_rate': 3.777777777777778e-05, 'epoch': 5.3}\n",
      "{'loss': 12.4171, 'learning_rate': 3.7555555555555554e-05, 'epoch': 5.3}\n",
      "{'loss': 12.4246, 'learning_rate': 3.733333333333334e-05, 'epoch': 5.31}\n",
      "{'loss': 12.4171, 'learning_rate': 3.7111111111111113e-05, 'epoch': 5.31}\n",
      "{'loss': 12.4195, 'learning_rate': 3.688888888888889e-05, 'epoch': 5.32}\n",
      "{'loss': 12.4196, 'learning_rate': 3.6666666666666666e-05, 'epoch': 5.33}\n",
      "{'loss': 12.42, 'learning_rate': 3.644444444444445e-05, 'epoch': 5.33}\n",
      "{'loss': 12.4235, 'learning_rate': 3.6222222222222225e-05, 'epoch': 5.34}\n",
      "{'loss': 12.4251, 'learning_rate': 3.6e-05, 'epoch': 5.35}\n",
      "{'loss': 12.4212, 'learning_rate': 3.577777777777778e-05, 'epoch': 5.35}\n",
      "{'loss': 12.4218, 'learning_rate': 3.555555555555556e-05, 'epoch': 5.36}\n",
      "{'loss': 12.4224, 'learning_rate': 3.5333333333333336e-05, 'epoch': 5.37}\n",
      "{'loss': 12.4185, 'learning_rate': 3.511111111111111e-05, 'epoch': 5.37}\n",
      "{'loss': 12.4192, 'learning_rate': 3.4888888888888895e-05, 'epoch': 5.38}\n",
      "{'loss': 12.4254, 'learning_rate': 3.466666666666667e-05, 'epoch': 5.38}\n",
      "{'loss': 12.4183, 'learning_rate': 3.444444444444445e-05, 'epoch': 5.39}\n",
      "{'loss': 12.4215, 'learning_rate': 3.4222222222222224e-05, 'epoch': 5.4}\n",
      "{'loss': 12.4222, 'learning_rate': 3.4000000000000007e-05, 'epoch': 5.4}\n",
      "{'loss': 12.4213, 'learning_rate': 3.377777777777778e-05, 'epoch': 5.41}\n",
      "{'loss': 12.4196, 'learning_rate': 3.355555555555556e-05, 'epoch': 5.42}\n",
      "{'loss': 12.4174, 'learning_rate': 3.3333333333333335e-05, 'epoch': 5.42}\n",
      "{'loss': 12.4208, 'learning_rate': 3.311111111111112e-05, 'epoch': 5.43}\n",
      "{'loss': 12.4195, 'learning_rate': 3.2888888888888894e-05, 'epoch': 5.44}\n",
      "{'loss': 12.4237, 'learning_rate': 3.266666666666667e-05, 'epoch': 5.44}\n",
      "{'loss': 12.4187, 'learning_rate': 3.2444444444444446e-05, 'epoch': 5.45}\n",
      "{'loss': 12.4195, 'learning_rate': 3.222222222222223e-05, 'epoch': 5.45}\n",
      "{'loss': 12.4174, 'learning_rate': 3.2000000000000005e-05, 'epoch': 5.46}\n",
      "{'loss': 12.4205, 'learning_rate': 3.177777777777778e-05, 'epoch': 5.47}\n",
      "{'loss': 12.417, 'learning_rate': 3.155555555555556e-05, 'epoch': 5.47}\n",
      "{'loss': 12.4194, 'learning_rate': 3.1333333333333334e-05, 'epoch': 5.48}\n",
      "{'loss': 12.422, 'learning_rate': 3.111111111111111e-05, 'epoch': 5.49}\n",
      "{'loss': 12.4172, 'learning_rate': 3.088888888888889e-05, 'epoch': 5.49}\n",
      "{'loss': 12.4187, 'learning_rate': 3.066666666666667e-05, 'epoch': 5.5}\n",
      "{'loss': 12.4205, 'learning_rate': 3.044444444444445e-05, 'epoch': 5.51}\n",
      "{'loss': 12.4205, 'learning_rate': 3.0222222222222225e-05, 'epoch': 5.51}\n",
      "{'loss': 12.4213, 'learning_rate': 3e-05, 'epoch': 5.52}\n",
      "{'loss': 12.4194, 'learning_rate': 2.9777777777777777e-05, 'epoch': 5.52}\n",
      "{'loss': 12.4162, 'learning_rate': 2.955555555555556e-05, 'epoch': 5.53}\n",
      "{'loss': 12.4188, 'learning_rate': 2.9333333333333336e-05, 'epoch': 5.54}\n",
      "{'loss': 12.4198, 'learning_rate': 2.9111111111111112e-05, 'epoch': 5.54}\n",
      "{'loss': 12.42, 'learning_rate': 2.8888888888888888e-05, 'epoch': 5.55}\n",
      "{'loss': 12.4193, 'learning_rate': 2.8666666666666668e-05, 'epoch': 5.56}\n",
      "{'loss': 12.419, 'learning_rate': 2.8444444444444447e-05, 'epoch': 5.56}\n",
      "{'loss': 12.4172, 'learning_rate': 2.8222222222222223e-05, 'epoch': 5.57}\n",
      "{'loss': 12.4233, 'learning_rate': 2.8000000000000003e-05, 'epoch': 5.58}\n",
      "{'loss': 12.4177, 'learning_rate': 2.777777777777778e-05, 'epoch': 5.58}\n",
      "{'loss': 12.4154, 'learning_rate': 2.7555555555555555e-05, 'epoch': 5.59}\n",
      "{'loss': 12.4182, 'learning_rate': 2.733333333333333e-05, 'epoch': 5.59}\n",
      "{'loss': 12.4178, 'learning_rate': 2.7111111111111114e-05, 'epoch': 5.6}\n",
      "{'loss': 12.417, 'learning_rate': 2.688888888888889e-05, 'epoch': 5.61}\n",
      "{'loss': 12.422, 'learning_rate': 2.6666666666666667e-05, 'epoch': 5.61}\n",
      "{'loss': 12.4212, 'learning_rate': 2.6444444444444443e-05, 'epoch': 5.62}\n",
      "{'loss': 12.4185, 'learning_rate': 2.6222222222222226e-05, 'epoch': 5.63}\n",
      "{'loss': 12.4184, 'learning_rate': 2.6000000000000002e-05, 'epoch': 5.63}\n",
      "{'loss': 12.4195, 'learning_rate': 2.5777777777777778e-05, 'epoch': 5.64}\n",
      "{'loss': 12.4225, 'learning_rate': 2.5555555555555554e-05, 'epoch': 5.65}\n",
      "{'loss': 12.4229, 'learning_rate': 2.5333333333333337e-05, 'epoch': 5.65}\n",
      "{'loss': 12.4205, 'learning_rate': 2.5111111111111113e-05, 'epoch': 5.66}\n",
      "{'loss': 12.4175, 'learning_rate': 2.488888888888889e-05, 'epoch': 5.67}\n",
      "{'loss': 12.4234, 'learning_rate': 2.466666666666667e-05, 'epoch': 5.67}\n",
      "{'loss': 12.419, 'learning_rate': 2.4444444444444445e-05, 'epoch': 5.68}\n",
      "{'loss': 12.423, 'learning_rate': 2.4222222222222224e-05, 'epoch': 5.68}\n",
      "{'loss': 12.4216, 'learning_rate': 2.4e-05, 'epoch': 5.69}\n",
      "{'loss': 12.4189, 'learning_rate': 2.377777777777778e-05, 'epoch': 5.7}\n",
      "{'loss': 12.4233, 'learning_rate': 2.3555555555555556e-05, 'epoch': 5.7}\n",
      "{'loss': 12.4202, 'learning_rate': 2.3333333333333336e-05, 'epoch': 5.71}\n",
      "{'loss': 12.42, 'learning_rate': 2.3111111111111112e-05, 'epoch': 5.72}\n",
      "{'loss': 12.4183, 'learning_rate': 2.288888888888889e-05, 'epoch': 5.72}\n",
      "{'loss': 12.4216, 'learning_rate': 2.2666666666666668e-05, 'epoch': 5.73}\n",
      "{'loss': 12.4167, 'learning_rate': 2.2444444444444447e-05, 'epoch': 5.74}\n",
      "{'loss': 12.4213, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.74}\n",
      "{'loss': 12.4223, 'learning_rate': 2.2000000000000003e-05, 'epoch': 5.75}\n",
      "{'loss': 12.4241, 'learning_rate': 2.177777777777778e-05, 'epoch': 5.75}\n",
      "{'loss': 12.4198, 'learning_rate': 2.1555555555555555e-05, 'epoch': 5.76}\n",
      "{'loss': 12.4229, 'learning_rate': 2.1333333333333335e-05, 'epoch': 5.77}\n",
      "{'loss': 12.4198, 'learning_rate': 2.111111111111111e-05, 'epoch': 5.77}\n",
      "{'loss': 12.4206, 'learning_rate': 2.088888888888889e-05, 'epoch': 5.78}\n",
      "{'loss': 12.4209, 'learning_rate': 2.0666666666666666e-05, 'epoch': 5.79}\n",
      "{'loss': 12.4199, 'learning_rate': 2.0444444444444446e-05, 'epoch': 5.79}\n",
      "{'loss': 12.4216, 'learning_rate': 2.0222222222222222e-05, 'epoch': 5.8}\n",
      "{'loss': 12.4148, 'learning_rate': 2e-05, 'epoch': 5.81}\n",
      "{'loss': 12.4212, 'learning_rate': 1.9777777777777778e-05, 'epoch': 5.81}\n",
      "{'loss': 12.422, 'learning_rate': 1.9555555555555557e-05, 'epoch': 5.82}\n",
      "{'loss': 12.4192, 'learning_rate': 1.9333333333333333e-05, 'epoch': 5.82}\n",
      "{'loss': 12.4187, 'learning_rate': 1.9111111111111113e-05, 'epoch': 5.83}\n",
      "{'loss': 12.4237, 'learning_rate': 1.888888888888889e-05, 'epoch': 5.84}\n",
      "{'loss': 12.4154, 'learning_rate': 1.866666666666667e-05, 'epoch': 5.84}\n",
      "{'loss': 12.4165, 'learning_rate': 1.8444444444444445e-05, 'epoch': 5.85}\n",
      "{'loss': 12.4199, 'learning_rate': 1.8222222222222224e-05, 'epoch': 5.86}\n",
      "{'loss': 12.4208, 'learning_rate': 1.8e-05, 'epoch': 5.86}\n",
      "{'loss': 12.4189, 'learning_rate': 1.777777777777778e-05, 'epoch': 5.87}\n",
      "{'loss': 12.4223, 'learning_rate': 1.7555555555555556e-05, 'epoch': 5.88}\n",
      "{'loss': 12.4208, 'learning_rate': 1.7333333333333336e-05, 'epoch': 5.88}\n",
      "{'loss': 12.4181, 'learning_rate': 1.7111111111111112e-05, 'epoch': 5.89}\n",
      "{'loss': 12.422, 'learning_rate': 1.688888888888889e-05, 'epoch': 5.89}\n",
      "{'loss': 12.4183, 'learning_rate': 1.6666666666666667e-05, 'epoch': 5.9}\n",
      "{'loss': 12.4184, 'learning_rate': 1.6444444444444447e-05, 'epoch': 5.91}\n",
      "{'loss': 12.4179, 'learning_rate': 1.6222222222222223e-05, 'epoch': 5.91}\n",
      "{'loss': 12.4201, 'learning_rate': 1.6000000000000003e-05, 'epoch': 5.92}\n",
      "{'loss': 12.4196, 'learning_rate': 1.577777777777778e-05, 'epoch': 5.93}\n",
      "{'loss': 12.4182, 'learning_rate': 1.5555555555555555e-05, 'epoch': 5.93}\n",
      "{'loss': 12.4208, 'learning_rate': 1.5333333333333334e-05, 'epoch': 5.94}\n",
      "{'loss': 12.4196, 'learning_rate': 1.5111111111111112e-05, 'epoch': 5.95}\n",
      "{'loss': 12.4195, 'learning_rate': 1.4888888888888888e-05, 'epoch': 5.95}\n",
      "{'loss': 12.4197, 'learning_rate': 1.4666666666666668e-05, 'epoch': 5.96}\n",
      "{'loss': 12.4181, 'learning_rate': 1.4444444444444444e-05, 'epoch': 5.96}\n",
      "{'loss': 12.4224, 'learning_rate': 1.4222222222222224e-05, 'epoch': 5.97}\n",
      "{'loss': 12.4209, 'learning_rate': 1.4000000000000001e-05, 'epoch': 5.98}\n",
      "{'loss': 12.4199, 'learning_rate': 1.3777777777777778e-05, 'epoch': 5.98}\n",
      "{'loss': 12.4231, 'learning_rate': 1.3555555555555557e-05, 'epoch': 5.99}\n",
      "{'loss': 12.4233, 'learning_rate': 1.3333333333333333e-05, 'epoch': 6.0}\n",
      "{'loss': 12.4187, 'learning_rate': 1.3111111111111113e-05, 'epoch': 6.0}\n",
      "{'loss': 12.4168, 'learning_rate': 1.2888888888888889e-05, 'epoch': 6.01}\n",
      "{'loss': 12.4227, 'learning_rate': 1.2666666666666668e-05, 'epoch': 6.02}\n",
      "{'loss': 12.4217, 'learning_rate': 1.2444444444444445e-05, 'epoch': 6.02}\n",
      "{'loss': 12.4204, 'learning_rate': 1.2222222222222222e-05, 'epoch': 6.03}\n",
      "{'loss': 12.4195, 'learning_rate': 1.2e-05, 'epoch': 6.04}\n",
      "{'loss': 12.4231, 'learning_rate': 1.1777777777777778e-05, 'epoch': 6.04}\n",
      "{'loss': 12.4187, 'learning_rate': 1.1555555555555556e-05, 'epoch': 6.05}\n",
      "{'loss': 12.4209, 'learning_rate': 1.1333333333333334e-05, 'epoch': 6.05}\n",
      "{'loss': 12.4211, 'learning_rate': 1.1111111111111112e-05, 'epoch': 6.06}\n",
      "{'loss': 12.4204, 'learning_rate': 1.088888888888889e-05, 'epoch': 6.07}\n",
      "{'loss': 12.4212, 'learning_rate': 1.0666666666666667e-05, 'epoch': 6.07}\n",
      "{'loss': 12.4235, 'learning_rate': 1.0444444444444445e-05, 'epoch': 6.08}\n",
      "{'loss': 12.4214, 'learning_rate': 1.0222222222222223e-05, 'epoch': 6.09}\n",
      "{'loss': 12.4211, 'learning_rate': 1e-05, 'epoch': 6.09}\n",
      "{'loss': 12.4198, 'learning_rate': 9.777777777777779e-06, 'epoch': 6.1}\n",
      "{'loss': 12.4183, 'learning_rate': 9.555555555555556e-06, 'epoch': 6.11}\n",
      "{'loss': 12.4192, 'learning_rate': 9.333333333333334e-06, 'epoch': 6.11}\n",
      "{'loss': 12.4229, 'learning_rate': 9.111111111111112e-06, 'epoch': 6.12}\n",
      "{'loss': 12.4208, 'learning_rate': 8.88888888888889e-06, 'epoch': 6.12}\n",
      "{'loss': 12.4248, 'learning_rate': 8.666666666666668e-06, 'epoch': 6.13}\n",
      "{'loss': 12.4182, 'learning_rate': 8.444444444444446e-06, 'epoch': 6.14}\n",
      "{'loss': 12.4216, 'learning_rate': 8.222222222222223e-06, 'epoch': 6.14}\n",
      "{'loss': 12.4192, 'learning_rate': 8.000000000000001e-06, 'epoch': 6.15}\n",
      "{'loss': 12.4217, 'learning_rate': 7.777777777777777e-06, 'epoch': 6.16}\n",
      "{'loss': 12.4236, 'learning_rate': 7.555555555555556e-06, 'epoch': 6.16}\n",
      "{'loss': 12.4167, 'learning_rate': 7.333333333333334e-06, 'epoch': 6.17}\n",
      "{'loss': 12.416, 'learning_rate': 7.111111111111112e-06, 'epoch': 6.18}\n",
      "{'loss': 12.4203, 'learning_rate': 6.888888888888889e-06, 'epoch': 6.18}\n",
      "{'loss': 12.4188, 'learning_rate': 6.666666666666667e-06, 'epoch': 6.19}\n",
      "{'loss': 12.4248, 'learning_rate': 6.4444444444444445e-06, 'epoch': 6.19}\n",
      "{'loss': 12.4239, 'learning_rate': 6.222222222222222e-06, 'epoch': 6.2}\n",
      "{'loss': 12.4154, 'learning_rate': 6e-06, 'epoch': 6.21}\n",
      "{'loss': 12.4176, 'learning_rate': 5.777777777777778e-06, 'epoch': 6.21}\n",
      "{'loss': 12.4164, 'learning_rate': 5.555555555555556e-06, 'epoch': 6.22}\n",
      "{'loss': 12.4209, 'learning_rate': 5.333333333333334e-06, 'epoch': 6.23}\n",
      "{'loss': 12.4198, 'learning_rate': 5.1111111111111115e-06, 'epoch': 6.23}\n",
      "{'loss': 12.4191, 'learning_rate': 4.888888888888889e-06, 'epoch': 6.24}\n",
      "{'loss': 12.4181, 'learning_rate': 4.666666666666667e-06, 'epoch': 6.25}\n",
      "{'loss': 12.4235, 'learning_rate': 4.444444444444445e-06, 'epoch': 6.25}\n",
      "{'loss': 12.4205, 'learning_rate': 4.222222222222223e-06, 'epoch': 6.26}\n",
      "{'loss': 12.4189, 'learning_rate': 4.000000000000001e-06, 'epoch': 6.26}\n",
      "{'loss': 12.4206, 'learning_rate': 3.777777777777778e-06, 'epoch': 6.27}\n",
      "{'loss': 12.4215, 'learning_rate': 3.555555555555556e-06, 'epoch': 6.28}\n",
      "{'loss': 12.4206, 'learning_rate': 3.3333333333333333e-06, 'epoch': 6.28}\n",
      "{'loss': 12.4173, 'learning_rate': 3.111111111111111e-06, 'epoch': 6.29}\n",
      "{'loss': 12.4144, 'learning_rate': 2.888888888888889e-06, 'epoch': 6.3}\n",
      "{'loss': 12.4193, 'learning_rate': 2.666666666666667e-06, 'epoch': 6.3}\n",
      "{'loss': 12.4221, 'learning_rate': 2.4444444444444447e-06, 'epoch': 6.31}\n",
      "{'loss': 12.4199, 'learning_rate': 2.2222222222222225e-06, 'epoch': 6.32}\n",
      "{'loss': 12.4204, 'learning_rate': 2.0000000000000003e-06, 'epoch': 6.32}\n",
      "{'loss': 12.423, 'learning_rate': 1.777777777777778e-06, 'epoch': 6.33}\n",
      "{'loss': 12.4201, 'learning_rate': 1.5555555555555556e-06, 'epoch': 6.33}\n",
      "{'loss': 12.4185, 'learning_rate': 1.3333333333333334e-06, 'epoch': 6.34}\n",
      "{'loss': 12.4221, 'learning_rate': 1.1111111111111112e-06, 'epoch': 6.35}\n",
      "{'loss': 12.421, 'learning_rate': 8.88888888888889e-07, 'epoch': 6.35}\n",
      "{'loss': 12.4211, 'learning_rate': 6.666666666666667e-07, 'epoch': 6.36}\n",
      "{'loss': 12.4231, 'learning_rate': 4.444444444444445e-07, 'epoch': 6.37}\n",
      "{'loss': 12.4204, 'learning_rate': 2.2222222222222224e-07, 'epoch': 6.37}\n",
      "{'loss': 12.4171, 'learning_rate': 0.0, 'epoch': 6.38}\n",
      "{'train_runtime': 301.4398, 'train_samples_per_second': 53.079, 'train_steps_per_second': 3.317, 'train_loss': 12.425732020378113, 'epoch': 6.38}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=12.425732020378113, metrics={'train_runtime': 301.4398, 'train_samples_per_second': 53.079, 'train_steps_per_second': 3.317, 'train_loss': 12.425732020378113, 'epoch': 6.38})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Training\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data['train'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=2, # number of example per batch\n",
    "        gradient_accumulation_steps=8, # number of batch to see before applying gradient update -> per_device_train_batch_size * gradient_accumulation_steps = number of example seen before an update\n",
    "        warmup_steps=100, # starts with a very low lr and linearly goes up to the target lr every steps\n",
    "        max_steps=1000, # number of steps after which the traning stops\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir='outputs'\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Push model to hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.push_to_hub(user/repoid,\n",
    "                  use_auth_token=True,\n",
    "                  commit_message=\"basic training\",\n",
    "                  private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"username/repoid\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, device_map=\"auto\") # load_in_8bits=True,\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 86753,   7508,    386,  20038,   1002,    426, 108045,    530,   9810,\n",
      "          14062,    632,  35847,    982,  11953,     29,    210]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexis Strappazzon\\Documents\\code\\python\\HF_bloomz_test\\.venv\\lib\\site-packages\\transformers\\generation\\utils.py:1445: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " “Training models with PEFT and LoRA is cool” ->:  ['humor', 'modeling'], 'modeling', 'perception', 'strategies'], 'modeling'], 'modeling-institutes', 'perception'], 'perception', 'strateg\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('“Training models with PEFT and LoRA is cool” ->: ', return_tensors='pt')\n",
    "print(batch)\n",
    "model.config.use_cache = True # silence the warnings. Please re-enable for inference!\n",
    "model.eval()\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=50)\n",
    "    \n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
