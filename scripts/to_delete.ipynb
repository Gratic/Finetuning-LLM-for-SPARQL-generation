{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "import pandas as pd\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"../outputs/batch_run/faith_template5/execution/Mistral-7B-Instruct-v0.2_rv16-ld0.05-bs1-p0-nta1-e3-template_engpeft-t0.2-topp0.95_executed.parquet.gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].translated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].linked_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].target_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "print(f\"{tokenizer.unk_token=}\")\n",
    "print(f\"{tokenizer.pad_token=}\")\n",
    "print(f\"{tokenizer.unk_token_id=}\")\n",
    "print(f\"{tokenizer.pad_token_id=}\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "print(f\"{tokenizer.unk_token=}\")\n",
    "print(f\"{tokenizer.pad_token=}\")\n",
    "print(f\"{tokenizer.unk_token_id=}\")\n",
    "print(f\"{tokenizer.pad_token_id=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize prompt and make files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"../outputs/batch_run/democracy_template8/execution/Mistral-7B-Instruct-v0.2_rv32-ld0.05-bs1-p0-nta1-e3-template_engpeft-t0.2-topp0.95_executed.parquet.gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handpicked_data = df.loc[(~df['execution'].str.startswith(\"exception:\")) & (~df['execution'].isnull()) & (df['execution'].map(len) > 0)].iloc[[1, 2, 3, 206, 207]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tokenizer.batch_encode_plus([f\"`sparql\\n{i}`\" for i in handpicked_data['translated_prompt'].to_list()], add_special_tokens=False, padding='longest', return_tensors='np')['input_ids'].tolist()\n",
    "labels = tokenizer.batch_encode_plus([f\"`sparql\\n{i}`\" for i in handpicked_data['target_template'].to_list()], add_special_tokens=False, padding='longest', return_tensors='np')['input_ids'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"preds\": preds,\n",
    "    \"labels\": labels,\n",
    "}\n",
    "\n",
    "path = Path(\"sft_peft_compute_metrics_execute_ok.json\")\n",
    "path.write_text(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "\n",
    "\n",
    "df = load_dataset(\"../outputs/batch_run/lezgo/execution/Mistral-7B-Instruct-v0.2_rv16-ld0-bs1-p0-nta0-e3-template_engpeft-t0.2-topp0.95_executed.parquet.gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.head()\n",
    "\n",
    "path = Path(\"evaluation_test.json\")\n",
    "path.write_text(df_out.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gold = json.loads(Path(\"../outputs/batch_run/lezgo/preprocessed_gold.json\").read_text())\n",
    "df_gold = pd.read_json(data_gold['df_gold_eval'])\n",
    "df_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_out = df_gold.head()\n",
    "\n",
    "path = Path(\"evaluation_test_gold.json\")\n",
    "path.write_text(df_gold_out.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"../datasets/final_queries_v1.7.json\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = dataset[2549:2553]\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_v2 = df_out.reset_index(drop=True)\n",
    "df_out_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"templatize_test.json\")\n",
    "path.write_text(df_out_v2.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the split: 118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic_input</th>\n",
       "      <th>templated_input</th>\n",
       "      <th>target_raw</th>\n",
       "      <th>target_template</th>\n",
       "      <th>gold_execution</th>\n",
       "      <th>gold_executed_query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>[\"Find artists represented in the Swedish Nati...</td>\n",
       "      <td>[\"Find artists represented in the Swedish Nati...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?itemDescription ?Swed...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>[\"Find all places with coordinates near Papa S...</td>\n",
       "      <td>[\"Find the places located near Papa Stour isla...</td>\n",
       "      <td>SELECT ?place ?placeLabel ?location (GROUP_CON...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'place': {'type': 'uri', 'value': 'http://ww...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>[\"Write a query to find the number of occurren...</td>\n",
       "      <td>[\"Find the number of unique awards won by indi...</td>\n",
       "      <td>SELECT (COUNT(?item) AS ?count) ?otheraward ?o...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'otheraward': {'type': 'uri', 'value': 'http...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>[\"Find all items on Wikidata that have a linke...</td>\n",
       "      <td>[\"Find entities in Wikidata that have a linked...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>[\"Write a SparQL query to retrieve the name, l...</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the name, o...</td>\n",
       "      <td>SELECT ?doctor ?doctorLabel ?ordinal ?performe...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'doctor': {'type': 'uri', 'value': 'http://w...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             basic_input  \\\n",
       "index                                                      \n",
       "1789   [\"Find artists represented in the Swedish Nati...   \n",
       "2338   [\"Find all places with coordinates near Papa S...   \n",
       "2779   [\"Write a query to find the number of occurren...   \n",
       "1624   [\"Find all items on Wikidata that have a linke...   \n",
       "662    [\"Write a SparQL query to retrieve the name, l...   \n",
       "\n",
       "                                         templated_input  \\\n",
       "index                                                      \n",
       "1789   [\"Find artists represented in the Swedish Nati...   \n",
       "2338   [\"Find the places located near Papa Stour isla...   \n",
       "2779   [\"Find the number of unique awards won by indi...   \n",
       "1624   [\"Find entities in Wikidata that have a linked...   \n",
       "662    [\"Write a SparQL query to retrieve the name, o...   \n",
       "\n",
       "                                              target_raw  \\\n",
       "index                                                      \n",
       "1789   SELECT ?item ?itemLabel ?itemDescription ?Swed...   \n",
       "2338   SELECT ?place ?placeLabel ?location (GROUP_CON...   \n",
       "2779   SELECT (COUNT(?item) AS ?count) ?otheraward ?o...   \n",
       "1624   SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...   \n",
       "662    SELECT ?doctor ?doctorLabel ?ordinal ?performe...   \n",
       "\n",
       "                                         target_template  \\\n",
       "index                                                      \n",
       "1789   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2338   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2779   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "1624   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "662    PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "\n",
       "                                          gold_execution  \\\n",
       "index                                                      \n",
       "1789   [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "2338   [{'place': {'type': 'uri', 'value': 'http://ww...   \n",
       "2779   [{'otheraward': {'type': 'uri', 'value': 'http...   \n",
       "1624   [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "662    [{'doctor': {'type': 'uri', 'value': 'http://w...   \n",
       "\n",
       "                                     gold_executed_query  \n",
       "index                                                     \n",
       "1789   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "2338   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "2779   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "1624   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "662    PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_dataset(\"../outputs/dataset_pipeline/final_fq17_with_limit_10/final_fq17-split_valid.pkl\")\n",
    "print(f\"Size of the split: {len(df)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row index: 1957\n",
      "basic_input\n",
      "\"Write a SparQL query to find distinct bases named after Union soldiers and retrieve their labels in English.\"\n",
      "\"Create a SparQL query that returns the distinct bases with the P31 type of 'Military base' and P17 type of 'Civil War' and their namesake's label as a Union soldier.\"\n",
      "\n",
      "templated_input\n",
      "\"Write a SparQL query to find military bases in the United States that are named after soldiers who served in the Union Army during the American Civil War.\"\n",
      "\"Create a SparQL query to retrieve information about military bases in the US with names derived from Union Army soldiers.\"\n",
      "\"Design a SparQL query for identifying military bases in the United States, which have been named after Union Army soldiers.\"\n",
      "\n",
      "target_raw\n",
      "SELECT DISTINCT ?base ?baseLabel ?namesake ?namesakeLabel WHERE {\n",
      "?base wdt:P31 wd:Q245016.\n",
      "?base wdt:P17 wd:Q30.\n",
      "?base wdt:P138 ?namesake.\n",
      "?namesake wdt:P241 wd:Q1752901.\n",
      "SERVICE wikibase:label {\n",
      "bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" .\n",
      "}\n",
      "}\n",
      "\n",
      "target_template\n",
      "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?base ?baseLabel ?namesake ?namesakeLabel WHERE {\n",
      "?base wdt:[property:instance of] wd:[entity:military base].\n",
      "?base wdt:[property:country] wd:[entity:United States of America].\n",
      "?base wdt:[property:named after] ?namesake.\n",
      "?namesake wdt:[property:military branch] wd:[entity:Union Army].\n",
      "SERVICE wikibase:label {\n",
      "bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" .\n",
      "}\n",
      "}\n",
      "\n",
      "gold_execution\n",
      "[{'namesake': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q355452'}, 'base': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q17033233'}, 'baseLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Philip H. Sheridan Reserve Center'}, 'namesakeLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Philip Sheridan'}}, {'namesake': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q435517'}, 'base': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q5027230'}, 'baseLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Camp Hancock'}, 'namesakeLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Winfield Scott Hancock'}}, {'namesake': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q297121'}, 'base': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q509549'}, 'baseLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Fort George G. Meade'}, 'namesakeLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'George Meade'}}, {'namesake': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q6290296'}, 'base': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1018681'}, 'baseLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Fort Sill'}, 'namesakeLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Joshua W. Sill'}}, {'namesake': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q740330'}, 'base': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q115198302'}, 'baseLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Fort Thomas'}, 'namesakeLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'George Henry Thomas'}}]\n",
      "\n",
      "gold_executed_query\n",
      "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?base ?baseLabel ?namesake ?namesakeLabel WHERE {\n",
      "?base wdt:P31 wd:Q245016.\n",
      "?base wdt:P17 wd:Q30.\n",
      "?base wdt:P138 ?namesake.\n",
      "?namesake wdt:P241 wd:Q1752901.\n",
      "SERVICE wikibase:label {\n",
      "bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" .\n",
      "}\n",
      "}\n",
      "LIMIT 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entry = df.sample()\n",
    "print(f\"Row index: {entry.index.item()}\")\n",
    "for c in df.columns:\n",
    "    print(c)\n",
    "    data = entry[c].item()\n",
    "    if isinstance(data, str):\n",
    "        print(data)\n",
    "    elif isinstance(data, list):\n",
    "        for i in data:\n",
    "            print(i)\n",
    "    else:\n",
    "        print(\"unknown type\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying gold datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['df_gold', 'df_gold_exec_timeout', 'df_gold_exec_fail', 'df_gold_exec_empty', 'df_gold_exec_to_eval', 'df_gold_eval']) \n",
      "\n",
      "len(df_gold)=1764\n",
      "len(df_gold_exec_timeout)=0\n",
      "len(df_gold_exec_fail)=0\n",
      "len(df_gold_exec_empty)=0\n",
      "len(df_gold_exec_to_eval)=1764\n",
      "len(df_gold_eval)=1764 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_path = Path(\"../outputs/dataset_pipeline/final_fq17_with_limit_10/gold_final_fq17-split_train.json\")\n",
    "\n",
    "if not gold_path.exists():\n",
    "    raise FileNotFoundError(\"The gold dataset was not found.\")\n",
    "\n",
    "gold_data = json.loads(gold_path.read_text())\n",
    "print(gold_data.keys(), \"\\n\")\n",
    "\n",
    "mandatory_columns = [\n",
    "    \"df_gold\",\n",
    "    \"df_gold_exec_timeout\",\n",
    "    'df_gold_exec_fail',\n",
    "    'df_gold_exec_empty',\n",
    "    'df_gold_exec_to_eval',\n",
    "    'df_gold_eval'\n",
    "]\n",
    "\n",
    "if len(gold_data.keys()) != len(mandatory_columns):\n",
    "    raise ValueError(\"The gold dataset does not contain the same number of mandatory columns.\")\n",
    "\n",
    "if not all([col in mandatory_columns for col in list(gold_data.keys())]):\n",
    "    raise ValueError(\"The gold dataset does not contain one or more of the mandatory columns.\")\n",
    "\n",
    "df_gold = pd.read_json(gold_data['df_gold']) \n",
    "df_gold_exec_timeout = pd.read_json(gold_data['df_gold_exec_timeout'])\n",
    "df_gold_exec_fail = pd.read_json(gold_data['df_gold_exec_fail'])\n",
    "df_gold_exec_empty = pd.read_json(gold_data['df_gold_exec_empty'])\n",
    "df_gold_exec_to_eval = pd.read_json(gold_data['df_gold_exec_to_eval'])\n",
    "df_gold_eval = pd.read_json(gold_data['df_gold_eval'])\n",
    "\n",
    "print(f\"{len(df_gold)=}\")\n",
    "print(f\"{len(df_gold_exec_timeout)=}\")\n",
    "print(f\"{len(df_gold_exec_fail)=}\")\n",
    "print(f\"{len(df_gold_exec_empty)=}\")\n",
    "print(f\"{len(df_gold_exec_to_eval)=}\")\n",
    "print(f\"{len(df_gold_eval)=}\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic_input</th>\n",
       "      <th>templated_input</th>\n",
       "      <th>target_raw</th>\n",
       "      <th>target_template</th>\n",
       "      <th>gold_execution</th>\n",
       "      <th>gold_executed_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>[\"Find artists represented in the Swedish Nati...</td>\n",
       "      <td>[\"Find artists represented in the Swedish Nati...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?itemDescription ?Swed...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>[\"Find all places with coordinates near Papa S...</td>\n",
       "      <td>[\"Find the places located near Papa Stour isla...</td>\n",
       "      <td>SELECT ?place ?placeLabel ?location (GROUP_CON...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'place': {'type': 'uri', 'value': 'http://ww...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>[\"Write a query to find the number of occurren...</td>\n",
       "      <td>[\"Find the number of unique awards won by indi...</td>\n",
       "      <td>SELECT (COUNT(?item) AS ?count) ?otheraward ?o...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'otheraward': {'type': 'uri', 'value': 'http...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>[\"Find all items on Wikidata that have a linke...</td>\n",
       "      <td>[\"Find entities in Wikidata that have a linked...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>[\"Write a SparQL query to retrieve the name, l...</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the name, o...</td>\n",
       "      <td>SELECT ?doctor ?doctorLabel ?ordinal ?performe...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'doctor': {'type': 'uri', 'value': 'http://w...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            basic_input  \\\n",
       "1789  [\"Find artists represented in the Swedish Nati...   \n",
       "2338  [\"Find all places with coordinates near Papa S...   \n",
       "2779  [\"Write a query to find the number of occurren...   \n",
       "1624  [\"Find all items on Wikidata that have a linke...   \n",
       "662   [\"Write a SparQL query to retrieve the name, l...   \n",
       "\n",
       "                                        templated_input  \\\n",
       "1789  [\"Find artists represented in the Swedish Nati...   \n",
       "2338  [\"Find the places located near Papa Stour isla...   \n",
       "2779  [\"Find the number of unique awards won by indi...   \n",
       "1624  [\"Find entities in Wikidata that have a linked...   \n",
       "662   [\"Write a SparQL query to retrieve the name, o...   \n",
       "\n",
       "                                             target_raw  \\\n",
       "1789  SELECT ?item ?itemLabel ?itemDescription ?Swed...   \n",
       "2338  SELECT ?place ?placeLabel ?location (GROUP_CON...   \n",
       "2779  SELECT (COUNT(?item) AS ?count) ?otheraward ?o...   \n",
       "1624  SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...   \n",
       "662   SELECT ?doctor ?doctorLabel ?ordinal ?performe...   \n",
       "\n",
       "                                        target_template  \\\n",
       "1789  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2338  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2779  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "1624  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "662   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "\n",
       "                                         gold_execution  \\\n",
       "1789  [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "2338  [{'place': {'type': 'uri', 'value': 'http://ww...   \n",
       "2779  [{'otheraward': {'type': 'uri', 'value': 'http...   \n",
       "1624  [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "662   [{'doctor': {'type': 'uri', 'value': 'http://w...   \n",
       "\n",
       "                                    gold_executed_query  \n",
       "1789  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "2338  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "2779  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "1624  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "662   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic_input</th>\n",
       "      <th>templated_input</th>\n",
       "      <th>target_raw</th>\n",
       "      <th>target_template</th>\n",
       "      <th>gold_execution</th>\n",
       "      <th>gold_executed_query</th>\n",
       "      <th>gold_eval</th>\n",
       "      <th>gold_get_nested_values</th>\n",
       "      <th>gold_eval_df</th>\n",
       "      <th>gold_id_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>[\"Find artists represented in the Swedish Nati...</td>\n",
       "      <td>[\"Find artists represented in the Swedish Nati...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?itemDescription ?Swed...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q23914814, A C...</td>\n",
       "      <td>{'item': {'0': 'http://www.wikidata.org/entity...</td>\n",
       "      <td>{'item': {'0': 'http://www.wikidata.org/entity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>[\"Find all places with coordinates near Papa S...</td>\n",
       "      <td>[\"Find the places located near Papa Stour isla...</td>\n",
       "      <td>SELECT ?place ?placeLabel ?location (GROUP_CON...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'place': {'type': 'uri', 'value': 'http://ww...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'place': {'type': 'uri', 'value': 'http://ww...</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q1552121, Papa...</td>\n",
       "      <td>{'place': {'0': 'http://www.wikidata.org/entit...</td>\n",
       "      <td>{'place': {'0': 'http://www.wikidata.org/entit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>[\"Write a query to find the number of occurren...</td>\n",
       "      <td>[\"Find the number of unique awards won by indi...</td>\n",
       "      <td>SELECT (COUNT(?item) AS ?count) ?otheraward ?o...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'otheraward': {'type': 'uri', 'value': 'http...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'otheraward': {'type': 'uri', 'value': 'http...</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q39477935, Fel...</td>\n",
       "      <td>{'otheraward': {'0': 'http://www.wikidata.org/...</td>\n",
       "      <td>{'otheraward': {'0': 'http://www.wikidata.org/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>[\"Find all items on Wikidata that have a linke...</td>\n",
       "      <td>[\"Find entities in Wikidata that have a linked...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q140, http://c...</td>\n",
       "      <td>{'item': {'0': 'http://www.wikidata.org/entity...</td>\n",
       "      <td>{'item': {'0': 'http://www.wikidata.org/entity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>[\"Write a SparQL query to retrieve the name, l...</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the name, o...</td>\n",
       "      <td>SELECT ?doctor ?doctorLabel ?ordinal ?performe...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'doctor': {'type': 'uri', 'value': 'http://w...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'doctor': {'type': 'uri', 'value': 'http://w...</td>\n",
       "      <td>[http://www.wikidata.org/entity/Q33085422, Thi...</td>\n",
       "      <td>{'doctor': {'0': 'http://www.wikidata.org/enti...</td>\n",
       "      <td>{'doctor': {'0': 'http://www.wikidata.org/enti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            basic_input  \\\n",
       "1789  [\"Find artists represented in the Swedish Nati...   \n",
       "2338  [\"Find all places with coordinates near Papa S...   \n",
       "2779  [\"Write a query to find the number of occurren...   \n",
       "1624  [\"Find all items on Wikidata that have a linke...   \n",
       "662   [\"Write a SparQL query to retrieve the name, l...   \n",
       "\n",
       "                                        templated_input  \\\n",
       "1789  [\"Find artists represented in the Swedish Nati...   \n",
       "2338  [\"Find the places located near Papa Stour isla...   \n",
       "2779  [\"Find the number of unique awards won by indi...   \n",
       "1624  [\"Find entities in Wikidata that have a linked...   \n",
       "662   [\"Write a SparQL query to retrieve the name, o...   \n",
       "\n",
       "                                             target_raw  \\\n",
       "1789  SELECT ?item ?itemLabel ?itemDescription ?Swed...   \n",
       "2338  SELECT ?place ?placeLabel ?location (GROUP_CON...   \n",
       "2779  SELECT (COUNT(?item) AS ?count) ?otheraward ?o...   \n",
       "1624  SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...   \n",
       "662   SELECT ?doctor ?doctorLabel ?ordinal ?performe...   \n",
       "\n",
       "                                        target_template  \\\n",
       "1789  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2338  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2779  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "1624  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "662   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "\n",
       "                                         gold_execution  \\\n",
       "1789  [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "2338  [{'place': {'type': 'uri', 'value': 'http://ww...   \n",
       "2779  [{'otheraward': {'type': 'uri', 'value': 'http...   \n",
       "1624  [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "662   [{'doctor': {'type': 'uri', 'value': 'http://w...   \n",
       "\n",
       "                                    gold_executed_query  \\\n",
       "1789  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2338  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2779  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "1624  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "662   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "\n",
       "                                              gold_eval  \\\n",
       "1789  [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "2338  [{'place': {'type': 'uri', 'value': 'http://ww...   \n",
       "2779  [{'otheraward': {'type': 'uri', 'value': 'http...   \n",
       "1624  [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "662   [{'doctor': {'type': 'uri', 'value': 'http://w...   \n",
       "\n",
       "                                 gold_get_nested_values  \\\n",
       "1789  [http://www.wikidata.org/entity/Q23914814, A C...   \n",
       "2338  [http://www.wikidata.org/entity/Q1552121, Papa...   \n",
       "2779  [http://www.wikidata.org/entity/Q39477935, Fel...   \n",
       "1624  [http://www.wikidata.org/entity/Q140, http://c...   \n",
       "662   [http://www.wikidata.org/entity/Q33085422, Thi...   \n",
       "\n",
       "                                           gold_eval_df  \\\n",
       "1789  {'item': {'0': 'http://www.wikidata.org/entity...   \n",
       "2338  {'place': {'0': 'http://www.wikidata.org/entit...   \n",
       "2779  {'otheraward': {'0': 'http://www.wikidata.org/...   \n",
       "1624  {'item': {'0': 'http://www.wikidata.org/entity...   \n",
       "662   {'doctor': {'0': 'http://www.wikidata.org/enti...   \n",
       "\n",
       "                                        gold_id_columns  \n",
       "1789  {'item': {'0': 'http://www.wikidata.org/entity...  \n",
       "2338  {'place': {'0': 'http://www.wikidata.org/entit...  \n",
       "2779  {'otheraward': {'0': 'http://www.wikidata.org/...  \n",
       "1624  {'item': {'0': 'http://www.wikidata.org/entity...  \n",
       "662   {'doctor': {'0': 'http://www.wikidata.org/enti...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gold_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments, AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from sft_peft import format_prompt\n",
    "import sft_peft\n",
    "from prompts_template import BASE_MISTRAL_TEMPLATE, BASE_BASIC_INSTRUCTION\n",
    "from libwikidatallm.TemplateLLMQuerySender import TemplateLLMQuerySender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template=\"[/INST]\", tokenizer=tokenizer)\n",
    "datasets = load_dataset(\"pandas\", data_files=\n",
    "                          {\n",
    "                              \"valid\": \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_valid.pkl\",\n",
    "                              \"train\": \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_train.pkl\",\n",
    "                              \"test\": \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_test.pkl\",\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    valid: Dataset({\n",
       "        features: ['basic_input', 'templated_input', 'target_raw', 'target_template', 'index'],\n",
       "        num_rows: 129\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['basic_input', 'templated_input', 'target_raw', 'target_template', 'index'],\n",
       "        num_rows: 1923\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['basic_input', 'templated_input', 'target_raw', 'target_template', 'index'],\n",
       "        num_rows: 513\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from SFTTrainer(Trainer) _prepare_non_packed_dataloader method\n",
    "def _prepare_non_packed_dataloader(\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    dataset_text_field,\n",
    "    max_seq_length,\n",
    "    formatting_func=None,\n",
    "    add_special_tokens=True,\n",
    "    remove_unused_columns=True,\n",
    "):\n",
    "    use_formatting_func = formatting_func is not None and dataset_text_field is None\n",
    "    # self._dataset_sanity_checked = False\n",
    "\n",
    "    # Inspired from: https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt\n",
    "    def tokenize(element):\n",
    "        outputs = tokenizer(\n",
    "            element[dataset_text_field] if not use_formatting_func else formatting_func(element),\n",
    "            add_special_tokens=add_special_tokens,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=max_seq_length,\n",
    "            return_overflowing_tokens=False,\n",
    "            return_length=False,\n",
    "        )\n",
    "\n",
    "        # if use_formatting_func and not self._dataset_sanity_checked:\n",
    "        #     if not isinstance(formatting_func(element), list):\n",
    "        #         raise ValueError(\n",
    "        #             \"The `formatting_func` should return a list of processed strings since it can lead to silent bugs.\"\n",
    "        #         )\n",
    "        #     else:\n",
    "        #         self._dataset_sanity_checked = True\n",
    "\n",
    "        return {\"input_ids\": outputs[\"input_ids\"], \"attention_mask\": outputs[\"attention_mask\"]}\n",
    "\n",
    "    signature_columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "\n",
    "    extra_colmuns = list(set(dataset.column_names) - set(signature_columns))\n",
    "\n",
    "    # if not remove_unused_columns and len(extra_colmuns) > 0:\n",
    "    #     warnings.warn(\n",
    "    #         \"You passed `remove_unused_columns=False` on a non-packed dataset. This might create some issues with the default collator and yield to errors. If you want to \"\n",
    "    #         f\"inspect dataset other columns (in this case {extra_colmuns}), you can subclass `DataCollatorForLanguageModeling` in case you used the default collator and create your own data collator in order to inspect the unused dataset columns.\"\n",
    "    #     )\n",
    "\n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names if remove_unused_columns else None,\n",
    "        num_proc=1,\n",
    "        batch_size=32,\n",
    "    )\n",
    "\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = BASE_MISTRAL_TEMPLATE\n",
    "sft_peft.templater = TemplateLLMQuerySender(None, template, start_seq='[', end_seq=']')\n",
    "sft_peft.input_column = \"basic_input\"\n",
    "sft_peft.target_column = \"target_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = _prepare_non_packed_dataloader(tokenizer, datasets['test'], None, None, format_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 513\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator(tokenized_dataset, return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from sft_peft import main, parse_args\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args([\n",
    "    \"--model\", \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"--train-data\", \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_train.pkl\",\n",
    "    \"--target-column\", \"target_raw\",\n",
    "    \"--input-column\", \"basic_input\",\n",
    "    \"--valid-data\", \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_valid.pkl\",\n",
    "    \"--start-tag\", \"[query]\",\n",
    "    \"--end-tag\", \"[/query]\",\n",
    "    \"--rvalue\", \"32\",\n",
    "    \"--lora-dropout\", \"0\",\n",
    "    \"--batch-size\", \"1\",\n",
    "    \"--gradient-accumulation\", str(4),\n",
    "    \"--packing\", \"0\",\n",
    "    \"--neft-tune-alpha\", \"0\",\n",
    "    \"--epochs\", \"1\",\n",
    "    \"--output\", \".\",\n",
    "    \"--save-name\", \"test_debug\",\n",
    "    \"--run-name\", f\"test_debug\",\n",
    "    \"--random-seed\", \"42\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tokens_with_ids(txt):\n",
    "    tokens = tokenizer.tokenize(txt, add_special_tokens=False)\n",
    "    token_ids = tokenizer.encode(txt, add_special_tokens=False)\n",
    "    print(list(zip(tokens, token_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.2', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▁[', 733), ('/', 28748), ('INST', 16289), (']', 28793)]\n",
      "[('▁[', 733), ('/', 28748), ('INST', 16289), (']', 28793), ('▁[', 733), ('query', 3385), (']', 28793)]\n",
      "[('▁[', 733), ('/', 28748), ('INST', 16289), (']', 28793), ('▁[', 733), ('query', 3385), (']', 28793)]\n"
     ]
    }
   ],
   "source": [
    "print_tokens_with_ids(\"[/INST]\")\n",
    "print_tokens_with_ids(\"[/INST] [query]\")\n",
    "print_tokens_with_ids(\"[/INST] [query]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from prompts_template import ELABORATE_INSTRUCTION, BASE_MISTRAL_TEMPLATE\n",
    "from libwikidatallm.TemplateLLMQuerySender import TemplateLLMQuerySender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your assignment involves a two-step process:\n",
      "First, you will receive a task described in a single sentence. This task outlines what information you need to find or what question you need to answer.\n",
      "Then, you will create a SPARQL Query: Based on the task given, you will write a SPARQL query. SPARQL is a specialized query language used to retrieve and manipulate data stored in Resource Description Framework (RDF) format. Your goal is to craft a query that, when executed, fetches the data or answers required by the initial instruction.\n",
      "Make sure your SPARQL query is correctly formulated so that, upon execution, it produces the desired result matching the task's requirements.\n",
      "Answer this following instruction:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>description</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>start_with_SELECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT ?property ?propertyType ?propertyLabel ...</td>\n",
       "      <td>Wikidata properties in numerical order</td>\n",
       "      <td>Counting stuff on Wikidata\\nAll Wikidata prope...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>267</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT ?id ?idLabel ?idDescription ?new{\\n?id ...</td>\n",
       "      <td>Wikidata properties excluding external IDs</td>\n",
       "      <td>Counting stuff on Wikidata\\nVariation of the a...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>296</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT (COUNT(?article) AS ?count)\\nWHERE {\\n?...</td>\n",
       "      <td></td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of scientifi...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT (COUNT(DISTINCT ?article) AS ?count)\\nW...</td>\n",
       "      <td>Count of fictional characters</td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of fictional...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>203</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT (COUNT(?item) AS ?count)\\nWHERE { ?item...</td>\n",
       "      <td>Count of items with coordinate locations</td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of items wit...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>186</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  SELECT ?property ?propertyType ?propertyLabel ...   \n",
       "1  SELECT ?id ?idLabel ?idDescription ?new{\\n?id ...   \n",
       "2  SELECT (COUNT(?article) AS ?count)\\nWHERE {\\n?...   \n",
       "3  SELECT (COUNT(DISTINCT ?article) AS ?count)\\nW...   \n",
       "4  SELECT (COUNT(?item) AS ?count)\\nWHERE { ?item...   \n",
       "\n",
       "                                  description  \\\n",
       "0      Wikidata properties in numerical order   \n",
       "1  Wikidata properties excluding external IDs   \n",
       "2                                               \n",
       "3               Count of fictional characters   \n",
       "4    Count of items with coordinate locations   \n",
       "\n",
       "                                             context  \\\n",
       "0  Counting stuff on Wikidata\\nAll Wikidata prope...   \n",
       "1  Counting stuff on Wikidata\\nVariation of the a...   \n",
       "2  Counting stuff on Wikidata\\nCount of scientifi...   \n",
       "3  Counting stuff on Wikidata\\nCount of fictional...   \n",
       "4  Counting stuff on Wikidata\\nCount of items wit...   \n",
       "\n",
       "                                              prompt  num_tokens  \\\n",
       "0  <s>[INST] <<SYS>>This is a conversation betwee...         267   \n",
       "1  <s>[INST] <<SYS>>This is a conversation betwee...         296   \n",
       "2  <s>[INST] <<SYS>>This is a conversation betwee...         197   \n",
       "3  <s>[INST] <<SYS>>This is a conversation betwee...         203   \n",
       "4  <s>[INST] <<SYS>>This is a conversation betwee...         186   \n",
       "\n",
       "   start_with_SELECT  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"../datasets/final_queries_v1.7.json\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "print(ELABORATE_INSTRUCTION)\n",
    "\n",
    "templater = TemplateLLMQuerySender(llm=None, template_text=BASE_MISTRAL_TEMPLATE, start_seq=\"[\", end_seq=\"]\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_query = dataset['query'].loc[dataset['query'].map(len).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2739"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_prompts(query, templater:TemplateLLMQuerySender, template:str, start_tag:str = '`sparql\\n', end_tag:str = \"`\"):\n",
    "    start_tag = '`sparql\\n'\n",
    "    end_tag = \"`\"\n",
    "\n",
    "    x = templater.apply_template({\n",
    "        \"system_prompt\": template,\n",
    "        \"prompt\": \"\\\"\"+ (\"abigword \" * 20) +\"\\\"\"\n",
    "    })\n",
    "    x += f\"{start_tag}{query}{end_tag}\"\n",
    "    return x\n",
    "\n",
    "longest_prompt = prepare_prompts(longest_query, templater=templater, template=ELABORATE_INSTRUCTION, start_tag=\"`sparql\\n\", end_tag=\"`\")\n",
    "len(tokenizer(longest_prompt)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "import json\n",
    "import random\n",
    "from prompts_template import ELABORATE_INSTRUCTION\n",
    "import sft_peft\n",
    "from sft_peft import is_query_format_acceptable, execute_pipeline, execute_query, extract_query\n",
    "from execution_utils import is_query_empty, can_add_limit_clause, add_relevant_prefixes_to_query, send_query_to_api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder_path = Path(\"../tests/scriptstests/data/compute_metrics_real_data_from_training_1\")\n",
    "folder_path = Path(\"../outputs/batch_run/learning_experiment_long_epochs_4/models\")\n",
    "run_name = \"M-7B-I-v0.2_oawtor-rv256-rm1-ld0-bs2-ga8-gc1-p0-nta0-e10-ctx3072-qno-template-template-stsparql_adapters\"\n",
    "num_epochs = 10\n",
    "epochs_data = [json.loads((folder_path / f\"{run_name.replace('_adapters', '')}_compute_metrics_{i}.json\").read_text()) for i in range(num_epochs)]\n",
    "\n",
    "len(epochs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['preds', 'labels', 'decoded_labels', 'decoded_preds'])\n"
     ]
    }
   ],
   "source": [
    "columns = epochs_data[0].keys()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label_answer_and_preds(row_number:int = 0, num_epochs:int = 3):\n",
    "    print(f\"LABEL n°{row_number}\",\"=\" * 98)\n",
    "    print(epochs_data[0][\"decoded_labels\"][row_number])\n",
    "    for i in range(num_epochs):\n",
    "        print(f\"EPOCH {i}\",\"=\" * 100)\n",
    "        print(epochs_data[i][\"decoded_preds\"][row_number])\n",
    "    \n",
    "def get_execution_response(query: str):\n",
    "    query = extract_query(query)\n",
    "    if is_query_empty(query):\n",
    "        return None\n",
    "    else:\n",
    "        query = add_relevant_prefixes_to_query(query)\n",
    "    \n",
    "        if can_add_limit_clause(query):\n",
    "            query += f\"\\nLIMIT 10\"\n",
    "\n",
    "    response = send_query_to_api(query, do_print=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your assignment involves a two-step process:\n",
      "First, you will receive a task described in a single sentence. This task outlines what information you need to find or what question you need to answer.\n",
      "Then, you will create a SPARQL Query: Based on the task given, you will write a SPARQL query. SPARQL is a specialized query language used to retrieve and manipulate data stored in Resource Description Framework (RDF) format. Your goal is to craft a query that, when executed, fetches the data or answers required by the initial instruction.\n",
      "Make sure your SPARQL query is correctly formulated so that, upon execution, it produces the desired result matching the task's requirements.\n",
      "Answer this following instruction:\n"
     ]
    }
   ],
   "source": [
    "print(ELABORATE_INSTRUCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL n°82 ==================================================================================================\n",
      "[sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?person ?personLabel ?countryLabel ?cpan ?github ?wikimedia {\n",
      "?person wdt:[property:instance of] wd:[entity:human] .\n",
      "{\n",
      "{ ?person wdt:[property:CPAN author ID] ?cpan } UNION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:Wikimedia username] ?wikimedia }\n",
      "}\n",
      "{\n",
      "{ ?person wdt:[property:occupation] wd:[entity:minister] } # occupation minister\n",
      "UNION {\n",
      "?person wdt:[property:position held] ?pos . # position held: minister\n",
      "?pos wdt:[property:subclass of]* wd:[entity:minister]\n",
      "}\n",
      "}\n",
      "OPTIONAL { ?person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "}[/sparql]\n",
      "EPOCH 0 ====================================================================================================\n",
      "Questionpackageer: task is writing-part process:\n",
      "\n",
      ", you will need a list to in a text sentence.\n",
      " sentence willlines the you you need to find. what action you need to answer.\n",
      "\n",
      ", you will receive a responseocraticQL query to a on the task,, you will create a SPARQL query to\n",
      "PARQL is a query query language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed, willches the data you answers the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted and that it when execution, it returns the desired results. the task.s instruction.\n",
      "\n",
      "swer: question task: FindFind all number of imagesities of all who have been article on TwitterHub.\" andAC, or Gitimedia Commons and with their Gitial and they.\"\n",
      "task[{ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?ISTINCT ?person ?personLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "?person wdt:[property:instance of] wd:[entity:human]; .\n",
      "? ?? ?person wdt:[property:positionAN author ID] ?cpan }\n",
      "ION {{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:Wikimedia username] ?wikimedia }\n",
      "}\n",
      "?\n",
      "? ?person wdt:[property:positionation] wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:position held] ?position .\n",
      " position held\n",
      " minister\n",
      "?pos wdt:[property:subclass of]* wd:[entity:minister] .}\n",
      "}\n",
      "?AL { ?person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"AUTO_LANGUAGE],en\". }\n",
      "}/sparql] This:ous::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "EPOCH 1 ====================================================================================================\n",
      "Questionpackageer: task is writing lot-part process:\n",
      "\n",
      ", you will need a list to in a text sentence.\n",
      " sentence willlines the you you need to find. what action you need to answer.\n",
      "\n",
      ", you will receive a responseocraticQL query to a on the task,, write will create a SPARQL query to\n",
      "PARQL is a query query language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed, willches the data you answers the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted and that it when execution, it returns the desired results. the task.s instruction.\n",
      "\n",
      "swer: task task: FindFind all number of imagesities of all who have been article on WikipediaHub.\" andAC, or Stackimedia Commons and with their respectiveial and they.\"\n",
      "task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?ISTINCT ?item ?personLabel ?nLabel ?titlepan ?github ?wikipediaimedia ?\n",
      "?person wdt:[property:instance of] wd:[entity:human]; .\n",
      "? ???person wdt:[property:occupAN author ID] ?cpan }\n",
      "ION {{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:Wikimedia username] ?wikimedia }\n",
      "}\n",
      "? ?? ?person wdt:[property:positionation] wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:position held] wposition .\n",
      " position held\n",
      " minister\n",
      "?pos wdt:[property:subclass of] wd:[entity:minister] .}\n",
      "}\n",
      "?AL { ?person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "}[/sparql] This [ousousc'cccccccccousousousousous''xxxxxxxxxxxxxxxxxxxxx:::xx:::::::::xxxx:::::::::xxxx::::::::::xx:::::::::xxx:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "EPOCH 2 ====================================================================================================\n",
      "Questionpackageer: task is writing lot-part process:\n",
      "\n",
      ", you will need a list to in a comment sentence.\n",
      " is willlines what you you need to find. what action you need to answer.\n",
      "\n",
      ", you will receive a responseocraticQL query to a on the task,, write will create a SPARQL query that ThisPARQL is a query language language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed, willches the information you answers the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted and that it when execution, it returns the desired results. the task.s instruction.\n",
      "\n",
      "swer: task task: FindFind all number of imagesities of all who have been article on WikipediaHub.\" andAC, or Stackimedia Commons and with the usernameial and they.\"\n",
      "task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?ISTINCT ?item ?personLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "?person wdt:[property:instance of] wd:[entity:human]; .\n",
      "? ?? ?person wdt:[property:positionAN author ID] ?cpan .\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:usernameikimedia username] ?wikimedia }\n",
      "}\n",
      "? ?? ?person wdt:[property:positionation]/ wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:country held] ?position .\n",
      " position held\n",
      "\n",
      "\n",
      "?pos wdt:[property:subclass of] wd:[entity:minister] .}\n",
      "}\n",
      "OPTIONAL { ?person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"AUTO_LANGUAGE],en\". }\n",
      "}/sparql] Findousousccccccccccccccccccccccccccccccccx::xxxxous:::ccc:cccc::::xxx::::::::::::::::::::::::cc::c:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::c:c::::::::::::::::::::::::::::::::::::::::::::::::ccc::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "EPOCH 3 ====================================================================================================\n",
      "Questionpackageer: task is writing-part process:\n",
      "\n",
      ", you will need a list to in a comment sentence.\n",
      " sentence willlines what you you need to find. what action you need to answer.\n",
      "\n",
      ", you will receive a responseocraticQL query to a on the task,, write will create a SPARQL query that ThisPARQL is a query language language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed, willches the information you answers the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted and that it when execution, it retriev the desired results. the task.s instruction.\n",
      "\n",
      "swer: task task: FindFind all number of imagesities of all who have been article on WikipediaHub.\" andAC, or Stackimedia Commons and with the usernameial and any.\"\n",
      "Task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?ISTINCT ?item ?personLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "?person wdt:[property:CP of] wd:[entity:human] .\n",
      "? ?? ?person wdt:[property:CPAN author ID] ?cpan }\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:Wikimedia username] ?wikimedia }\n",
      "}\n",
      "OPTION\n",
      "? ?person wdt:[property:positionation] wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:n held] wposition .\n",
      " position held\n",
      "\n",
      "\n",
      "?pos wdt:[property:subclass of]+ wd:[entity:minister] .}\n",
      "}\n",
      "OPTIONAL { ?person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" }\n",
      "}/sparql] Find [ouscccccccccccccccccccccousccccc::cc:::::::::::::::::::::::::x:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "EPOCH 4 ====================================================================================================\n",
      "Questionpackageer: task is writing lot-part process:\n",
      "\n",
      ", you will need a list to in a comment sentence.\n",
      " sentence willlines the you you need to find. what action you need to answer.\n",
      "\n",
      ", you will receive a listocraticQL query to a on the task,, write will create a queryPARQL query that ThisPARQL is a query language language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed, willches the information you answers the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted before that it when execution, it retriev the desired results. the task.s instruction.\n",
      "\n",
      "swer the task task in FindFind all number of imagesities of all who have been article on TwitterHub.\" andAC, or Stackimedia Commons and with the usernameial and they.\"\n",
      "Task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?ISTINCT ?item ?personLabel ?nLabel ?ministerpan ?github ?wikimedia ?\n",
      "?person wdt:[property:instance of] wd:[entity:human] .\n",
      "? ?? ?person wdt:[property:occupAN username ID] ?cpan }\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:usernameikimedia username] ?wikimedia }\n",
      "}\n",
      "? ?? ?person wdt:[property:positionation] wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:n held] wposition .\n",
      " position held\n",
      " e\n",
      "{pos wdt:[property:subclass of]* wd:[entity:minister] .}\n",
      "}\n",
      "OPTIONAL { ?person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "}[/sparql] Find cscscscscccccccccccccccccccccccc::ccc::::::::::::::::::::::::xx::::::::::::::::::::::::c:::c:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "EPOCH 5 ====================================================================================================\n",
      "Questionpackageer: task is writing review-part process:\n",
      "\n",
      ", you will need a list to in a comment sentence. Your sentence willlines what you you need to find. what question you need to answer.\n",
      "\n",
      ", you will be a listocraticQL query to a on the task,, write will construct a queryPARQL query that ThisPARQL queries a query language language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed, willches the information you answers the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted before that it when execution, it retriev the desired results. the task.s requirement.\n",
      "\n",
      "swer the task task in FindFind all number of imagesities of all who have been article on TwitterHub.\" aAC, or Stackimedia Commons and with their usernameial and any.\"\n",
      "Task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?itemLabelpersonLabel ?nLabel ?ministerpan ?github ?wikimedia ?\n",
      "?person wdt:[property:CP of] wd:[entity:human] .\n",
      "? ?? ?person wdt:[property:positionAN author ID] ?cpan }\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:usernameikimedia username] ?wikimedia }\n",
      "}\n",
      "FILTER\n",
      "? ?person wdt:[property:positionation] wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:n held] wposition . # position held\n",
      " e\n",
      "?pos wdt:[property:subclass of]* wd:[entity:minister] .}\n",
      "}\n",
      "?AL { ?person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"AUTO_LANGUAGE],en\". }\n",
      "}/sparql] Thisousousccccccc''ccccccccccccccccccc::cccc::::::ccc::::::cc::::::::cc:::::ccc:::ccc:::::::::ccc:::::ccccccc:::::cccc::::::::::::::::::::::::::::::::::::::::::ionion::v:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::cc::::::::::::::::::::::::::::::::::::::amam::::::::::::::::::::::ccccc:::::::::::::::::::::::::::::::::::::::::::::::ccc:::::::'''':::::::am:::::::::::::::::::::force:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::k::::::::::::::::::v::::::\n",
      "EPOCH 6 ====================================================================================================\n",
      "Questionpackageer: task is writing review-part process:\n",
      "\n",
      ", you will need a list to in a comment sentence.\n",
      " sentence willlines what you you need to find. what question you need to answer.\n",
      "\n",
      ", you will be a listocraticQL query to a on the task,, construct will construct a queryPARQL query that ThisPARQL is a query language language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed against willches the information you answers the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted before that it when execution, it retriev the desired results. the task.s requirement.\n",
      "\n",
      "swer the task task in FindFind all number of imagesities of all who have been article on TwitterHub.\" as,, or Stackimedia Commons and with the usernameial and any.\"\n",
      "Task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?ISTINCT ?personLabelpersonLabel ?nLabel ?ministerpan ?github ?wikimedia ?\n",
      "?person wdt:[property:CP of] wd:[entity:human] .\n",
      "? ?? ?person wdt:[property:occupAN username ID] ?cpan }\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:usernameikimedia username] ?wikimedia }\n",
      "}\n",
      "?\n",
      "? ?person wdt:[property:positionation] wd:[entity:polit] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:country held] wposition .\n",
      " position held\n",
      " e\n",
      "{pos wdt:[property:subclass of] wd:[entity:minister] .}\n",
      "}\n",
      "?AL {\n",
      "person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "}[/sparql] The [ouscsccccccccccccccccccccccccccc::cccc:::::ccc:::cc::::::::::::::::xx::::::::::::::::cc:::::ccccccc:::::ccc:::::::::::::::::::::::::::::::::::::::::::'ion'':::::::::::::::::::c:::::cv':::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::v::::am::::::c::::::cccc::vvv::cccccv:vvvv::::vv::cccccccc:::::amccc::::amamam:::::v::::vv:onymccccc::cccc:::::::::::::::::::::::vvvvv:::::vv:::::cccconymececec'onymam''''''::ecec:ec:::::::::''efam:::efv'ececececv:::amamamam:::----::::::::::::::::::::::::::::vv:::::::::::::::::::::::::::::v:::::::::::::::::::::::::::::::::::::::::::::amam::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::vvv::::::::::::::::::vvvv:::::vv::::::::'::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::vvvv::::::::::vvv:vvvvvvvvc\n",
      "EPOCH 7 ====================================================================================================\n",
      "Questionpackageer: task is writing close-part process:\n",
      "\n",
      ", you will need a list to in a comment sentence.\n",
      " sentence willlines what you you need to find. what question you need to answer.\n",
      "\n",
      ", you will be a listocraticQL query to a on the task,, construct will construct a queryPARQL query that ThisPARQL queries a query language language for to retrieve and manipulate data on in R Description Framework (RDF) format.\n",
      " query is to write a query that will when executed against willches the information you information the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted before that it when execution, it retriev the desired results. the task.s instruction.\n",
      "\n",
      "swer the task task in\n",
      "Find all number of imagesities of all who have been article on TwitterHub.\" aAC, or Stackimedia Commons and with the usernameial and any.\"\n",
      "Task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?ISTINCT ?itemLabelpersonLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "VALperson wdt:[property:CP of] wd:[entity:human] .\n",
      "? ?? ?person wdt:[property:occupAN username ID] ?cpan }\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:usernameikimedia username] ?wikimedia }\n",
      "}\n",
      "FILTER\n",
      "? ?person wdt:[property:positionation] wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:n held] ?position .\n",
      " position held\n",
      " e title{pos wdt:[property:subclass of] wd:[entity:minister] .}\n",
      "}\n",
      "?AL {\n",
      "person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"AUTO_LANGUAGE],en\". }\n",
      "}[/sparql] Thetsousccccccc'''cccccccccccccccccc::cccc:::cccc::ccc::::::::cc::::cccc::ccc::::c:ccccccc:::ccccccccc:::cccccc:::::::::::::::::::::::::::::::::::ce:::::vv''vv::::::::::::::::ccc:::ccc'''::::::::::::::::::::::::::::::::::::::::::::::::::::::am:::::::::::::::::::::::forceam:::amamam:::::cam:::::ccccccccccccccc:cvvv:::::ccccccccccc:::::ccccc:::amamamamamamam:c::::cccccccccccccccc::ccc:::::::::::::::::vvvvv::::ccc:::::cccccececforce'amam''''amamamamecamamamam::forceam::::amamamamamforforforceforceforceececforceforceforceforceamamamamamamamamamamvam:::::::::::v::::::::::::::::::::::::vamam:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::amam::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::vv:::::v:::::::::::::::::::::vvvv:::::v:::::::amam''::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::am:::::::::::::::::vamvvvvv::::::::vvv:vccvvcccc\n",
      "EPOCH 8 ====================================================================================================\n",
      "Questionpackageer: task is writing close-part process:\n",
      "\n",
      ", you will need a prompt to in a comment sentence.\n",
      " sentence willlines a you you need to find. what question you need to answer.\n",
      "\n",
      ", you will be a listocraticQL query to a on the task,, construct will construct a queryPARQL query that ThisPARQL is a query language language for to retrieve and manipulate data on on R Description Framework (RDF) format.\n",
      " query is to write a query that will when run against willches the information you information the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted before that it when execution, it retriev the desired results. the task.s instruction.\n",
      "\n",
      "swer the task task in\n",
      "Find all number of imagesities of all who have been article on TwitterHub.\" a,, or Stackimedia Commons and with the usernameial and any.\"\n",
      "Task[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?personLabelpersonLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "?person wdt:[property:CP of] wd:[entity:human] .\n",
      "? ?? ?person wdt:[property:CPAN username ID] ?cpan }\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:usernameikimedia username] ?wikimedia }\n",
      "}\n",
      "FILTER\n",
      "? ?person wdt:[property:positionation]/ wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:n held] wposition .\n",
      " position held\n",
      " e title{pos (dt:[property:subclass of] wd:[entity:minister] .}\n",
      "}\n",
      "?AL {\n",
      "person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "}[/sparql] Theousousccccccc'''cccccccccccccccccc::ccccc:::::cccc:ccc::::::::::c:::::::ccccxxccc:::cccccccccc:::ccccccccc:::cccccc:::::::::::::::::::::::::::::::::::ce:::::'''''v::::::::::::::::forcc:::cc''''::::::::::::::::::::::::::::::::::::::::::::::::::::::::'::::::':::::::::::::::forforfor::foramamam:::::camam::'ccccc'''cc::ccccv:''vv:::::v::ccccccccc::::amamccce:amamamamamamamamamamonym::::ccamcyccccc::cccc::::onym::::::::::::::::::vvv::::::cccam::::cccc''ec''''''''''''ececamamam:forceforceforce:::'amamforceamamforforforceforceforce''forceforceforceforceforceamamamamamamamamam---:::force::::ricricforceforce:::::::::::::::amamv::::vvamamamamam:v::::::::::::::::::::::::::::::::::::::::ionionion:::'::::::::::::::amamam::am::::::::am::::::::::::::::::::::::::::::::::::::::idid:::::::::::::::idid:::::::::::::::::::vvv:::::::::::::amam'   ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::am:::::::::::::::::amamvv::v:::::::::v:vvvvvvvvvv\n",
      "EPOCH 9 ====================================================================================================\n",
      "Questionpackageer: task is writing close-part process:\n",
      "\n",
      ", you will need a prompt to in a comment sentence.\n",
      " sentence willlines a you you need to find. what question you need to answer.\n",
      "\n",
      ", you will be a listocraticQL query to a on the task,, construct will construct a SPARQL query that ThisPARQL is a query language language for to retrieve and manipulate data on on R Description Framework (RDF) format.\n",
      " query is to write a query that will when run against willches the information you information the by the task task.\n",
      "\n",
      " sure to queryPARQL query is valid formatted before that it when execution, it retriev the desired results. the task.s instruction.\n",
      "\n",
      "swer the task task in\n",
      "Find all number of imagesities of all who have been article on TwitterHub.\" a,, or Stackimedia Commons and with their usernameial and any.\"\n",
      "Spec[[ [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?personLabelpersonLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "?person wdt:[property:CP of] wd:[entity:human] .\n",
      "? ?? ?person wdt:[property:CPAN username ID] ?cpan }\n",
      "ION\n",
      "{ ?person wdt:[property:GitHub username] ?github } UNION\n",
      "{ ?person wdt:[property:usernameikimedia username] ?wikimedia }\n",
      "}\n",
      "?\n",
      "? ?person wdt:[property:positionation] wd:[entity:minister] } UN minister:\n",
      "UNION\n",
      " ??person wdt:[property:n held] ?position .\n",
      " position held\n",
      " e title{pos (dt:[property:subclass of] wd:[entity:minister] .}\n",
      "}\n",
      "?AL {\n",
      "person wdt:[property:country of citizenship] ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"AUTO_LANGUAGE],en\". }\n",
      "}[/sparql] Theousousccccccc'''cccccccccccccccccc::ccccc:::ccccc:ccc::::::::cc:::::::ccccxxccc:::cccccccccc:::ccccccccc::ccccccc::::::::::::::::::::::::::::::::::vcece::::vce''ghterv:::::::::::::::forforfor:::cc''''::::::::::::::::::::::::::::::::::::::::::::::::::::::::'::::::::::''::::::::::forforfor:::forforam:::::amamam:'''cccc''''c::ccccv:''vv:::::v:::c:ccccc::::amamamamamce:amamamamamamamamamamam::::amamamcycycccce::cccc::::forcec:::::::::::::::::vvv:::::::cam:::::ccccamececec'''''''''''ececicamamforceforceforceforce:::foramamforceamforceforforforforceforce''forceforceforceforceforceforceamamamamamamamam---::::::::ricricforceforce:::::::::::::::amvv::::vvamamam:amamv::::::::::::::::::::::::::::::::::::::::ionionion:::'::::::::am:::::amamam::am:::::::::::::::::::::::::::::::::::::::::::::::::idid:::::::::::::::idid:::::::::::::::::::vvv:::::::::::::amam'   ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::amamvv::::::::::::v::vccvvvvcc\n"
     ]
    }
   ],
   "source": [
    "n_rows = len(epochs_data[0][\"decoded_preds\"])\n",
    "\n",
    "row_number = random.randint(0, n_rows)\n",
    "print_label_answer_and_preds(row_number, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is acceptable query: True\n",
      "Pred is acceptable query: True\n",
      "\n",
      "Pipelined label success: True\n",
      "Pipelined pred success: True\n",
      "\n",
      "Successfully extracted query label=True\n",
      "Successfully extracted query pred=True\n",
      "\n",
      "Extracted Label\n",
      "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?person ?personLabel ?countryLabel ?cpan ?github ?wikimedia {\n",
      "?person wdt:P31 wd:Q5 .\n",
      "{\n",
      "{ ?person wdt:P8124 ?cpan } UNION\n",
      "{ ?person wdt:P2037 ?github } UNION\n",
      "{ ?person wdt:P4174 ?wikimedia }\n",
      "}\n",
      "{\n",
      "{ ?person wdt:P106 wd:Q83307 } # occupation minister\n",
      "UNION {\n",
      "?person wdt:P39 ?pos . # position held: minister\n",
      "?pos wdt:P279* wd:Q83307\n",
      "}\n",
      "}\n",
      "OPTIONAL { ?person wdt:P27 ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "}\n",
      "\n",
      "Extracted Prediction\n",
      "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?personLabelpersonLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "?person wdt:Q67804278 wd:Q5 .\n",
      "? ?? ?person wdt:CPAN username ID ?cpan }\n",
      "ION\n",
      "{ ?person wdt:P2037 ?github } UNION\n",
      "{ ?person wdt:usernameikimedia username ?wikimedia }\n",
      "}\n",
      "?\n",
      "? ?person wdt:positionation wd:Q83307 } UN minister:\n",
      "UNION\n",
      " ??person wdt:n held ?position .\n",
      " position held\n",
      " e title{pos (dt:P279 wd:Q83307 .}\n",
      "}\n",
      "?AL {\n",
      "person wdt:P27 ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"AUTO_LANGUAGE],en\". }\n",
      "}\n",
      "\n",
      "executed_label\n",
      "[{'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q15025'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Audrey Tang'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Taiwan'}, 'cpan': {'type': 'literal', 'value': 'AUDREYT'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q15025'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Audrey Tang'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Taiwan'}, 'wikimedia': {'type': 'literal', 'value': 'AudreyTang'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q15025'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Audrey Tang'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Taiwan'}, 'cpan': {'type': 'literal', 'value': 'AUTRIJUS'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q15025'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Audrey Tang'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Taiwan'}, 'wikimedia': {'type': 'literal', 'value': '唐鳳'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q110088824'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Bozhidar Bozhanov'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Bulgaria'}, 'github': {'type': 'literal', 'value': 'Glamdring'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q23530'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Dmitry Medvedev'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Russia'}, 'wikimedia': {'type': 'literal', 'value': 'Dmitry Medvedev for RIAN'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q449769'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Jan Sokol'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Czechoslovakia'}, 'wikimedia': {'type': 'literal', 'value': 'Sokoljan'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q20175887'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Kaare Dybvad Bek'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Kingdom of Denmark'}, 'wikimedia': {'type': 'literal', 'value': 'Kaare Dybvad'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q2649226'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Hugo de Jonge'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Kingdom of the Netherlands'}, 'github': {'type': 'literal', 'value': 'HugoDeJonge'}}, {'person': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q449769'}, 'personLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Jan Sokol'}, 'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Czech Republic'}, 'wikimedia': {'type': 'literal', 'value': 'Sokoljan'}}]\n",
      "\n",
      "executed_pred\n",
      "Execution has failed!\n",
      "exception: 400 Client Error: Bad Request for url: https://query.wikidata.org/bigdata/namespace/wdq/sparql?query=PREFIX+bd%3A+%3Chttp%3A%2F%2Fwww.bigdata.com%2Frdf%23%3E%0APREFIX+wd%3A+%3Chttp%3A%2F%2Fwww.wikidata.org%2Fentity%2F%3E%0APREFIX+wdt%3A+%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2Fdirect%2F%3E%0APREFIX+wikibase%3A+%3Chttp%3A%2F%2Fwikiba.se%2Fontology%23%3E%0A%0ASELECT+DISTINCT+%3FpersonLabelpersonLabel+%3FnLabel+%3Ftitlepan+%3Fgithub+%3Fwikimedia+%3F%0A%3Fperson+wdt%3AQ67804278+wd%3AQ5+.%0A%3F+%3F%3F+%3Fperson+wdt%3ACPAN+username+ID+%3Fcpan+%7D%0AION%0A%7B+%3Fperson+wdt%3AP2037+%3Fgithub+%7D+UNION%0A%7B+%3Fperson+wdt%3Ausernameikimedia+username+%3Fwikimedia+%7D%0A%7D%0A%3F%0A%3F+%3Fperson+wdt%3Apositionation+wd%3AQ83307+%7D+UN+minister%3A%0AUNION%0A+%3F%3Fperson+wdt%3An+held+%3Fposition+.%0A+position+held%0A+e+title%7Bpos+%28dt%3AP279+wd%3AQ83307+.%7D%0A%7D%0A%3FAL+%7B%0Aperson+wdt%3AP27+%3Fcountry+%7D%0ASERVICE+wikibase%3Alabel+%7B+bd%3AserviceParam+wikibase%3Alanguage+%22AUTO_LANGUAGE%5D%2Cen%22.+%7D%0A%7D%0ALIMIT+10&format=json\n",
      "SPARQL-QUERY: queryStr=PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT DISTINCT ?personLabelpersonLabel ?nLabel ?titlepan ?github ?wikimedia ?\n",
      "?person wdt:Q67804278 wd:Q5 .\n",
      "? ?? ?person wdt:CPAN username ID ?cpan }\n",
      "ION\n",
      "{ ?person wdt:P2037 ?github } UNION\n",
      "{ ?person wdt:usernameikimedia username ?wikimedia }\n",
      "}\n",
      "?\n",
      "? ?person wdt:positionation wd:Q83307 } UN minister:\n",
      "UNION\n",
      " ??person wdt:n held ?position .\n",
      " position held\n",
      " e title{pos (dt:P279 wd:Q83307 .}\n",
      "}\n",
      "?AL {\n",
      "person wdt:P27 ?country }\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"AUTO_LANGUAGE],en\". }\n",
      "}\n",
      "LIMIT 10\n",
      "java.util.concurrent.ExecutionException: org.openrdf.query.MalformedQueryException: Encountered \" \"?\" \"? \"\" at line 6, column 78.\n",
      "Was expecting one of:\n",
      "    \"(\" ...\n",
      "    \"{\" ...\n",
      "    \"from\" ...\n",
      "    \"where\" ...\n",
      "    \"with\" ...\n",
      "    <VAR1> ...\n",
      "    <VAR2> ...\n",
      "    \n",
      "\tat java.util.concurrent.FutureTask.report(FutureTask.java:122)\n",
      "\tat java.util.concurrent.FutureTask.get(FutureTask.java:206)\n",
      "\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\n",
      "\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\n",
      "\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\n",
      "\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\n",
      "\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n",
      "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\n",
      "\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:320)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\n",
      "\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:82)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\n",
      "\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\n",
      "\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:122)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\n",
      "\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\n",
      "\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\n",
      "\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\n",
      "\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\n",
      "\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n",
      "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\n",
      "\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\n",
      "\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\n",
      "\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\n",
      "\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\n",
      "\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\n",
      "\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\n",
      "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\n",
      "\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\n",
      "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\n",
      "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\n",
      "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\n",
      "\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\n",
      "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.openrdf.query.MalformedQueryException: Encountered \" \"?\" \"? \"\" at line 6, column 78.\n",
      "Was expecting one of:\n",
      "    \"(\" ...\n",
      "    \"{\" ...\n",
      "    \"from\" ...\n",
      "    \"where\" ...\n",
      "    \"with\" ...\n",
      "    <VAR1> ...\n",
      "    <VAR2> ...\n",
      "    \n",
      "\tat com.bigdata.rdf.sail.sparql.Bigdata2ASTSPARQLParser.parseQuery2(Bigdata2ASTSPARQLParser.java:400)\n",
      "\tat com.bigdata.rdf.sail.webapp.QueryServlet$SparqlQueryTask.call(QueryServlet.java:741)\n",
      "\tat com.bigdata.rdf.sail.webapp.QueryServlet$SparqlQueryTask.call(QueryServlet.java:695)\n",
      "\tat com.bigdata.rdf.task.ApiTaskForIndexManager.call(ApiTaskForIndexManager.java:68)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: com.bigdata.rdf.sail.sparql.ast.ParseException: Encountered \" \"?\" \"? \"\" at line 6, column 78.\n",
      "Was expecting one of:\n",
      "    \"(\" ...\n",
      "    \"{\" ...\n",
      "    \"from\" ...\n",
      "    \"where\" ...\n",
      "    \"with\" ...\n",
      "    <VAR1> ...\n",
      "    <VAR2> ...\n",
      "    \n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.generateParseException(SyntaxTreeBuilder.java:9722)\n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.jj_consume_token(SyntaxTreeBuilder.java:9589)\n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.GroupGraphPattern(SyntaxTreeBuilder.java:1962)\n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.WhereClause(SyntaxTreeBuilder.java:1013)\n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.SelectQuery(SyntaxTreeBuilder.java:377)\n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.Query(SyntaxTreeBuilder.java:328)\n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.QueryContainer(SyntaxTreeBuilder.java:216)\n",
      "\tat com.bigdata.rdf.sail.sparql.ast.SyntaxTreeBuilder.parseQuery(SyntaxTreeBuilder.java:32)\n",
      "\tat com.bigdata.rdf.sail.sparql.Bigdata2ASTSPARQLParser.parseQuery2(Bigdata2ASTSPARQLParser.java:336)\n",
      "\t... 7 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_label = epochs_data[0][\"decoded_labels\"][row_number]\n",
    "decoded_pred = epochs_data[9][\"decoded_preds\"][row_number]\n",
    "\n",
    "sft_peft.start_tag = \"[sparql]\"\n",
    "sft_peft.end_tag = \"[/sparql]\"\n",
    "\n",
    "is_query_format_acceptable_label = is_query_format_acceptable(decoded_label)\n",
    "is_query_format_acceptable_pred = is_query_format_acceptable(decoded_pred)\n",
    "print(f\"Label is acceptable query: {is_query_format_acceptable_label}\")\n",
    "print(f\"Pred is acceptable query: {is_query_format_acceptable_pred}\")\n",
    "print()\n",
    "\n",
    "if not is_query_format_acceptable_label or not is_query_format_acceptable_pred:\n",
    "    raise Exception(\"Decoded label or pred is not a valid SPARQL query.\")\n",
    "\n",
    "pipelined_label = execute_pipeline([decoded_label])[0]\n",
    "pipelined_pred = execute_pipeline([decoded_pred])[0]\n",
    "\n",
    "print(f\"Pipelined label success: {not pipelined_label['has_error']}\")\n",
    "print(f\"Pipelined pred success: {not pipelined_pred['has_error']}\")\n",
    "print()\n",
    "\n",
    "if pipelined_label['has_error'] or pipelined_pred['has_error']:\n",
    "    raise Exception('Pipelined label or pred failed')\n",
    "\n",
    "output_label = pipelined_label.get('output', None)\n",
    "output_pred = pipelined_pred.get('output', None)\n",
    "\n",
    "# print(f\"Output Label: {output_label}\")\n",
    "# print(f\"Output Prediction: {output_pred}\")\n",
    "\n",
    "extracted_label = extract_query(output_label)\n",
    "extracted_pred = extract_query(output_pred)\n",
    "\n",
    "print(f\"Successfully extracted query label={extracted_label != None}\")\n",
    "print(f\"Successfully extracted query pred={extracted_pred != None}\")\n",
    "print()\n",
    "\n",
    "if extracted_label is None or extracted_pred is None:\n",
    "    raise Exception('Failed to extract query')\n",
    "\n",
    "print(\"Extracted Label\")\n",
    "print(f\"{extracted_label}\")\n",
    "print()\n",
    "print(\"Extracted Prediction\")\n",
    "print(f\"{extracted_pred}\")\n",
    "print()\n",
    "\n",
    "executed_label = execute_query(output_label)\n",
    "executed_pred  = execute_query(output_pred)\n",
    "\n",
    "print(\"executed_label\")\n",
    "print(f\"{executed_label if executed_label != None else 'Execution has failed!'}\")\n",
    "print()\n",
    "print(\"executed_pred\")\n",
    "print(f\"{executed_pred if executed_pred != None else 'Execution has failed!'}\")\n",
    "if executed_pred == None:\n",
    "    response = get_execution_response(output_pred)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, load_peft_weights\n",
    "from prompts_template import ELABORATE_INSTRUCTION, BASE_MISTRAL_TEMPLATE\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "adapter_path = \"../outputs/batch_run/learning_experiment_long_epochs_4/models/M-7B-I-v0.2_oawtor-rv256-rm1-ld0-bs2-ga8-gc1-p0-nta0-e10-ctx3072-qno-template-template-stsparql_adapters\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecbc7bb265d4233b28cd54e3c0d3207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=device,\n",
    "    torch_dtype=dtype,\n",
    ")\n",
    "\n",
    "try:\n",
    "    model = PeftModel.from_pretrained(model, adapter_path, is_trainable=False)\n",
    "except RuntimeError as e: # RuntimeError => Might be padding token is left in the embedding when saved\n",
    "    d_adpt = load_peft_weights(adapter_path)\n",
    "    len_d_adpt = len(d_adpt.get('base_model.model.lm_head.weight', 0))\n",
    "    if len_d_adpt != 0 and len_d_adpt != len(tokenizer):\n",
    "        model.resize_token_embeddings(len(tokenizer) + 1)\n",
    "        model = PeftModel.from_pretrained(model, adapter_path, is_trainable=False)\n",
    "    else:\n",
    "        raise e\n",
    "except Exception as e:\n",
    "    try:\n",
    "        model = PeftModel.from_pretrained(model, os.path.abspath(adapter_path), is_trainable=False)\n",
    "    except RuntimeError as e: # RuntimeError => Might be padding token is left in the embedding when saved\n",
    "        d_adpt = load_peft_weights(adapter_path)\n",
    "        len_d_adpt = len(d_adpt.get('base_model.model.lm_head.weight', 0))\n",
    "        if len_d_adpt != 0 and len_d_adpt != len(tokenizer):\n",
    "            model.resize_token_embeddings(len(tokenizer) + 1)\n",
    "            model = PeftModel.from_pretrained(model, os.path.abspath(adapter_path), is_trainable=False)\n",
    "        else:\n",
    "            raise e\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_adpt = load_peft_weights(adapter_path)\n",
    "len(d_adpt.get('base_model.model.lm_head.weight', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_model.model.lm_head.weight',\n",
       " 'base_model.model.model.embed_tokens.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight',\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight',\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d_adpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32000, 4096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "modified_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified_tokenizer.pad_token='[PAD]'\n",
      "modified_tokenizer.pad_token_id=32000\n"
     ]
    }
   ],
   "source": [
    "print(f\"{modified_tokenizer.pad_token=}\")\n",
    "print(f\"{modified_tokenizer.pad_token_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from generate_finetune_dataset import keep_working_queries\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>description</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>start_with_SELECT</th>\n",
       "      <th>query_templated</th>\n",
       "      <th>basic_prompt</th>\n",
       "      <th>basic_num_tokens</th>\n",
       "      <th>basic_result</th>\n",
       "      <th>...</th>\n",
       "      <th>basic_is_skipped</th>\n",
       "      <th>basic_is_prompt_too_long</th>\n",
       "      <th>templated_prompt</th>\n",
       "      <th>templated_num_tokens</th>\n",
       "      <th>templated_result</th>\n",
       "      <th>templated_full_answer</th>\n",
       "      <th>templated_is_skipped</th>\n",
       "      <th>templated_is_prompt_too_long</th>\n",
       "      <th>execution</th>\n",
       "      <th>executed_query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT ?property ?propertyType ?propertyLabel ...</td>\n",
       "      <td>Wikidata properties in numerical order</td>\n",
       "      <td>Counting stuff on Wikidata\\nAll Wikidata prope...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>267</td>\n",
       "      <td>True</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"SELECT ?property ?propertyTyp...</td>\n",
       "      <td>226</td>\n",
       "      <td>[\"Write a SparQL query to retrieve Wikidata pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"PREFIX bd: &lt;http://www.bigdat...</td>\n",
       "      <td>289</td>\n",
       "      <td>[\"Write a SparQL query to retrieve all Wikidat...</td>\n",
       "      <td>{'content': ' 1. \"Write a SparQL query to retr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'property': {'type': 'uri', 'value': 'http:/...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT ?id ?idLabel ?idDescription ?new{\\n?id ...</td>\n",
       "      <td>Wikidata properties excluding external IDs</td>\n",
       "      <td>Counting stuff on Wikidata\\nVariation of the a...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>296</td>\n",
       "      <td>True</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"SELECT ?id ?idLabel ?idDescri...</td>\n",
       "      <td>259</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the ID, lab...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"PREFIX bd: &lt;http://www.bigdat...</td>\n",
       "      <td>322</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the ID, lab...</td>\n",
       "      <td>{'content': ' 1. \"Write a SparQL query to retr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'id': {'type': 'uri', 'value': 'http://www.w...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT (COUNT(?article) AS ?count)\\nWHERE {\\n?...</td>\n",
       "      <td></td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of scientifi...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>197</td>\n",
       "      <td>True</td>\n",
       "      <td>PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\\n...</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"SELECT (COUNT(?article) AS ?c...</td>\n",
       "      <td>159</td>\n",
       "      <td>[\"Find the total number of scientific articles...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"PREFIX wd: &lt;http://www.wikida...</td>\n",
       "      <td>201</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the count o...</td>\n",
       "      <td>{'content': ' 1. \"Write a SparQL query to retr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>timeout</td>\n",
       "      <td>PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT (COUNT(DISTINCT ?article) AS ?count)\\nW...</td>\n",
       "      <td>Count of fictional characters</td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of fictional...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>203</td>\n",
       "      <td>True</td>\n",
       "      <td>PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\\n...</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"SELECT (COUNT(DISTINCT ?artic...</td>\n",
       "      <td>165</td>\n",
       "      <td>[\"Find the number of distinct fictional charac...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"PREFIX wd: &lt;http://www.wikida...</td>\n",
       "      <td>210</td>\n",
       "      <td>[\"Write a query to find the total number of di...</td>\n",
       "      <td>{'content': ' 1. \"Write a query to find the to...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'count': {'datatype': 'http://www.w3.org/200...</td>\n",
       "      <td>PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT (COUNT(?item) AS ?count)\\nWHERE { ?item...</td>\n",
       "      <td>Count of items with coordinate locations</td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of items wit...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>186</td>\n",
       "      <td>True</td>\n",
       "      <td>PREFIX wdt: &lt;http://www.wikidata.org/prop/dire...</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"SELECT (COUNT(?item) AS ?coun...</td>\n",
       "      <td>148</td>\n",
       "      <td>[\"How many items in Wikidata have recorded coo...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;s&gt;[INST] QUERY=\"PREFIX wdt: &lt;http://www.wikid...</td>\n",
       "      <td>172</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the number ...</td>\n",
       "      <td>{'content': ' 1. \"Write a SparQL query to retr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'count': {'datatype': 'http://www.w3.org/200...</td>\n",
       "      <td>PREFIX wdt: &lt;http://www.wikidata.org/prop/dire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   query  \\\n",
       "index                                                      \n",
       "0      SELECT ?property ?propertyType ?propertyLabel ...   \n",
       "1      SELECT ?id ?idLabel ?idDescription ?new{\\n?id ...   \n",
       "2      SELECT (COUNT(?article) AS ?count)\\nWHERE {\\n?...   \n",
       "3      SELECT (COUNT(DISTINCT ?article) AS ?count)\\nW...   \n",
       "4      SELECT (COUNT(?item) AS ?count)\\nWHERE { ?item...   \n",
       "\n",
       "                                      description  \\\n",
       "index                                               \n",
       "0          Wikidata properties in numerical order   \n",
       "1      Wikidata properties excluding external IDs   \n",
       "2                                                   \n",
       "3                   Count of fictional characters   \n",
       "4        Count of items with coordinate locations   \n",
       "\n",
       "                                                 context  \\\n",
       "index                                                      \n",
       "0      Counting stuff on Wikidata\\nAll Wikidata prope...   \n",
       "1      Counting stuff on Wikidata\\nVariation of the a...   \n",
       "2      Counting stuff on Wikidata\\nCount of scientifi...   \n",
       "3      Counting stuff on Wikidata\\nCount of fictional...   \n",
       "4      Counting stuff on Wikidata\\nCount of items wit...   \n",
       "\n",
       "                                                  prompt  num_tokens  \\\n",
       "index                                                                  \n",
       "0      <s>[INST] <<SYS>>This is a conversation betwee...         267   \n",
       "1      <s>[INST] <<SYS>>This is a conversation betwee...         296   \n",
       "2      <s>[INST] <<SYS>>This is a conversation betwee...         197   \n",
       "3      <s>[INST] <<SYS>>This is a conversation betwee...         203   \n",
       "4      <s>[INST] <<SYS>>This is a conversation betwee...         186   \n",
       "\n",
       "       start_with_SELECT                                    query_templated  \\\n",
       "index                                                                         \n",
       "0                   True  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "1                   True  PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2                   True  PREFIX wd: <http://www.wikidata.org/entity/>\\n...   \n",
       "3                   True  PREFIX wd: <http://www.wikidata.org/entity/>\\n...   \n",
       "4                   True  PREFIX wdt: <http://www.wikidata.org/prop/dire...   \n",
       "\n",
       "                                            basic_prompt  basic_num_tokens  \\\n",
       "index                                                                        \n",
       "0      <s>[INST] QUERY=\"SELECT ?property ?propertyTyp...               226   \n",
       "1      <s>[INST] QUERY=\"SELECT ?id ?idLabel ?idDescri...               259   \n",
       "2      <s>[INST] QUERY=\"SELECT (COUNT(?article) AS ?c...               159   \n",
       "3      <s>[INST] QUERY=\"SELECT (COUNT(DISTINCT ?artic...               165   \n",
       "4      <s>[INST] QUERY=\"SELECT (COUNT(?item) AS ?coun...               148   \n",
       "\n",
       "                                            basic_result  ...  \\\n",
       "index                                                     ...   \n",
       "0      [\"Write a SparQL query to retrieve Wikidata pr...  ...   \n",
       "1      [\"Write a SparQL query to retrieve the ID, lab...  ...   \n",
       "2      [\"Find the total number of scientific articles...  ...   \n",
       "3      [\"Find the number of distinct fictional charac...  ...   \n",
       "4      [\"How many items in Wikidata have recorded coo...  ...   \n",
       "\n",
       "      basic_is_skipped  basic_is_prompt_too_long  \\\n",
       "index                                              \n",
       "0                False                     False   \n",
       "1                False                     False   \n",
       "2                False                     False   \n",
       "3                False                     False   \n",
       "4                False                     False   \n",
       "\n",
       "                                        templated_prompt templated_num_tokens  \\\n",
       "index                                                                           \n",
       "0      <s>[INST] QUERY=\"PREFIX bd: <http://www.bigdat...                  289   \n",
       "1      <s>[INST] QUERY=\"PREFIX bd: <http://www.bigdat...                  322   \n",
       "2      <s>[INST] QUERY=\"PREFIX wd: <http://www.wikida...                  201   \n",
       "3      <s>[INST] QUERY=\"PREFIX wd: <http://www.wikida...                  210   \n",
       "4      <s>[INST] QUERY=\"PREFIX wdt: <http://www.wikid...                  172   \n",
       "\n",
       "                                        templated_result  \\\n",
       "index                                                      \n",
       "0      [\"Write a SparQL query to retrieve all Wikidat...   \n",
       "1      [\"Write a SparQL query to retrieve the ID, lab...   \n",
       "2      [\"Write a SparQL query to retrieve the count o...   \n",
       "3      [\"Write a query to find the total number of di...   \n",
       "4      [\"Write a SparQL query to retrieve the number ...   \n",
       "\n",
       "                                   templated_full_answer templated_is_skipped  \\\n",
       "index                                                                           \n",
       "0      {'content': ' 1. \"Write a SparQL query to retr...                False   \n",
       "1      {'content': ' 1. \"Write a SparQL query to retr...                False   \n",
       "2      {'content': ' 1. \"Write a SparQL query to retr...                False   \n",
       "3      {'content': ' 1. \"Write a query to find the to...                False   \n",
       "4      {'content': ' 1. \"Write a SparQL query to retr...                False   \n",
       "\n",
       "       templated_is_prompt_too_long  \\\n",
       "index                                 \n",
       "0                             False   \n",
       "1                             False   \n",
       "2                             False   \n",
       "3                             False   \n",
       "4                             False   \n",
       "\n",
       "                                               execution  \\\n",
       "index                                                      \n",
       "0      [{'property': {'type': 'uri', 'value': 'http:/...   \n",
       "1      [{'id': {'type': 'uri', 'value': 'http://www.w...   \n",
       "2                                                timeout   \n",
       "3      [{'count': {'datatype': 'http://www.w3.org/200...   \n",
       "4      [{'count': {'datatype': 'http://www.w3.org/200...   \n",
       "\n",
       "                                          executed_query  \n",
       "index                                                     \n",
       "0      PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "1      PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "2      PREFIX wd: <http://www.wikidata.org/entity/>\\n...  \n",
       "3      PREFIX wd: <http://www.wikidata.org/entity/>\\n...  \n",
       "4      PREFIX wdt: <http://www.wikidata.org/prop/dire...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"../outputs/dataset_pipeline/fq17_3/fq17_3-generated_prompt-executed.parquet.gzip\")\n",
    "if not path.exists():\n",
    "    raise FileExistsError(f\"No file was found at this path: {path}\")\n",
    "\n",
    "dataset = load_dataset(path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'description', 'context', 'prompt', 'num_tokens',\n",
       "       'start_with_SELECT', 'query_templated', 'basic_prompt',\n",
       "       'basic_num_tokens', 'basic_result', 'basic_full_answer',\n",
       "       'basic_is_skipped', 'basic_is_prompt_too_long', 'templated_prompt',\n",
       "       'templated_num_tokens', 'templated_result', 'templated_full_answer',\n",
       "       'templated_is_skipped', 'templated_is_prompt_too_long', 'execution',\n",
       "       'executed_query'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>templated_result</th>\n",
       "      <th>query_templated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Write a SparQL query to retrieve all Wikidat...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Write a SparQL query to retrieve the ID, lab...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Write a query to find the total number of di...</td>\n",
       "      <td>PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Write a SparQL query to retrieve the number ...</td>\n",
       "      <td>PREFIX wdt: &lt;http://www.wikidata.org/prop/dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[\"Write a SparQL query to retrieve the number ...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        templated_result  \\\n",
       "index                                                      \n",
       "0      [\"Write a SparQL query to retrieve all Wikidat...   \n",
       "1      [\"Write a SparQL query to retrieve the ID, lab...   \n",
       "3      [\"Write a query to find the total number of di...   \n",
       "4      [\"Write a SparQL query to retrieve the number ...   \n",
       "5      [\"Write a SparQL query to retrieve the number ...   \n",
       "\n",
       "                                         query_templated  \n",
       "index                                                     \n",
       "0      PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "1      PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  \n",
       "3      PREFIX wd: <http://www.wikidata.org/entity/>\\n...  \n",
       "4      PREFIX wdt: <http://www.wikidata.org/prop/dire...  \n",
       "5      PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_dataset = keep_working_queries(dataset)\n",
    "\n",
    "columns_to_take = [\n",
    "    \"templated_result\",\n",
    "    \"query_templated\",\n",
    "]\n",
    "\n",
    "dataset_for_tokenization = dropped_dataset[columns_to_take]\n",
    "dataset_for_tokenization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_concat_dataset)=2294959\n"
     ]
    }
   ],
   "source": [
    "all_concat_dataset = dataset_for_tokenization.apply(lambda x: x['templated_result'][0].strip() + x[\"query_templated\"].strip(), axis=1).sum()\n",
    "print(f\"{len(all_concat_dataset)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.2', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(all_concat_dataset)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokens.tokens())=824341\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(tokens.tokens())=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry n°353\n",
      "----- Prompts From Original -----\n",
      "\"Write a SPARQL query to retrieve all books with a title, illustrator, publisher, and publication date, but allow for the possibility that some books may not have an illustrator or publisher listed.\"\n",
      "\"Create a SPARQL query to find all books with a title, optional illustrator and publisher information, and a publication date.\"\n",
      "\"Generate a SPARQL query to retrieve books with required title, publication date, and optional illustrator and publisher information.\"\n",
      "----- Original Query -----\n",
      "SELECT ?book ?title ?illustratorLabel ?publisherLabel ?published\n",
      "WHERE\n",
      "{\n",
      "?book wdt:P50 wd:Q35610. # required wdt:P50\n",
      "OPTIONAL { # match all or none from group:\n",
      "?book wdt:P1476 ?title; # required wdt:P1476\n",
      "wdt:P110 ?illustrator; # required wdt:P110\n",
      "wdt:P123 ?publisher; # required wdt:P123\n",
      "wdt:P577 ?published. # required wdt:P577\n",
      "}\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "} \n",
      "\n",
      "----- Prompts From Templated -----\n",
      "\"Write a SPARQL query to retrieve books authored by Arthur Conan Doyle, along with their titles, illustrators, publishers, and publication dates if available.\"\n",
      "\"Create a SPARQL query that returns all books with an author of 'Arthur Conan Doyle', as well as their optional title, illustrator, publisher, and publication date information.\"\n",
      "----- Templated Query -----\n",
      "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?book ?title ?illustratorLabel ?publisherLabel ?published\n",
      "WHERE\n",
      "{\n",
      "?book wdt:[property:author] wd:[entity:Arthur Conan Doyle]. # required wdt:[property:author]\n",
      "OPTIONAL { # match all or none from group:\n",
      "?book wdt:[property:title] ?title; # required wdt:[property:title]\n",
      "wdt:[property:illustrator] ?illustrator; # required wdt:[property:illustrator]\n",
      "wdt:[property:publisher] ?publisher; # required wdt:[property:publisher]\n",
      "wdt:[property:publication date] ?published. # required wdt:[property:publication date]\n",
      "}\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "entry_iloc_id = random.randint(0, len(dropped_dataset) - 1)\n",
    "entry = dropped_dataset.iloc[entry_iloc_id]\n",
    "print(f\"Entry n°{entry_iloc_id}\")\n",
    "print(\"----- Prompts From Original -----\")\n",
    "print(\"\\n\".join(entry[\"basic_result\"]))\n",
    "print(\"----- Original Query -----\")\n",
    "print(entry[\"query\"], \"\\n\")\n",
    "print(\"----- Prompts From Templated -----\")\n",
    "print(\"\\n\".join(entry[\"templated_result\"]))\n",
    "print(\"----- Templated Query -----\")\n",
    "print(entry[\"query_templated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'description', 'context', 'prompt', 'num_tokens',\n",
       "       'start_with_SELECT', 'query_templated', 'basic_prompt',\n",
       "       'basic_num_tokens', 'basic_result', 'basic_full_answer',\n",
       "       'basic_is_skipped', 'basic_is_prompt_too_long', 'templated_prompt',\n",
       "       'templated_num_tokens', 'templated_result', 'templated_full_answer',\n",
       "       'templated_is_skipped', 'templated_is_prompt_too_long', 'execution',\n",
       "       'executed_query'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] QUERY=\"PREFIX bd: <http://www.bigdata.com/rdf#>\n",
      "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "\n",
      "SELECT ?property ?propertyType ?propertyLabel ?propertyDescription WHERE {\n",
      "?property wikibase:propertyType ?propertyType .\n",
      "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "} ORDER BY ASC(xsd:integer(STRAFTER(STR(?property), 'P')))\" DESCRIPTION=\"Wikidata properties in numerical order\" CONTEXT=\"Counting stuff on Wikidata\n",
      "All Wikidata properties with label and description, ordered numerically\n",
      "Adapted from one of the Query Service Examples\" Read QUERY, DESCRIPTION, and CONTEXT. There is a machine capable of writing the given SparQL QUERY if we provide the correct prompt. A prompt should be at least one sentence and no longer than five sentences. Each prompt must be enclosed in quotation marks. Provide a list of three prompts that would elicit the QUERY. [/INST]\n",
      "['\"Write a SparQL query to retrieve all Wikidata properties with their labels and descriptions, ordered numerically.\"', '\"Create a query that returns the property name, type, label, and description for each Wikidata property in numerical order.\"', '\"Generate a SparQL query to extract the label and description of Wikidata properties, sorted by their numerical identifiers. Use prefixes for Big Data, XML Schema, and Wikibase ontology.\"']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['templated_prompt'].iloc[0])\n",
    "print(dataset['templated_result'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n",
      "description\n",
      "context\n",
      "prompt\n",
      "num_tokens\n",
      "start_with_SELECT\n",
      "query_templated\n",
      "basic_prompt\n",
      "basic_num_tokens\n",
      "basic_result\n",
      "basic_full_answer\n",
      "basic_is_skipped\n",
      "basic_is_prompt_too_long\n",
      "templated_prompt\n",
      "templated_num_tokens\n",
      "templated_result\n",
      "templated_full_answer\n",
      "templated_is_skipped\n",
      "templated_is_prompt_too_long\n",
      "execution\n",
      "executed_query\n"
     ]
    }
   ],
   "source": [
    "QUERY=\"PREFIX bd: <http://www.bigdata.com/rdf#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "\n",
    "SELECT ?property ?propertyType ?propertyLabel ?propertyDescription WHERE {\n",
    "?property wikibase:propertyType ?propertyType .\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "} ORDER BY ASC(xsd:integer(STRAFTER(STR(?property), 'P')))\" DESCRIPTION=\"Wikidata properties in numerical order\" CONTEXT=\"Counting stuff on Wikidata\n",
    "All Wikidata properties with label and description, ordered numerically\n",
    "Adapted from one of the Query Service Examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<s> [INST] Your assignment involves a two-step process:                                                                                    \n",
    "First, you will receive a task described in a single sentence. This task outlines what information you need to find or what question you need to answer.                        \n",
    "Then, you will create a SPARQL Query: Based on the task given, you will write a SPARQL query. SPARQL is a specialized query language used to retrieve and manipulate data stored\n",
    " in Resource Description Framework (RDF) format. Your goal is to craft a query that, when executed, fetches the data or answers required by the initial instruction.\n",
    "Make sure your SPARQL query is correctly formulated so that, upon execution, it produces the desired result matching the task's requirements.\n",
    "Answer this following instruction:                                                      \n",
    "\"Write a SparQL query to find the top 10 properties that connect warriors or military personnel to military organizations in Wikidata, ordered by frequency of usage.\"\n",
    "[/INST] [sparql]PREFIX bd: <http://www.bigdata.com/rdf#>\n",
    "PREFIX hint: <http://www.bigdata.com/queryHints#>\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>                                                                                                                                    \n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>                                                                                                                                   \n",
    "                                            \n",
    "SELECT ?count ?property ?propertyLabel ?samp WHERE {                                                                                                                            \n",
    "{                                                                                       \n",
    "SELECT (COUNT(?item) AS ?count) ?property (SAMPLE(?item) AS ?samp) WHERE {                                                                                                      \n",
    "hint:Query hint:optimizer \"None\".  \n",
    "?org_class wdt:[property:subclass of]* wd:[entity:armed organization].                                                                                                          \n",
    "?org wdt:[property:instance of]? ?org_class .\n",
    "?item ?prop ?org .                                                                      \n",
    "?item wdt:[property:occupation] ?role .\n",
    "?role wdt:[property:subclass of]* wd:[entity:warrior] .                                                                                                                         \n",
    "?property wikibase:directClaim ?prop .\n",
    "} GROUP BY ?property                                                                                                                                                            \n",
    "}                                                                                                                                                                               \n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}                                 \n",
    "ORDER BY DESC (?count)[/sparql]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/CodeLlama-7b-Instruct-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 518, 29914, 25580, 29962], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"[/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1, 29871, 518, 25580, 29962, 3575, 12827, 20789, 263, 1023, 29899, 10568, 1889, 29901, 462, 462, 462, 462, 462, 268, 13, 6730, 29892, 366, 674, 7150, 263, 3414, 5439, 297, 263, 2323, 10541, 29889, 910, 3414, 714, 9012, 825, 2472, 366, 817, 304, 1284, 470, 825, 1139, 366, 817, 304, 1234, 29889, 462, 308, 13, 11760, 29892, 366, 674, 1653, 263, 10937, 1718, 2239, 13641, 29901, 16564, 373, 278, 3414, 2183, 29892, 366, 674, 2436, 263, 10937, 1718, 2239, 2346, 29889, 10937, 1718, 2239, 338, 263, 4266, 1891, 2346, 4086, 1304, 304, 10563, 322, 26749, 848, 6087, 13, 297, 18981, 12953, 16657, 313, 29934, 4037, 29897, 3402, 29889, 3575, 7306, 338, 304, 25554, 263, 2346, 393, 29892, 746, 8283, 29892, 6699, 267, 278, 848, 470, 6089, 3734, 491, 278, 2847, 15278, 29889, 13, 9984, 1854, 596, 10937, 1718, 2239, 2346, 338, 5149, 883, 7964, 577, 393, 29892, 2501, 8225, 29892, 372, 13880, 278, 7429, 1121, 9686, 278, 3414, 29915, 29879, 11780, 29889, 13, 22550, 445, 1494, 15278, 29901, 462, 462, 462, 539, 13, 29908, 6113, 263, 317, 862, 2239, 2346, 304, 1284, 278, 2246, 29871, 29896, 29900, 4426, 393, 4511, 1370, 28739, 470, 9121, 24127, 304, 9121, 25700, 297, 3772, 333, 532, 29892, 10372, 491, 10868, 310, 8744, 1213, 13, 29961, 29914, 25580, 29962, 518, 29879, 862, 1519, 29962, 15094, 25634, 289, 29881, 29901, 529, 1124, 597, 1636, 29889, 3752, 1272, 29889, 510, 29914, 29878, 2176, 29937, 29958, 13, 15094, 25634, 13182, 29901, 529, 1124, 597, 1636, 29889, 3752, 1272, 29889, 510, 29914, 1972, 29950, 9466, 29937, 29958, 13, 15094, 25634, 281, 29881, 29901, 529, 1124, 597, 1636, 29889, 2851, 333, 532, 29889, 990, 29914, 10041, 3779, 462, 462, 462, 462, 462, 462, 462, 462, 268, 13, 15094, 25634, 281, 6008, 29901, 529, 1124, 597, 1636, 29889, 2851, 333, 532, 29889, 990, 29914, 7728, 29914, 11851, 3779, 13, 15094, 25634, 281, 638, 747, 559, 29901, 529, 1124, 597, 2851, 16912, 29889, 344, 29914, 609, 3002, 29937, 29958, 462, 462, 462, 462, 462, 462, 462, 462, 1678, 13, 462, 462, 632, 13, 6404, 1577, 2798, 1577, 6799, 1577, 6799, 4775, 1577, 29879, 1160, 5754, 426, 462, 462, 462, 462, 462, 462, 462, 632, 13, 29912, 462, 462, 462, 462, 462, 4706, 13, 6404, 313, 18736, 10780, 667, 29897, 3339, 1577, 2798, 29897, 1577, 6799, 313, 8132, 3580, 1307, 10780, 667, 29897, 3339, 1577, 29879, 1160, 29897, 5754, 426, 462, 462, 462, 462, 462, 462, 539, 13, 29882, 524, 29901, 3010, 13182, 29901, 20640, 3950, 376, 8516, 1642, 259, 13, 29973, 990, 29918, 1990, 281, 6008, 10834, 6799, 29901, 1491, 1990, 310, 14178, 281, 29881, 10834, 10041, 29901, 279, 2168, 13013, 1822, 462, 462, 462, 462, 462, 462, 965, 13, 29973, 990, 281, 6008, 10834, 6799, 29901, 8758, 310, 29962, 29973, 1577, 990, 29918, 1990, 869, 13, 29973, 667, 1577, 7728, 1577, 990, 869, 462, 462, 462, 462, 539, 13, 29973, 667, 281, 6008, 10834, 6799, 29901, 26601, 29962, 1577, 12154, 869, 13, 29973, 12154, 281, 6008, 10834, 6799, 29901, 1491, 1990, 310, 14178, 281, 29881, 10834, 10041, 29901, 4495, 13479, 29962, 869, 462, 462, 462, 462, 462, 462, 462, 3986, 13, 29973, 6799, 281, 638, 747, 559, 29901, 11851, 29907, 8342, 1577, 7728, 869, 13, 29913, 15345, 6770, 1577, 6799, 462, 462, 462, 462, 462, 462, 462, 462, 462, 632, 13, 29913, 462, 462, 462, 462, 462, 462, 462, 462, 462, 462, 18884, 13, 6304, 19059, 281, 638, 747, 559, 29901, 1643, 426, 289, 29881, 29901, 5509, 4736, 281, 638, 747, 559, 29901, 11675, 14704, 20656, 29949, 29918, 29931, 19453, 29965, 10461, 1402, 264, 1642, 500, 13, 29913, 462, 462, 29871, 13, 22364, 6770, 23050, 22308, 2798, 9601, 29914, 29879, 862, 1519, 29962], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 => <s>\n",
      "1 => <s>\n",
      "29871 => \n",
      "518 => [\n",
      "25580 => INST\n",
      "29962 => ]\n",
      "3575 => Your\n",
      "12827 => assignment\n",
      "20789 => involves\n",
      "263 => a\n",
      "1023 => two\n",
      "29899 => -\n",
      "10568 => step\n",
      "1889 => process\n",
      "29901 => :\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "268 =>    \n",
      "13 => \n",
      "\n",
      "6730 => First\n",
      "29892 => ,\n",
      "366 => you\n",
      "674 => will\n",
      "7150 => receive\n",
      "263 => a\n",
      "3414 => task\n",
      "5439 => described\n",
      "297 => in\n",
      "263 => a\n",
      "2323 => single\n",
      "10541 => sentence\n",
      "29889 => .\n",
      "910 => This\n",
      "3414 => task\n",
      "714 => out\n",
      "9012 => lines\n",
      "825 => what\n",
      "2472 => information\n",
      "366 => you\n",
      "817 => need\n",
      "304 => to\n",
      "1284 => find\n",
      "470 => or\n",
      "825 => what\n",
      "1139 => question\n",
      "366 => you\n",
      "817 => need\n",
      "304 => to\n",
      "1234 => answer\n",
      "29889 => .\n",
      "462 =>                \n",
      "308 =>        \n",
      "13 => \n",
      "\n",
      "11760 => Then\n",
      "29892 => ,\n",
      "366 => you\n",
      "674 => will\n",
      "1653 => create\n",
      "263 => a\n",
      "10937 => SP\n",
      "1718 => AR\n",
      "2239 => QL\n",
      "13641 => Query\n",
      "29901 => :\n",
      "16564 => Based\n",
      "373 => on\n",
      "278 => the\n",
      "3414 => task\n",
      "2183 => given\n",
      "29892 => ,\n",
      "366 => you\n",
      "674 => will\n",
      "2436 => write\n",
      "263 => a\n",
      "10937 => SP\n",
      "1718 => AR\n",
      "2239 => QL\n",
      "2346 => query\n",
      "29889 => .\n",
      "10937 => SP\n",
      "1718 => AR\n",
      "2239 => QL\n",
      "338 => is\n",
      "263 => a\n",
      "4266 => special\n",
      "1891 => ized\n",
      "2346 => query\n",
      "4086 => language\n",
      "1304 => used\n",
      "304 => to\n",
      "10563 => retrieve\n",
      "322 => and\n",
      "26749 => manipulate\n",
      "848 => data\n",
      "6087 => stored\n",
      "13 => \n",
      "\n",
      "297 => in\n",
      "18981 => Resource\n",
      "12953 => Description\n",
      "16657 => Framework\n",
      "313 => (\n",
      "29934 => R\n",
      "4037 => DF\n",
      "29897 => )\n",
      "3402 => format\n",
      "29889 => .\n",
      "3575 => Your\n",
      "7306 => goal\n",
      "338 => is\n",
      "304 => to\n",
      "25554 => craft\n",
      "263 => a\n",
      "2346 => query\n",
      "393 => that\n",
      "29892 => ,\n",
      "746 => when\n",
      "8283 => executed\n",
      "29892 => ,\n",
      "6699 => fetch\n",
      "267 => es\n",
      "278 => the\n",
      "848 => data\n",
      "470 => or\n",
      "6089 => answers\n",
      "3734 => required\n",
      "491 => by\n",
      "278 => the\n",
      "2847 => initial\n",
      "15278 => instruction\n",
      "29889 => .\n",
      "13 => \n",
      "\n",
      "9984 => Make\n",
      "1854 => sure\n",
      "596 => your\n",
      "10937 => SP\n",
      "1718 => AR\n",
      "2239 => QL\n",
      "2346 => query\n",
      "338 => is\n",
      "5149 => correctly\n",
      "883 => form\n",
      "7964 => ulated\n",
      "577 => so\n",
      "393 => that\n",
      "29892 => ,\n",
      "2501 => upon\n",
      "8225 => execution\n",
      "29892 => ,\n",
      "372 => it\n",
      "13880 => produces\n",
      "278 => the\n",
      "7429 => desired\n",
      "1121 => result\n",
      "9686 => matching\n",
      "278 => the\n",
      "3414 => task\n",
      "29915 => '\n",
      "29879 => s\n",
      "11780 => requirements\n",
      "29889 => .\n",
      "13 => \n",
      "\n",
      "22550 => Answer\n",
      "445 => this\n",
      "1494 => following\n",
      "15278 => instruction\n",
      "29901 => :\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "539 =>      \n",
      "13 => \n",
      "\n",
      "29908 => \"\n",
      "6113 => Write\n",
      "263 => a\n",
      "317 => S\n",
      "862 => par\n",
      "2239 => QL\n",
      "2346 => query\n",
      "304 => to\n",
      "1284 => find\n",
      "278 => the\n",
      "2246 => top\n",
      "29871 => \n",
      "29896 => 1\n",
      "29900 => 0\n",
      "4426 => properties\n",
      "393 => that\n",
      "4511 => connect\n",
      "1370 => war\n",
      "28739 => riors\n",
      "470 => or\n",
      "9121 => military\n",
      "24127 => personnel\n",
      "304 => to\n",
      "9121 => military\n",
      "25700 => organizations\n",
      "297 => in\n",
      "3772 => Wik\n",
      "333 => id\n",
      "532 => ata\n",
      "29892 => ,\n",
      "10372 => ordered\n",
      "491 => by\n",
      "10868 => frequency\n",
      "310 => of\n",
      "8744 => usage\n",
      "1213 => .\"\n",
      "13 => \n",
      "\n",
      "29961 => [\n",
      "29914 => /\n",
      "25580 => INST\n",
      "29962 => ]\n",
      "518 => [\n",
      "29879 => s\n",
      "862 => par\n",
      "1519 => ql\n",
      "29962 => ]\n",
      "15094 => PRE\n",
      "25634 => FIX\n",
      "289 => b\n",
      "29881 => d\n",
      "29901 => :\n",
      "529 => <\n",
      "1124 => http\n",
      "597 => ://\n",
      "1636 => www\n",
      "29889 => .\n",
      "3752 => big\n",
      "1272 => data\n",
      "29889 => .\n",
      "510 => com\n",
      "29914 => /\n",
      "29878 => r\n",
      "2176 => df\n",
      "29937 => #\n",
      "29958 => >\n",
      "13 => \n",
      "\n",
      "15094 => PRE\n",
      "25634 => FIX\n",
      "13182 => hint\n",
      "29901 => :\n",
      "529 => <\n",
      "1124 => http\n",
      "597 => ://\n",
      "1636 => www\n",
      "29889 => .\n",
      "3752 => big\n",
      "1272 => data\n",
      "29889 => .\n",
      "510 => com\n",
      "29914 => /\n",
      "1972 => query\n",
      "29950 => H\n",
      "9466 => ints\n",
      "29937 => #\n",
      "29958 => >\n",
      "13 => \n",
      "\n",
      "15094 => PRE\n",
      "25634 => FIX\n",
      "281 => w\n",
      "29881 => d\n",
      "29901 => :\n",
      "529 => <\n",
      "1124 => http\n",
      "597 => ://\n",
      "1636 => www\n",
      "29889 => .\n",
      "2851 => wik\n",
      "333 => id\n",
      "532 => ata\n",
      "29889 => .\n",
      "990 => org\n",
      "29914 => /\n",
      "10041 => entity\n",
      "3779 => />\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "268 =>    \n",
      "13 => \n",
      "\n",
      "15094 => PRE\n",
      "25634 => FIX\n",
      "281 => w\n",
      "6008 => dt\n",
      "29901 => :\n",
      "529 => <\n",
      "1124 => http\n",
      "597 => ://\n",
      "1636 => www\n",
      "29889 => .\n",
      "2851 => wik\n",
      "333 => id\n",
      "532 => ata\n",
      "29889 => .\n",
      "990 => org\n",
      "29914 => /\n",
      "7728 => prop\n",
      "29914 => /\n",
      "11851 => direct\n",
      "3779 => />\n",
      "13 => \n",
      "\n",
      "15094 => PRE\n",
      "25634 => FIX\n",
      "281 => w\n",
      "638 => ik\n",
      "747 => ib\n",
      "559 => ase\n",
      "29901 => :\n",
      "529 => <\n",
      "1124 => http\n",
      "597 => ://\n",
      "2851 => wik\n",
      "16912 => iba\n",
      "29889 => .\n",
      "344 => se\n",
      "29914 => /\n",
      "609 => ont\n",
      "3002 => ology\n",
      "29937 => #\n",
      "29958 => >\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "1678 =>   \n",
      "13 => \n",
      "\n",
      "462 =>                \n",
      "462 =>                \n",
      "632 =>            \n",
      "13 => \n",
      "\n",
      "6404 => SELECT\n",
      "1577 => ?\n",
      "2798 => count\n",
      "1577 => ?\n",
      "6799 => property\n",
      "1577 => ?\n",
      "6799 => property\n",
      "4775 => Label\n",
      "1577 => ?\n",
      "29879 => s\n",
      "1160 => amp\n",
      "5754 => WHERE\n",
      "426 => {\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "632 =>            \n",
      "13 => \n",
      "\n",
      "29912 => {\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "4706 =>       \n",
      "13 => \n",
      "\n",
      "6404 => SELECT\n",
      "313 => (\n",
      "18736 => COUNT\n",
      "10780 => (?\n",
      "667 => item\n",
      "29897 => )\n",
      "3339 => AS\n",
      "1577 => ?\n",
      "2798 => count\n",
      "29897 => )\n",
      "1577 => ?\n",
      "6799 => property\n",
      "313 => (\n",
      "8132 => SA\n",
      "3580 => MP\n",
      "1307 => LE\n",
      "10780 => (?\n",
      "667 => item\n",
      "29897 => )\n",
      "3339 => AS\n",
      "1577 => ?\n",
      "29879 => s\n",
      "1160 => amp\n",
      "29897 => )\n",
      "5754 => WHERE\n",
      "426 => {\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "539 =>      \n",
      "13 => \n",
      "\n",
      "29882 => h\n",
      "524 => int\n",
      "29901 => :\n",
      "3010 => Query\n",
      "13182 => hint\n",
      "29901 => :\n",
      "20640 => optim\n",
      "3950 => izer\n",
      "376 => \"\n",
      "8516 => None\n",
      "1642 => \".\n",
      "259 =>  \n",
      "13 => \n",
      "\n",
      "29973 => ?\n",
      "990 => org\n",
      "29918 => _\n",
      "1990 => class\n",
      "281 => w\n",
      "6008 => dt\n",
      "10834 => :[\n",
      "6799 => property\n",
      "29901 => :\n",
      "1491 => sub\n",
      "1990 => class\n",
      "310 => of\n",
      "14178 => ]*\n",
      "281 => w\n",
      "29881 => d\n",
      "10834 => :[\n",
      "10041 => entity\n",
      "29901 => :\n",
      "279 => ar\n",
      "2168 => med\n",
      "13013 => organization\n",
      "1822 => ].\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "965 =>          \n",
      "13 => \n",
      "\n",
      "29973 => ?\n",
      "990 => org\n",
      "281 => w\n",
      "6008 => dt\n",
      "10834 => :[\n",
      "6799 => property\n",
      "29901 => :\n",
      "8758 => instance\n",
      "310 => of\n",
      "29962 => ]\n",
      "29973 => ?\n",
      "1577 => ?\n",
      "990 => org\n",
      "29918 => _\n",
      "1990 => class\n",
      "869 => .\n",
      "13 => \n",
      "\n",
      "29973 => ?\n",
      "667 => item\n",
      "1577 => ?\n",
      "7728 => prop\n",
      "1577 => ?\n",
      "990 => org\n",
      "869 => .\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "539 =>      \n",
      "13 => \n",
      "\n",
      "29973 => ?\n",
      "667 => item\n",
      "281 => w\n",
      "6008 => dt\n",
      "10834 => :[\n",
      "6799 => property\n",
      "29901 => :\n",
      "26601 => occupation\n",
      "29962 => ]\n",
      "1577 => ?\n",
      "12154 => role\n",
      "869 => .\n",
      "13 => \n",
      "\n",
      "29973 => ?\n",
      "12154 => role\n",
      "281 => w\n",
      "6008 => dt\n",
      "10834 => :[\n",
      "6799 => property\n",
      "29901 => :\n",
      "1491 => sub\n",
      "1990 => class\n",
      "310 => of\n",
      "14178 => ]*\n",
      "281 => w\n",
      "29881 => d\n",
      "10834 => :[\n",
      "10041 => entity\n",
      "29901 => :\n",
      "4495 => war\n",
      "13479 => rior\n",
      "29962 => ]\n",
      "869 => .\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "3986 =>         \n",
      "13 => \n",
      "\n",
      "29973 => ?\n",
      "6799 => property\n",
      "281 => w\n",
      "638 => ik\n",
      "747 => ib\n",
      "559 => ase\n",
      "29901 => :\n",
      "11851 => direct\n",
      "29907 => C\n",
      "8342 => laim\n",
      "1577 => ?\n",
      "7728 => prop\n",
      "869 => .\n",
      "13 => \n",
      "\n",
      "29913 => }\n",
      "15345 => GROUP\n",
      "6770 => BY\n",
      "1577 => ?\n",
      "6799 => property\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "632 =>            \n",
      "13 => \n",
      "\n",
      "29913 => }\n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "462 =>                \n",
      "18884 =>               \n",
      "13 => \n",
      "\n",
      "6304 => SER\n",
      "19059 => VICE\n",
      "281 => w\n",
      "638 => ik\n",
      "747 => ib\n",
      "559 => ase\n",
      "29901 => :\n",
      "1643 => label\n",
      "426 => {\n",
      "289 => b\n",
      "29881 => d\n",
      "29901 => :\n",
      "5509 => service\n",
      "4736 => Param\n",
      "281 => w\n",
      "638 => ik\n",
      "747 => ib\n",
      "559 => ase\n",
      "29901 => :\n",
      "11675 => language\n",
      "14704 => \"[\n",
      "20656 => AUT\n",
      "29949 => O\n",
      "29918 => _\n",
      "29931 => L\n",
      "19453 => ANG\n",
      "29965 => U\n",
      "10461 => AGE\n",
      "1402 => ],\n",
      "264 => en\n",
      "1642 => \".\n",
      "500 => }\n",
      "13 => \n",
      "\n",
      "29913 => }\n",
      "462 =>                \n",
      "462 =>                \n",
      "29871 => \n",
      "13 => \n",
      "\n",
      "22364 => ORDER\n",
      "6770 => BY\n",
      "23050 => DESC\n",
      "22308 => (?\n",
      "2798 => count\n",
      "9601 => )[\n",
      "29914 => /\n",
      "29879 => s\n",
      "862 => par\n",
      "1519 => ql\n",
      "29962 => ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt)[\"input_ids\"]\n",
    "list(map(lambda x: print(f\"{x} => {tokenizer.decode(x)}\"), input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[29961, 29914, 25580, 29962]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>description</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>start_with_SELECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT ?property ?propertyType ?propertyLabel ...</td>\n",
       "      <td>Wikidata properties in numerical order</td>\n",
       "      <td>Counting stuff on Wikidata\\nAll Wikidata prope...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>267</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT ?id ?idLabel ?idDescription ?new{\\n?id ...</td>\n",
       "      <td>Wikidata properties excluding external IDs</td>\n",
       "      <td>Counting stuff on Wikidata\\nVariation of the a...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>296</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT (COUNT(?article) AS ?count)\\nWHERE {\\n?...</td>\n",
       "      <td></td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of scientifi...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT (COUNT(DISTINCT ?article) AS ?count)\\nW...</td>\n",
       "      <td>Count of fictional characters</td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of fictional...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>203</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT (COUNT(?item) AS ?count)\\nWHERE { ?item...</td>\n",
       "      <td>Count of items with coordinate locations</td>\n",
       "      <td>Counting stuff on Wikidata\\nCount of items wit...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;This is a conversation betwee...</td>\n",
       "      <td>186</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  SELECT ?property ?propertyType ?propertyLabel ...   \n",
       "1  SELECT ?id ?idLabel ?idDescription ?new{\\n?id ...   \n",
       "2  SELECT (COUNT(?article) AS ?count)\\nWHERE {\\n?...   \n",
       "3  SELECT (COUNT(DISTINCT ?article) AS ?count)\\nW...   \n",
       "4  SELECT (COUNT(?item) AS ?count)\\nWHERE { ?item...   \n",
       "\n",
       "                                  description  \\\n",
       "0      Wikidata properties in numerical order   \n",
       "1  Wikidata properties excluding external IDs   \n",
       "2                                               \n",
       "3               Count of fictional characters   \n",
       "4    Count of items with coordinate locations   \n",
       "\n",
       "                                             context  \\\n",
       "0  Counting stuff on Wikidata\\nAll Wikidata prope...   \n",
       "1  Counting stuff on Wikidata\\nVariation of the a...   \n",
       "2  Counting stuff on Wikidata\\nCount of scientifi...   \n",
       "3  Counting stuff on Wikidata\\nCount of fictional...   \n",
       "4  Counting stuff on Wikidata\\nCount of items wit...   \n",
       "\n",
       "                                              prompt  num_tokens  \\\n",
       "0  <s>[INST] <<SYS>>This is a conversation betwee...         267   \n",
       "1  <s>[INST] <<SYS>>This is a conversation betwee...         296   \n",
       "2  <s>[INST] <<SYS>>This is a conversation betwee...         197   \n",
       "3  <s>[INST] <<SYS>>This is a conversation betwee...         203   \n",
       "4  <s>[INST] <<SYS>>This is a conversation betwee...         186   \n",
       "\n",
       "   start_with_SELECT  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../datasets/final_queries_v1.7.json\"\n",
    "dataset = load_dataset(path)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query\n",
      "SELECT ?jobname (COUNT(?person) AS ?members)\n",
      "WHERE {\n",
      "?person wdt:P3429 ?ee;\n",
      "wdt:P106 ?job.\n",
      "?job rdfs:label ?jobname filter (lang(?jobname) = \"en\")\n",
      "} GROUP BY ?jobname\n",
      "ORDER BY DESC (?members)\n",
      "Description\n",
      "BubbleChart\n",
      "Context\n",
      "Biographical facts\n",
      "Bubble chart of occupations\n"
     ]
    }
   ],
   "source": [
    "# assuming 'df' is your DataFrame and it has these columns\n",
    "row = dataset[['query', 'description', 'context']].loc[(dataset['description'].str.len() > 0)&(dataset['context'].str.len() > 0)].sample()\n",
    "print(\"Query\")\n",
    "print(row['query'].item())\n",
    "print(\"Description\")\n",
    "print(row['description'].item())\n",
    "print(\"Context\")\n",
    "print(row['context'].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>last_executed_step</th>\n",
       "      <th>to_be_executed_step</th>\n",
       "      <th>translated_prompt</th>\n",
       "      <th>status</th>\n",
       "      <th>has_error</th>\n",
       "      <th>output</th>\n",
       "      <th>basic_input</th>\n",
       "      <th>templated_input</th>\n",
       "      <th>target_raw</th>\n",
       "      <th>target_template</th>\n",
       "      <th>gold_execution</th>\n",
       "      <th>gold_executed_query</th>\n",
       "      <th>execution</th>\n",
       "      <th>executed_query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>\"Find artists represented in the Swedish Natio...</td>\n",
       "      <td></td>\n",
       "      <td>LLMTranslator</td>\n",
       "      <td></td>\n",
       "      <td>Unexpected err.msg=\"The LLM result doesn't mat...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"Find artists represented in the Swedish Nati...</td>\n",
       "      <td>\"Find artists represented in the Swedish Natio...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?itemDescription ?Swed...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>exception: query is empty</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>\"Find the places located near Papa Stour islan...</td>\n",
       "      <td></td>\n",
       "      <td>LLMTranslator</td>\n",
       "      <td></td>\n",
       "      <td>Unexpected err.msg=\"The LLM result doesn't mat...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"Find all places with coordinates near Papa S...</td>\n",
       "      <td>\"Find the places located near Papa Stour islan...</td>\n",
       "      <td>SELECT ?place ?placeLabel ?location (GROUP_CON...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'place': {'type': 'uri', 'value': 'http://ww...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>exception: query is empty</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>\"Find the number of unique awards won by indiv...</td>\n",
       "      <td></td>\n",
       "      <td>LLMTranslator</td>\n",
       "      <td></td>\n",
       "      <td>Unexpected err.msg=\"The LLM result doesn't mat...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"Write a query to find the number of occurren...</td>\n",
       "      <td>\"Find the number of unique awards won by indiv...</td>\n",
       "      <td>SELECT (COUNT(?item) AS ?count) ?otheraward ?o...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'otheraward': {'type': 'uri', 'value': 'http...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>exception: query is empty</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>\"Find entities in Wikidata that have a linked ...</td>\n",
       "      <td></td>\n",
       "      <td>LLMTranslator</td>\n",
       "      <td></td>\n",
       "      <td>Unexpected err.msg=\"The LLM result doesn't mat...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"Find all items on Wikidata that have a linke...</td>\n",
       "      <td>\"Find entities in Wikidata that have a linked ...</td>\n",
       "      <td>SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>exception: query is empty</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>\"Write a SparQL query to retrieve the name, or...</td>\n",
       "      <td></td>\n",
       "      <td>LLMTranslator</td>\n",
       "      <td></td>\n",
       "      <td>Unexpected err.msg=\"The LLM result doesn't mat...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>[\"Write a SparQL query to retrieve the name, l...</td>\n",
       "      <td>\"Write a SparQL query to retrieve the name, or...</td>\n",
       "      <td>SELECT ?doctor ?doctorLabel ?ordinal ?performe...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>[{'doctor': {'type': 'uri', 'value': 'http://w...</td>\n",
       "      <td>PREFIX bd: &lt;http://www.bigdata.com/rdf#&gt;\\nPREF...</td>\n",
       "      <td>exception: query is empty</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     row last_executed_step  \\\n",
       "index                                                                         \n",
       "1789   \"Find artists represented in the Swedish Natio...                      \n",
       "2338   \"Find the places located near Papa Stour islan...                      \n",
       "2779   \"Find the number of unique awards won by indiv...                      \n",
       "1624   \"Find entities in Wikidata that have a linked ...                      \n",
       "662    \"Write a SparQL query to retrieve the name, or...                      \n",
       "\n",
       "      to_be_executed_step translated_prompt  \\\n",
       "index                                         \n",
       "1789        LLMTranslator                     \n",
       "2338        LLMTranslator                     \n",
       "2779        LLMTranslator                     \n",
       "1624        LLMTranslator                     \n",
       "662         LLMTranslator                     \n",
       "\n",
       "                                                  status  has_error output  \\\n",
       "index                                                                        \n",
       "1789   Unexpected err.msg=\"The LLM result doesn't mat...       True   None   \n",
       "2338   Unexpected err.msg=\"The LLM result doesn't mat...       True   None   \n",
       "2779   Unexpected err.msg=\"The LLM result doesn't mat...       True   None   \n",
       "1624   Unexpected err.msg=\"The LLM result doesn't mat...       True   None   \n",
       "662    Unexpected err.msg=\"The LLM result doesn't mat...       True   None   \n",
       "\n",
       "                                             basic_input  \\\n",
       "index                                                      \n",
       "1789   [\"Find artists represented in the Swedish Nati...   \n",
       "2338   [\"Find all places with coordinates near Papa S...   \n",
       "2779   [\"Write a query to find the number of occurren...   \n",
       "1624   [\"Find all items on Wikidata that have a linke...   \n",
       "662    [\"Write a SparQL query to retrieve the name, l...   \n",
       "\n",
       "                                         templated_input  \\\n",
       "index                                                      \n",
       "1789   \"Find artists represented in the Swedish Natio...   \n",
       "2338   \"Find the places located near Papa Stour islan...   \n",
       "2779   \"Find the number of unique awards won by indiv...   \n",
       "1624   \"Find entities in Wikidata that have a linked ...   \n",
       "662    \"Write a SparQL query to retrieve the name, or...   \n",
       "\n",
       "                                              target_raw  \\\n",
       "index                                                      \n",
       "1789   SELECT ?item ?itemLabel ?itemDescription ?Swed...   \n",
       "2338   SELECT ?place ?placeLabel ?location (GROUP_CON...   \n",
       "2779   SELECT (COUNT(?item) AS ?count) ?otheraward ?o...   \n",
       "1624   SELECT ?item ?itemLabel ?3dmodel\\nWHERE {\\n?it...   \n",
       "662    SELECT ?doctor ?doctorLabel ?ordinal ?performe...   \n",
       "\n",
       "                                         target_template  \\\n",
       "index                                                      \n",
       "1789   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2338   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2779   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "1624   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "662    PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "\n",
       "                                          gold_execution  \\\n",
       "index                                                      \n",
       "1789   [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "2338   [{'place': {'type': 'uri', 'value': 'http://ww...   \n",
       "2779   [{'otheraward': {'type': 'uri', 'value': 'http...   \n",
       "1624   [{'item': {'type': 'uri', 'value': 'http://www...   \n",
       "662    [{'doctor': {'type': 'uri', 'value': 'http://w...   \n",
       "\n",
       "                                     gold_executed_query  \\\n",
       "index                                                      \n",
       "1789   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2338   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "2779   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "1624   PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "662    PREFIX bd: <http://www.bigdata.com/rdf#>\\nPREF...   \n",
       "\n",
       "                       execution executed_query  \n",
       "index                                            \n",
       "1789   exception: query is empty           None  \n",
       "2338   exception: query is empty           None  \n",
       "2779   exception: query is empty           None  \n",
       "1624   exception: query is empty           None  \n",
       "662    exception: query is empty           None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"../outputs/batch_run/test/execution/CL-7b-Instruct_oawbn8-rv256-rm1-ld0-bs2-ga8-gc1-p0-nta0-e1-ctx3072-qno-template-template-stsparql_engpeft-dgreedy-t02-topp095-cdbf16_executed.parquet.gzip\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset)=118\n",
      "len(dataset.loc[dataset['has_error']])=118\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(dataset)=}\")\n",
    "print(f\"{len(dataset.loc[dataset['has_error']])=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
