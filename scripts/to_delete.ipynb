{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "import pandas as pd\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"../outputs/batch_run/faith_template5/execution/Mistral-7B-Instruct-v0.2_rv16-ld0.05-bs1-p0-nta1-e3-template_engpeft-t0.2-topp0.95_executed.parquet.gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].translated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].linked_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].target_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "print(f\"{tokenizer.unk_token=}\")\n",
    "print(f\"{tokenizer.pad_token=}\")\n",
    "print(f\"{tokenizer.unk_token_id=}\")\n",
    "print(f\"{tokenizer.pad_token_id=}\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "print(f\"{tokenizer.unk_token=}\")\n",
    "print(f\"{tokenizer.pad_token=}\")\n",
    "print(f\"{tokenizer.unk_token_id=}\")\n",
    "print(f\"{tokenizer.pad_token_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"../outputs/batch_run/democracy_template8/execution/Mistral-7B-Instruct-v0.2_rv32-ld0.05-bs1-p0-nta1-e3-template_engpeft-t0.2-topp0.95_executed.parquet.gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handpicked_data = df.loc[(~df['execution'].str.startswith(\"exception:\")) & (~df['execution'].isnull()) & (df['execution'].map(len) > 0)].iloc[[1, 2, 3, 206, 207]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tokenizer.batch_encode_plus([f\"`sparql\\n{i}`\" for i in handpicked_data['translated_prompt'].to_list()], add_special_tokens=False, padding='longest', return_tensors='np')['input_ids'].tolist()\n",
    "labels = tokenizer.batch_encode_plus([f\"`sparql\\n{i}`\" for i in handpicked_data['target_template'].to_list()], add_special_tokens=False, padding='longest', return_tensors='np')['input_ids'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "data = {\n",
    "    \"preds\": preds,\n",
    "    \"labels\": labels,\n",
    "}\n",
    "\n",
    "path = Path(\"sft_peft_compute_metrics_execute_ok.json\")\n",
    "path.write_text(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "\n",
    "\n",
    "df = load_dataset(\"../outputs/batch_run/lezgo/execution/Mistral-7B-Instruct-v0.2_rv16-ld0-bs1-p0-nta0-e3-template_engpeft-t0.2-topp0.95_executed.parquet.gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "df_out = df.head()\n",
    "\n",
    "path = Path(\"evaluation_test.json\")\n",
    "path.write_text(df_out.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_gold = json.loads(Path(\"../outputs/batch_run/lezgo/preprocessed_gold.json\").read_text())\n",
    "df_gold = pd.read_json(data_gold['df_gold_eval'])\n",
    "df_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_out = df_gold.head()\n",
    "\n",
    "path = Path(\"evaluation_test_gold.json\")\n",
    "path.write_text(df_gold_out.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"../datasets/final_queries_v1.7.json\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = dataset[2549:2553]\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_v2 = df_out.reset_index(drop=True)\n",
    "df_out_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"templatize_test.json\")\n",
    "path.write_text(df_out_v2.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"../outputs/dataset_pipeline/fq17_3/fq17_3-split_test.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = df.iloc[0]\n",
    "for c in df.columns:\n",
    "    print(c)\n",
    "    print(entry[c])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from data_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"../outputs/dataset_pipeline/fq17_3/fq17_3-split_test.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[2].target_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments, AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from sft_peft import format_prompt\n",
    "import sft_peft\n",
    "from prompts_template import BASE_MISTRAL_TEMPLATE, BASE_BASIC_INSTRUCTION\n",
    "from libwikidatallm.TemplateLLMQuerySender import TemplateLLMQuerySender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template=\"[/INST]\", tokenizer=tokenizer)\n",
    "datasets = load_dataset(\"pandas\", data_files=\n",
    "                          {\n",
    "                              \"valid\": \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_valid.pkl\",\n",
    "                              \"train\": \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_train.pkl\",\n",
    "                              \"test\": \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_test.pkl\",\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    valid: Dataset({\n",
       "        features: ['basic_input', 'templated_input', 'target_raw', 'target_template', 'index'],\n",
       "        num_rows: 129\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['basic_input', 'templated_input', 'target_raw', 'target_template', 'index'],\n",
       "        num_rows: 1923\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['basic_input', 'templated_input', 'target_raw', 'target_template', 'index'],\n",
       "        num_rows: 513\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from SFTTrainer(Trainer) _prepare_non_packed_dataloader method\n",
    "def _prepare_non_packed_dataloader(\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    dataset_text_field,\n",
    "    max_seq_length,\n",
    "    formatting_func=None,\n",
    "    add_special_tokens=True,\n",
    "    remove_unused_columns=True,\n",
    "):\n",
    "    use_formatting_func = formatting_func is not None and dataset_text_field is None\n",
    "    # self._dataset_sanity_checked = False\n",
    "\n",
    "    # Inspired from: https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt\n",
    "    def tokenize(element):\n",
    "        outputs = tokenizer(\n",
    "            element[dataset_text_field] if not use_formatting_func else formatting_func(element),\n",
    "            add_special_tokens=add_special_tokens,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=max_seq_length,\n",
    "            return_overflowing_tokens=False,\n",
    "            return_length=False,\n",
    "        )\n",
    "\n",
    "        # if use_formatting_func and not self._dataset_sanity_checked:\n",
    "        #     if not isinstance(formatting_func(element), list):\n",
    "        #         raise ValueError(\n",
    "        #             \"The `formatting_func` should return a list of processed strings since it can lead to silent bugs.\"\n",
    "        #         )\n",
    "        #     else:\n",
    "        #         self._dataset_sanity_checked = True\n",
    "\n",
    "        return {\"input_ids\": outputs[\"input_ids\"], \"attention_mask\": outputs[\"attention_mask\"]}\n",
    "\n",
    "    signature_columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "\n",
    "    extra_colmuns = list(set(dataset.column_names) - set(signature_columns))\n",
    "\n",
    "    # if not remove_unused_columns and len(extra_colmuns) > 0:\n",
    "    #     warnings.warn(\n",
    "    #         \"You passed `remove_unused_columns=False` on a non-packed dataset. This might create some issues with the default collator and yield to errors. If you want to \"\n",
    "    #         f\"inspect dataset other columns (in this case {extra_colmuns}), you can subclass `DataCollatorForLanguageModeling` in case you used the default collator and create your own data collator in order to inspect the unused dataset columns.\"\n",
    "    #     )\n",
    "\n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names if remove_unused_columns else None,\n",
    "        num_proc=1,\n",
    "        batch_size=32,\n",
    "    )\n",
    "\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = BASE_MISTRAL_TEMPLATE\n",
    "sft_peft.templater = TemplateLLMQuerySender(None, template, start_seq='[', end_seq=']')\n",
    "sft_peft.input_column = \"basic_input\"\n",
    "sft_peft.target_column = \"target_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = _prepare_non_packed_dataloader(tokenizer, datasets['test'], None, None, format_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 513\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator(tokenized_dataset, return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from sft_peft import main, parse_args\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args([\n",
    "    \"--model\", \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"--train-data\", \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_train.pkl\",\n",
    "    \"--target-column\", \"target_raw\",\n",
    "    \"--input-column\", \"basic_input\",\n",
    "    \"--valid-data\", \"../outputs/dataset_pipeline/fq17_3/fq17_3-split_valid.pkl\",\n",
    "    \"--start-tag\", \"[query]\",\n",
    "    \"--end-tag\", \"[/query]\",\n",
    "    \"--rvalue\", \"32\",\n",
    "    \"--lora-dropout\", \"0\",\n",
    "    \"--batch-size\", \"1\",\n",
    "    \"--gradient-accumulation\", str(4),\n",
    "    \"--packing\", \"0\",\n",
    "    \"--neft-tune-alpha\", \"0\",\n",
    "    \"--epochs\", \"1\",\n",
    "    \"--output\", \".\",\n",
    "    \"--save-name\", \"test_debug\",\n",
    "    \"--run-name\", f\"test_debug\",\n",
    "    \"--random-seed\", \"42\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\"../modules\").absolute().__str__())\n",
    "\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tokens_with_ids(txt):\n",
    "    tokens = tokenizer.tokenize(txt, add_special_tokens=False)\n",
    "    token_ids = tokenizer.encode(txt, add_special_tokens=False)\n",
    "    print(list(zip(tokens, token_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.2', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▁[', 733), ('/', 28748), ('INST', 16289), (']', 28793)]\n",
      "[('▁[', 733), ('/', 28748), ('INST', 16289), (']', 28793), ('▁[', 733), ('query', 3385), (']', 28793)]\n",
      "[('▁[', 733), ('/', 28748), ('INST', 16289), (']', 28793), ('▁[', 733), ('query', 3385), (']', 28793)]\n"
     ]
    }
   ],
   "source": [
    "print_tokens_with_ids(\"[/INST]\")\n",
    "print_tokens_with_ids(\"[/INST] [query]\")\n",
    "print_tokens_with_ids(\"[/INST] [query]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
