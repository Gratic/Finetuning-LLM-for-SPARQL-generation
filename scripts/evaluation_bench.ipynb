{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from typing import List, Dict, Union\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import nltk\n",
    "\n",
    "def failed_generation_index(dataset: pd.DataFrame):\n",
    "    return dataset.loc[dataset['has_error'] == True].index\n",
    "\n",
    "def corpus_meteor(references: List, hypotheses: List):\n",
    "    meteor_scores = 0.\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        meteor_scores += single_meteor_score(ref.split(), hyp.split())\n",
    "    return meteor_scores / float(len(references))\n",
    "\n",
    "def safe_eval(execution: str):\n",
    "    \"\"\"Evaluates \"\"\"\n",
    "    try:\n",
    "        return literal_eval(execution)\n",
    "    except Exception as inst:\n",
    "        logging.error(f\"Exception occured while evaluating: {inst}.\")\n",
    "        print(f\"Exception occured while evaluating: {inst}.\")\n",
    "        return None\n",
    "\n",
    "def eval_dataset(dataset: pd.DataFrame, col_name: str = \"eval\"):\n",
    "    df_eval = dataset.copy()\n",
    "    df_eval[col_name] = df_eval.apply(lambda x: safe_eval(x['execution']), axis=1)\n",
    "    return df_eval[~df_eval[col_name].isnull()]\n",
    "\n",
    "def get_nested_values(element: Union[Dict, str, None]):\n",
    "    values = []\n",
    "    if isinstance(element, dict):\n",
    "        for k, v in element.items():\n",
    "            if isinstance(v, dict):\n",
    "                values += get_nested_values(v)\n",
    "            elif isinstance(v, str):\n",
    "                if 'value' in k:\n",
    "                    values.append(v)\n",
    "    elif isinstance(element, list):\n",
    "        for el in element:\n",
    "            values += get_nested_values(el)\n",
    "    elif element is None:\n",
    "        values = []\n",
    "    else:\n",
    "        logging.error(f\"get_nested_values doesn't have an implementation for: {type(element)}.\")\n",
    "        raise TypeError(f\"Compatible types are Dict and List, found: {type(element)}.\")\n",
    "    return values\n",
    "\n",
    "def compute_precision(hypothesis: List, gold: List):\n",
    "    shypothesis = set(hypothesis)\n",
    "    sgold = set(gold)\n",
    "    \n",
    "    if len(shypothesis) == 0:\n",
    "        return 1. if len(sgold) == 0 else 0.\n",
    "    \n",
    "    relevant = shypothesis.intersection(sgold)\n",
    "    return len(relevant)/len(shypothesis)\n",
    "\n",
    "def compute_recall(hypothesis: List, gold: List):\n",
    "    shypothesis = set(hypothesis)\n",
    "    sgold = set(gold)\n",
    "    \n",
    "    if len(sgold) == 0:\n",
    "        return 1. if len(shypothesis) == 0 else 0.\n",
    "    \n",
    "    relevant = shypothesis.intersection(sgold)\n",
    "    return len(relevant)/len(sgold)\n",
    "\n",
    "def load_dataset(path: str):\n",
    "    if path.endswith(('.parquet', '.parquet.gzip')):\n",
    "        return pd.read_parquet(path, engine='auto')\n",
    "    elif path.endswith('.json'):\n",
    "        return pd.read_json(path)\n",
    "    \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\n",
    "    \"dataset\": \"../outputs/batch_run/test2/execution/Mistral-7B-Instruct-v0.2_rv16-bs2-p0_t0.2-topp0.95_executed.parquet.gzip\",\n",
    "    \"gold\": \"../datasets/queries_with_execution_results_with_limit.parquet.gzip\",\n",
    "    \"model\": \"Mistral-7B-Instruct-v0.2\",\n",
    "    \"output\": \".\",\n",
    "    \"save_name\": \"test\",\n",
    "    \"log_level\": \"warning\",\n",
    "    \"log_file\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='../outputs/batch_run/test2/execution/Mistral-7B-Instruct-v0.2_rv16-bs2-p0_t0.2-topp0.95_executed.parquet.gzip', gold='../datasets/queries_with_execution_results_with_limit.parquet.gzip', log_file='', log_level='warning', model='Mistral-7B-Instruct-v0.2', output='.', save_name='test')\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace()\n",
    "args.__dict__.update(arguments)\n",
    "print(args)\n",
    "\n",
    "numeric_log_level = getattr(logging, args.log_level.upper(), None)\n",
    "if not isinstance(numeric_log_level, int):\n",
    "    raise ValueError(f\"Invalid log level: {args.log_level}.\")\n",
    "logging.basicConfig(filename=args.log_file if args.log_file else None, level=numeric_log_level)\n",
    "\n",
    "if not os.path.exists(args.dataset):\n",
    "    raise FileNotFoundError(f\"The dataset file not found with path: {args.dataset}\")\n",
    "\n",
    "if not os.path.exists(args.gold):\n",
    "    raise FileNotFoundError(f\"The gold dataset file not found with path: {args.gold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(args.dataset)\n",
    "df_gold = load_dataset(args.gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_gen_fail = df.drop(failed_generation_index(df))\n",
    "df_exec_timeout = df_no_gen_fail.loc[df_no_gen_fail['execution'] == 'timeout']\n",
    "df_exec_fail = df_no_gen_fail.loc[df_no_gen_fail['execution'].str.startswith('exception')]\n",
    "df_exec_empty = df_no_gen_fail.loc[df_no_gen_fail['execution'].isnull()]\n",
    "df_exec_to_eval = df_no_gen_fail.drop(df_exec_timeout.index).drop(df_exec_fail.index).drop(df_exec_empty.index)\n",
    "df_eval = eval_dataset(df_exec_to_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold_exec_timeout = df_gold.loc[df_gold['execution'] == 'timeout']\n",
    "df_gold_exec_fail = df_gold.loc[df_gold['execution'].str.startswith('exception')]\n",
    "df_gold_exec_empty = df_gold.loc[df_gold['execution'].isnull()]\n",
    "df_gold_exec_to_eval = df_gold.drop(df_gold_exec_timeout.index).drop(df_gold_exec_fail.index).drop(df_gold_exec_empty.index)\n",
    "df_gold_eval = eval_dataset(df_gold_exec_to_eval, \"gold_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2421    \"Can you find out where the authors of Wikimam...\n",
       "2429    \"Can you retrieve all Wikipedia sites using Sp...\n",
       "2431    \"Can you find me all the historical buildings ...\n",
       "2432    \"Can you retrieve a list of alumni from the Un...\n",
       "2435    \"Can you retrieve the distinct names of Willem...\n",
       "                              ...                        \n",
       "2811    \"Can you find out where people born in Brittan...\n",
       "2814    \"Can you retrieve all properties used to descr...\n",
       "2819    \"Can you write a SparQL query to find all item...\n",
       "2822    \"Can you write a SparQL query to find scholarl...\n",
       "2836    \"Can you find me all the groups of fictional c...\n",
       "Name: row, Length: 87, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval['row']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ?author ?authorLabel ?birthPlaceLabel WHERE {\n",
      "  ?author wdt:P31 wd:Q1145.  # Q1145 is \"person\"\n",
      "  ?author wdt:P19 wd:Q13563.  # Q13563 is \"author\"\n",
      "  ?author wdt:P569 ?birthPlace.  # P569 is \"date of birth\"\n",
      "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
      "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". bd:serviceParam wikibase:entityId ?birthPlace . }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_exec_to_eval['translated_prompt'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_eval    [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "Name: 2421, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gold_eval[['gold_eval']].loc['2421']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval</th>\n",
       "      <th>gold_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eval gold_eval\n",
       "2421   []       NaN\n",
       "2429   []       NaN\n",
       "2431   []       NaN\n",
       "2432   []       NaN\n",
       "2435   []       NaN\n",
       "...   ...       ...\n",
       "2811   []       NaN\n",
       "2814   []       NaN\n",
       "2819   []       NaN\n",
       "2822   []       NaN\n",
       "2836   []       NaN\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[['eval']].join(df_gold_eval[['gold_eval']], rsuffix=\"_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_loc(x, df, column, default=None):\n",
    "    try:\n",
    "        ans = df[[column]].loc[str(x.name)]\n",
    "    except:\n",
    "        ans = default\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>[{'consort': {'type': 'uri', 'value': 'http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>[{'lighthouse': {'type': 'uri', 'value': 'http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>[{'airport': {'type': 'uri', 'value': 'http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>[{'WorldPride': {'type': 'uri', 'value': 'http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              gold_eval\n",
       "2421  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2429  [{'consort': {'type': 'uri', 'value': 'http://...\n",
       "2431  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2432  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2435                                               None\n",
       "...                                                 ...\n",
       "2811  [{'lighthouse': {'type': 'uri', 'value': 'http...\n",
       "2814  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2819  [{'airport': {'type': 'uri', 'value': 'http://...\n",
       "2822  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2836  [{'WorldPride': {'type': 'uri', 'value': 'http...\n",
       "\n",
       "[87 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[['eval']].apply(lambda x: safe_loc(x, df_gold_eval, \"gold_eval\", None), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2570    [{'state': {'type': 'uri', 'value': 'http://ww...\n",
       "2581    [{'count': {'datatype': 'http://www.w3.org/200...\n",
       "2607    [{'numDirectors': {'datatype': 'http://www.w3....\n",
       "2629    [{'numSpouses': {'datatype': 'http://www.w3.or...\n",
       "2668    [{'num': {'datatype': 'http://www.w3.org/2001/...\n",
       "2795    [{'region': {'type': 'uri', 'value': 'http://w...\n",
       "Name: eval, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval['eval'].loc[df_eval['eval'].map(len) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_eval = df_eval.copy()\n",
    "df_merged_eval[\"gold_eval\"] = df_merged_eval.apply(lambda x: safe_loc(x, df_gold_eval, \"gold_eval\", None), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval</th>\n",
       "      <th>gold_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'consort': {'type': 'uri', 'value': 'http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'lighthouse': {'type': 'uri', 'value': 'http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'airport': {'type': 'uri', 'value': 'http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'item': {'type': 'uri', 'value': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'WorldPride': {'type': 'uri', 'value': 'http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eval                                          gold_eval\n",
       "2421   []  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2429   []  [{'consort': {'type': 'uri', 'value': 'http://...\n",
       "2431   []  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2432   []  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2435   []                                               None\n",
       "...   ...                                                ...\n",
       "2811   []  [{'lighthouse': {'type': 'uri', 'value': 'http...\n",
       "2814   []  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2819   []  [{'airport': {'type': 'uri', 'value': 'http://...\n",
       "2822   []  [{'item': {'type': 'uri', 'value': 'http://www...\n",
       "2836   []  [{'WorldPride': {'type': 'uri', 'value': 'http...\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_eval[['eval', 'gold_eval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_eval['precision'] = df_merged_eval.apply(lambda x: compute_precision(get_nested_values(x['eval']), get_nested_values(x['gold_eval'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_eval['recall'] = df_merged_eval.apply(lambda x: compute_recall(get_nested_values(x['eval']), get_nested_values(x['gold_eval'])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  recall\n",
       "2421        0.0     0.0\n",
       "2429        0.0     0.0\n",
       "2431        0.0     0.0\n",
       "2432        0.0     0.0\n",
       "2435        1.0     1.0\n",
       "...         ...     ...\n",
       "2811        0.0     0.0\n",
       "2814        0.0     0.0\n",
       "2819        0.0     0.0\n",
       "2822        0.0     0.0\n",
       "2836        0.0     0.0\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_eval[['precision', 'recall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_precision=0.09195402298850575, m_recall=0.09195402298850575, m_fscore=0.09195402298850575\n"
     ]
    }
   ],
   "source": [
    "m_precision = df_merged_eval['precision'].mean()\n",
    "m_recall = df_merged_eval['recall'].mean()\n",
    "m_fscore = 2*m_precision*m_recall/(m_precision+m_recall)\n",
    "\n",
    "print(f\"{m_precision=}, {m_recall=}, {m_fscore=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score=0.01493558729594148, meteor_score=0.1299193095224561\n"
     ]
    }
   ],
   "source": [
    "bleu_score = corpus_bleu([[x.split()] for x in df_no_gen_fail['target']], [x.split() for x in df_no_gen_fail['translated_prompt']])\n",
    "meteor_score = corpus_meteor(df_no_gen_fail['target'], df_no_gen_fail['translated_prompt'])\n",
    "\n",
    "print(f\"{bleu_score=}, {meteor_score=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name          Mistral-7B-Instruct-v0.2\n",
       "num_rows                                 427\n",
       "num_gen_fail                             107\n",
       "num_exec_timeout                           1\n",
       "num_exec_fail                            232\n",
       "num_exec_empty                             0\n",
       "num_exec_to_eval                          87\n",
       "num_eval                                  87\n",
       "bleu_score                          0.014936\n",
       "meteor_score                        0.129919\n",
       "precision                           0.091954\n",
       "recall                              0.091954\n",
       "f1score                             0.091954\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = pd.Series(data=\n",
    "                {\n",
    "                    \"model_name\": args.model,\n",
    "                    \"num_rows\": len(df),\n",
    "                    \"num_gen_fail\": len(df.loc[df['has_error'] == True]),\n",
    "                    \"num_exec_timeout\": len(df_exec_timeout),\n",
    "                    \"num_exec_fail\": len(df_exec_fail),\n",
    "                    \"num_exec_empty\": len(df_exec_empty),\n",
    "                    \"num_exec_to_eval\": len(df_exec_to_eval),\n",
    "                    \"num_eval\": len(df_eval),\n",
    "                    \"bleu_score\": bleu_score,\n",
    "                    \"meteor_score\": meteor_score,\n",
    "                    \"precision\": m_precision,\n",
    "                    \"recall\": m_recall,\n",
    "                    \"f1score\": m_fscore\n",
    "                })\n",
    "serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(args.output, exist_ok=True)\n",
    "serie.to_json(os.path.join(args.output, f\"{args.save_name}.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
