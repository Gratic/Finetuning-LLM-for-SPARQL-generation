[Execution]
# Use Huggingface's Accelerate library
use_accelerate = False

# Path to the preprocessed gold data (json format)
preprocess_gold_path = outputs/batch_run/experiment_basic_vs_template/preprocessed_gold.json
random_seed = 123456

[Models]
# Path is the path to find the model or the huggingface's id [company]/[model name].
# Name is used for saving purposes.
# path: where to find the model, can be a folder or a hugging face id
# name: name of the model for creating files
# context_length: the maximal context length to use, higher means higher memory consumption
# token: auth token for gated models
# quantization: how to quantisize the models weight when fine tuning, possible options are 'no', '4bit' and '8bit'. By default set to '4bit'.
; {
;     "path": "meta-llama/Llama-2-7b-chat-hf",
;     "name": "Llama-2-7b-chat-hf",
;     "context_length": 512,
;     "token": "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",
;     "quantization": "4bit"
; },
models = [
    {
        "path": "mistralai/Mistral-7B-Instruct-v0.2",
        "name": "Mistral-7B-Instruct-v0.2",
        "context_length": 4096
    }
    ]


[Datasets]
# Paths to the different splits of the datasets.
# Must be done before using this scripts using generate_finetune_dataset.py
train = outputs/finetune_dataset_train.pkl
valid = outputs/finetune_dataset_valid.pkl
test = outputs/finetune_dataset_test.pkl

[Training Hyperparameters]
# Optimizer should be the name (or names separated by a comma) of huggingface's implemented optimizer names.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
# https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.optim
optimizer=adamw_torch
# lora_r_value, lora_dropout, batch_size, packing, neft_tune_alpha and pipeline_type are comma separated list.
# e.g. lora_r_value = 4, 8 will be interpreted as ["4", "8"].
# A cross product is realized between above mentioned list to train with all possible combinations.
# Packing in particular needs to be 0 or 1 exclusively, because it gets treated as a boolean.
lora_r_value = 4, 8, 16, 32
# lora r alpha is based on lora_r_value, r alpha = lora_r_value * lora_r_alpha_mult
lora_r_alpha_mult = 1
lora_dropout = 0, 0.05
batch_size = 1
# packing is a boolean (0 = False, 1 = True)
packing = 0
neft_tune_alpha = 0, 1, 5
gradient_accumulation = 4
# gradient_checkpointing is a boolean (0 = False, 1 = True)
gradient_checkpointing = 1
epochs = 3
# Possible values are defined in Pipeline Types To Target Columns section under.
pipeline_type = basic
# Possible values are defined in Input Types to Input Columns section under.
input_type = basic

[Evaluation Hyperparameters]
# Possible engine are vllm and peft.
engine = peft
# decoding can be 'greedy' or 'sampling' with peft engine
decoding = greedy
temperature = 0.2
top_p = 0.95
num_tokens=1024
# computational_type changes the type of the weight of the model during evaluation (works only with engine=peft). Choices are 'fp32', 'fp16' and 'bf16'.
computational_type=bf16
start_tag =[sparql]
end_tag =[/sparql]

[Training Hyperparameters Name Abbreviations]
optimizer = opt
lora_r_value = rv
lora_r_alpha_mult = ramul
lora_dropout = ld
batch_size = bs
packing = p
neft_tune_alpha = nta
gradient_accumulation = ga
gradient_checkpointing = gc
num_epochs = e

[Evaluation Hyperparameters Name Abbreviations]
engine = eng
decoding = d
temperature = t
top_p = topp
num_tokens = no
computational_type=cd
start_tag = no
end_tag = no

[Pipeline Types To Target Columns]
# Each key is a possible pipeline_type value of the section Training Hyperparameters.
# Different pipelines needs different target (not preprocessed the same).
# Here we define, which pipeline needs which target column.
template = target_template
basic = target_raw

[Input Types to Input Columns]
template = templated_input
basic = basic_input
